key,title,year,month,day,journal,issn,volume,issue,pages,authors,url,language,publisher,location,abstract,notes,doi,keywords,pubmed_id,pmc_id
rayyan-210801544,Natural Hazards Twitter Dataset,,1,1,,,,,,,,en,,,"With the development of the Internet, social media has become an important channel for posting disaster-related information. Analyzing attitudes hidden in these texts, known as sentiment analysis, is crucial for the government or relief agencies to improve disaster response efficiency, but it has not received sufficient attention. This paper aims to fill this gap by focusing on investigating attitudes towards disaster response and analyzing targeted relief supplies during disaster response. The contributions of this paper are fourfold. First, we propose several machine learning models for classifying public sentiment concerning disaster-related social media data. Second, we create a natural disaster dataset with sentiment labels, which contains nearly 50,00 Twitter data about different natural disasters in the United States (e.g., a tornado in 2011, a hurricane named Sandy in 2012, a series of floods in 2013, a hurricane named Matthew in 2016, a blizzard in 2016, a hurricane named Harvey in 2017, a hurricane named Michael in 2018, a series of wildfires in 2018, and a hurricane named Dorian in 2019). We are making our dataset available to the research community: https://github.com/Dong-UTIL/Natural-Hazards-Twitter-Dataset. It is our hope that our contribution will enable the study of sentiment analysis in disaster response. Third, we focus on extracting public attitudes and analyzing the essential needs (e.g., food, housing, transportation, and medical supplies) for the public during disaster response, instead of merely targeting on studying positive or negative attitudes of the public to natural disasters. Fourth, we conduct this research from two different dimensions for a comprehensive understanding of public opinion on disaster response, since disparate hazards caused by different types of natural disasters.","",https://doi.org/10.48550/arxiv.2004.14456,"",,
rayyan-210801734,Integrated Question-Answering System for Natural Disaster Domains Based on Social Media Messages Posted at the Time of Disaster,,1,1,,,,,,,,en,,,"Natural disasters are events that humans cannot control, and Japan has suffered from many such disasters over its long history. Many of these have caused severe damage to human lives and property. These days, numerous Japanese people have gained considerable experience preparing for disasters and are now striving to predict the effects of disasters using social network services (SNSs) to exchange information in real time. Currently, Twitter is the most popular and powerful SNS tool used for disaster response in Japan because it allows users to exchange and disseminate information quickly. However, since almost all of the Japanese-related content is also written in the Japanese language, which restricts most of its benefits to Japanese people, we feel that it is necessary to create a disaster response system that would help people who do not understand Japanese. Accordingly, this paper presents the framework of a question-answering (QA) system that was developed using a Twitter dataset containing more than nine million tweets compiled during the Osaka North Earthquake that occurred on 18 June 2018. We also studied the structure of the questions posed and developed methods for classifying them into particular categories in order to find answers from the dataset using an ontology, word similarity, keyword frequency, and natural language processing. The experimental results presented herein confirm the accuracy of the answer results generated from our proposed system.","",https://doi.org/10.3390/info11090456,"",,
rayyan-210801925,Water level prediction from social media images with a multi-task ranking approach,,1,1,,,,,,,,en,,,"Floods are among the most frequent and catastrophic natural disasters and affect millions of people worldwide. It is important to create accurate flood maps to plan (offline) and conduct (real-time) flood mitigation and flood rescue operations. Arguably, images collected from social media can provide useful information for that task, which would otherwise be unavailable. We introduce a computer vision system that estimates water depth from social media images taken during flooding events, in order to build flood maps in (near) real-time. We propose a multi-task (deep) learning approach, where a model is trained using both a regression and a pairwise ranking loss. Our approach is motivated by the observation that a main bottleneck for image-based flood level estimation is training data: it is diffcult and requires a lot of effort to annotate uncontrolled images with the correct water depth. We demonstrate how to effciently learn a predictor from a small set of annotated water levels and a larger set of weaker annotations that only indicate in which of two images the water level is higher, and are much easier to obtain. Moreover, we provide a new dataset, named DeepFlood, with 8145 annotated ground-level images, and show that the proposed multi-task approach can predict the water level from a single, crowd-sourced image with ~11 cm root mean square error.","",https://doi.org/10.48550/arxiv.2007.06749,"",,
rayyan-210805337,"The COVID-19 pandemic: when science collided with politics, culture and the human imagination",,1,1,,,,,,,,en,,,"Open AccessMoreSectionsView PDF ToolsAdd to favoritesDownload CitationsTrack Citations ShareShare onFacebookTwitterLinked InRedditEmail Cite this article Highfield Roger 2021The COVID-19 pandemic: when science collided with politics, culture and the human imaginationInterface Focus.112021007020210070http://doi.org/10.1098/rsfs.2021.0070SectionOpen AccessIntroductionThe COVID-19 pandemic: when science collided with politics, culture and the human imagination Roger Highfield Roger Highfield Science Museum Group, London, UK [email protected] Google Scholar Find this author on PubMed Search for more papers by this author Roger Highfield Roger Highfield Science Museum Group, London, UK [email protected] Google Scholar Find this author on PubMed Published:12 October 2021https://doi.org/10.1098/rsfs.2021.0070 As the SARS-CoV-2 virus continues to disrupt life around the world, the pandemic has provided a mirror with which to review the relationship between science, policymaking and society. It reflects the more successful aspects of the response to COVID-19, such as the remarkable speed of vaccine development, some perplexing features, such as anti-vaccine sentiment, the efficacy, public acceptance and political influence of epidemiology, and more. There is no better perspective to gaze through this looking glass than from the viewpoint of the Science Museum Group, a cultural institution which acts as a nexus for government, industry, the charitable sector and the public, along with the past, present and future of science, engineering and innovation [1]. Museums can offer unique perspectives on the spread of infectious disease [2]. Their collections and scholarship reveal the lessons of the past, such as the historic debates over the benefits and risks of vaccination [3]. Moreover, through collecting contemporary objects along with exhibitions and events, museums can shed light on how science can shape our future, whether through the development of new therapeutics, monitoring the evolution of a virus, or by modelling. They can also show how we, in turn, can shape science. The pandemic has also driven the evolution of museums, compelling them along with many other organizations to engage with audiences online and to go beyond traditional 'material culture', where stories are told through objects, to find new ways to inform audiences about the threat posed by this invisible enemy and the scientific response. To reflect the greatest global health crisis in a generation, the five museums that form the Science Museum Group have launched their largest ever collecting project, which has acquired the first doses of COVID vaccine given in the UK, testing kits and the signs used in government briefings among many other things. The Group has hosted a series of well-attended virtual events, involving leading figures such as Anthony Fauci, chief medical advisor to the President of the United States of America; Sarah Gilbert of the Jenner Institute, University of Oxford; Kate Bingham former chair of the UK Government's Vaccine Taskforce; and Chris Whitty [4], Chief Medical Officer to England. The Group has published more than 120 000 words about COVID-19 in blogs that aimed to share the latest expert knowledge with the public on a range of themes, from the use of organoids [5] and AI [6] to the rollout of vaccines [7]. The Science Museum itself hosted the world's first Global Vaccine Confidence Summit and an NHS vaccination centre [8], where thousands of people were inoculated, including the Health Secretary and the Duke and Duchess of Cambridge. The group is now working on an exhibition about the hunt for an effective COVID-19 vaccine with the National Museums of Scotland, National Council of Science Museums India, and the Guangdong Science Centre and its network in China. Both this journal and the museums act as a melting pot for ideas. One focus on this issue is the interface between the pandemic, policy and the machinery of government, which has been a preoccupation for millennia: Cicero was prompted to remark, Salus populi suprema lex esto ('The health (welfare, good, salvation, felicity) of the people should be the supreme law'). In his contribution along these lines to this issue of Interface Focus, Chris Whitty, Chief Medical Officer, and Luke Collet-Fenson examine what COVID-19 can tell us about formal and informal science advice in emergencies, and the tensions that emerge, notably between comprehensive advice that has been rigorously tested against speed, along with striking the right balance between taking on board diverse views and groupthink. Adapting the existing structures of scientific advice is more effective than creating new ones in an emergency and, while a final judgement of the UK scientific response will take time, and that judgement is likely to evolve, they argue that everyone should be grateful to the thousands of scientists involved in the pandemic effort. Philip Ball takes a more critical view, showing how the COVID-19 pandemic has highlighted—as never before—how science works and the ways in which science interacts with policymaking and with society [9]. He notes that how well a country has fared in avoiding illness and fatalities is, roughly speaking, uncorrelated with either its wealth or its scientific strength. There are lessons for scientists and politicians, he concludes, and the latter should acknowledge that scientific advice is likely to be more effective when it is genuinely independent, autonomous and transparent. One draconian aspect of government responses—stay at home orders—is examined by Toby Phillips, Yuxi Zhang and Anna Petherick [10]. Drawing on data from the Oxford COVID-19 Government Response Tracker, they reveal three broad trends in their use of non-pharmaceutical interventions in the first year that pose questions about the extent to which pandemic management depends on early decisions. They conclude that seeking to make sense of tendencies in non-pharmaceutical intervention adoption, while vaccination programmes spread globally gradually and inconsistently, could assist policymakers in making better decisions to overcome this and future global health crises. Fiona Watt, who is the Executive Chair of the UK's Medical Research Council, with Patrick Chinnery, Jonathan Pearce, Anna Kinsey, Joanna Jenkinson and Glenn Wells, look back at how UK government support for COVID-19 medical research evolved. This was primed by previous experience with Ebola and Zika, beginning with the early calls for proposals in February 2020 that 'pump-primed' funding for vaccines and therapeutics, and culminating in the launch of the government's National Core Studies programme in October. They discuss how the research community mobilized to submit and review grants more rapidly than ever before, despite laboratory and office closures caused by the pandemic, and highlight the challenges of running clinical trials as the number of hospitalized patients fluctuated with different waves of the disease. The pandemic response has already left an important legacy, which ranges from a UK vaccines manufacturing capacity to a helpful blurring of interests in those in applied and discovery medical research. Like Watt et al. [11] Jim Smith and David Goodhew [12] argue that the urgency and focus imposed by COVID-19 prompted funders to become nimble and also benefited from a 'seed corn' of discovery science, from the basis for routine diagnostic tests to the development of vaccines [11]. The speed of dissemination of research has benefitted from the widespread use of pre-prints, such as from bioRvix and medRxiv, which present an open and rapid way to share pre-peer reviewed studies. But the advice provided to schools on the basis of this research was, however, often published at the last minute, flawed or inconsistent. Their report concludes: 'Must do better'. One issue of contention early in the pandemic was the effectiveness of face coverings given the lack of evidence from randomized control trials. Lydia Bourouiba, Katherine Randall, E. T. Ewing, Linsey Marr and Jose Jimenez explore how the pandemic exposed major gaps in our understanding of the transmission of viruses through the air which slowed recognition of airborne transmission of COVID-19 and contributed to muddled public health policies and messaging [13]. They revisit the past to highlight potential future solutions and argue the importance of using a historical perspective to help design more resilient, far-sighted and effective public health policies. In the light of the debate about the effectiveness of face coverings, Trish Greenhalgh [14] examines how mental models have sometimes facilitated the thinking of scientists and other times been a hinderance. The latter occurred in the case of COVID-19 when undue emphasis was initially placed on randomized control trials, which were inconclusive at the start of the pandemic, when it was also believed that the disease was spread by respiratory droplets. By June 2020, more than 200 aerosol scientists argued that mechanistic evidence had demonstrated 'beyond any reasonable doubt' that the SARS-CoV-2 virus is carried long distances by microdroplets. Models and empirical thinking are complementary but, by not fully appreciating how they work hand in glove, scientists and policymakers initially favoured experimental evidence over theory based on mechanistic insights, rejecting the use of face coverings. In particular, the World Health Organization was sluggish to respond to emerging evidence. As a result, lives were lost. The successful development of COVID-19 vaccines has outpaced the production of antiviral drugs. There is a bottleneck when screening vast numbers of potential small molecules (ranging from a few hundred million to billions) to shortlist lead compounds for COVID-19 antiviral drug development. To overcome this hurdle, I discuss with Peter Coveney and colleagues [15] from a diverse and international range of institutions how to use a judicious combination of in silico theory-led modelling with AI methods that rely on big data [16]. At the interface between AI, in the form of machine learning methods, and physics-based methodology, each compensates for the weaknesses of the other. Together they offer a way to reform the drug discovery process, which is expensive, inefficient and slow, to deliver pandemic drugs at pandemic speed. Aside from the direct impact of the pandemic, there has been considerable speculation regarding how people coped with the health crisis, and to what extent. Adam Hampshire, Peter Hellyer, William Trender and Samuel Chamberlain describe an unbiased approach that learns from people's collective lived experiences through the application of AI in the form of natural-language processing of free-text reports [17]. Based on an analysis of texts about impact and means of coping from more than 50 000 UK individuals in the first lockdown, they concluded that 45 topics were required to optimally summarize practical coping strategies that they recommended, and that the relevance of the topics could be predicted from population variables such as age. They propose this kind of methodology, which is both inclusive and neutral, may help inform public health strategies and individually tailored interventions. The pandemic has led to significant changes in daily routines and lifestyle worldwide and, aside from resulting mental health issues, there have been reports of sleep disturbances in the general population during lockdowns. Circadian misalignment and sleep disruption have a profound impact on immune function and subsequently, the ability of individuals to combat infections. Xiaodong Zhuang, Zulian Liu and Sharlene Ting [18] summarize the evidence on the interplay between circadian biology, sleep and COVID-19 with the aims to identify areas of translational potentials—such as the optimum time to deliver drugs or vaccines, along with improving sleep quality—that may inform diagnostic and therapeutic strategies. This issue of Interface Focus also ponders the lessons of previous pandemics for COVID-19. Infectious diseases have wreaked havoc on human communities since ancient times, shaping society as deeply and surely as revolution, war and economic crashes [19]. Past pandemics always pose questions about how we should act in future. Katie Dabin examines what the COVID-19 project is telling us about the impact of COVID-19 on cancer research and the collateral damage of the latest outbreak on future care [20]. She focuses on cancer treatment and research that will be featured in a new exhibition opening in October 2021, Cancer Revolution: Science, Innovation and Hope, at the Science and Industry Museum in Manchester. The exhibition has been updated despite COVID-19 restrictions to include stories and perspectives about the impact of the pandemic on individuals, health services and in research. The response to both underlines the necessity of global, collaborative research and the altruism of patients willing to participate in research—even when they might not experience the benefit of it themselves. Humans are, after all, the most cooperative species of all [21]. Natasha McEnroe and Stewart Emmens [22] describe the challenges faced by curators of the history of medicine when trying to collect and preserve objects that convey the impacts of COVID-19 while in the grip of the pandemic. As the gap between events and collecting has closed, with the rise of so-called 'rapid response' collecting, they also ask if it has become more subject to the whims and interests of the curator. Collecting in these challenging circumstances can also highlight existing issues, notably how to collect digital material, which ranges from apps and tweets to emails, pandemic modelling software and satirical social media. Museum collections can provide important context. McEnroe and Emmens examine why the 1918–1919 influenza pandemic left behind so little material culture, in contrast with polio and tuberculosis. Perhaps this reflects how people did not want to be reminded of the trauma and death, perhaps much of the equipment continued to be used, or perhaps it was thought highly infectious, and discarded. Britain a century ago mounted a relatively ineffectual response and Mark Honigsbaum argues there is a parallel in the way that in early 2020, as in 1918, medical professionals, and public health administrators, commentators and government advisors and politicians deprecated the severity of the coronavirus outbreak and, rather than screen travellers at the border and introduce community testing and rigorous contact tracing and quarantines, advised individuals with symptoms of coronavirus infection to self-isolate at home [23]: 'Why this was the case will keep historians and committees of inquiry occupied for years'. He talks of a collective failure of imagination when it comes to envisaging how quickly our world could be thrown into turmoil by a new pandemic virus. Though modelling is a crystal ball, often its vision can be cracked and clouded by incomplete data and understanding. Roy Anderson, Carolin Vegvari, Deirdre Hollingsworth, Li Pi, Rosie Maddren, Chi Wai Ng and Rebecca Baggaley examine how modelling has fared in the pandemic, where uncertainties remain in key areas such as the determinants of what predisposes to asymptomatic infection, what population fraction is asymptomatic, what is the infectiousness of such individuals, compared to those with symptoms, and how these are influenced by various variables [24]. They point out that, given the high transmissibility of the Delta variant which has spread rapidly worldwide, and in the light of data on breakthrough infections in a small proportion of vaccinated individuals, the concept of a target level of herd immunity by vaccination is no longer valid. To eradicate transmission, 100% of large populations would have to be effectively immunized to prevent continued transmission and the logistics required to achieve universal coverage are daunting, even in countries with robust healthcare infrastructure. More support from the richer nations is needed in resource poor settings since unvaccinated populations create opportunities for viral evolution. Christl Donnelly and Ruth McCabe explore a key detail of the interface between science and society in the COVID-19 era by examining the development, communication and influence of mathematical transmission modelling to explore the public health impacts of the pandemic, and how to mitigate them with lockdowns and other interventions [25]. Unusually, as well as reviewing the models themselves, they draw on the opinions and experiences of modellers, scientific advisers, such as attendees of SAGE, SPI-M and comparable advisory bodies during the pandemic, and experts in science communication in the UK to explore and understand the complex relationships between models, decision-making, the media, and the public. The study highlights the desire for increased two-way communication between these players, not least in conveying the extent to which the crystal ball of modelling is cracked. Complementing the points made by Whitty and Collet-Fenson, they point out how scientists must ensure that their models are of the highest scientific quality while also acknowledging their inherent limitations and the urgent need for results, while decision-makers must understand the nuances of underlying results and in the context of all other evidence. The use of computer models to gaze into the future leads to the final theme of this issue of Interface Focus: how to visualize COVID-19, and the possible course of the pandemic by revealing the invisible worlds of the virus itself, along with how to envisage pandemic possibilities through the literature of science fiction. Beginning with the former, Katy Barrett and Geoff Belknap [26] consider the history of image-making in medicine to trace how images have provided the means for discovery, for description and for diagnosis of disease and how these image-making practices are reflected in work to identify and visualize the Covid-19 virus in 2020–2021. They outline the different ways in which diseases have been located in the history of the medical image: in the community, in the body, in the cell, and on the image itself. Starting from a contemporary art commission in the Science Museum's 'Medicine: The Wellcome Galleries', they explore five examples of iconic medical images, by John Snow, Florence Nightingale, Arthur Schuster, and Donald Caspar and Aaron Klug, ending with a model of the coronavirus created by the MRC Laboratory of Molecular Biology in Cambridge. The latter underlines how one of the most striking visual results of the pandemic has been the coronavirus itself, whether in watercolours, or digitally, or in the form of a glass sculpture, the SARS-CoV-2 crown of spikes is now part of popular visual culture appearing in cartoons, artworks and even as an emoji. As they remark, no previous virus or disease has gained such visual currency as an image of the agent of pestilence and death. Images of the virus have also benefitted from the maturation of a form of electron microscopy (EM). Kendra E. Leigh & Yorgo Modis [27] describe how the SARS-CoV-2 pandemic struck when recent advances in microscope hardware and analysis software, particularly in cryo-EM and cryo-electron tomography, have opened a new era in structural biology, making many previously intractable targets amenable to visualization to accelerate efforts to create COVID-19 vaccines and therapeutics. One example is illustrated by how structures of the spike (S) glycoprotein of SARS-CoV-2 were available in March 2020, only a few months after the sequencing of the new virus. The spike structures underpinned the analysis of the effects of mutations, such as those shown by studies of other coronaviruses to improve immunogenicity, which could be used to hone SARS-CoV-2 vaccine formulations. Given the expectation of future pandemics given changes in land use, [28] they call for the momentum of this field to be sustained. Finally, Glyn Morgan discusses how, in these unprecedented times, people turn to fiction as both a comforting distraction and a means to make sense of what lurks around the corner [29]. Fiction about pandemics and other disease outbreaks surged in 2020 and his survey of the long history of science fiction's engagement with disease demonstrates the ways in which these narratives, whether in literature or film, reflect contemporary cultural concerns. Ultimately, by portraying alternative worlds and possible futures, Morgan argues that science fiction can offer a 'creative space' to prompt new ways to think and learn. We need this space because it does not take a pandemic long to change the world: the time between the first international reports of a completely new infection, COVID-19, and the first UK wave was less than 12 weeks. Museums can provide fresh perspectives on culture because they lie at the nexus of science, industry, the public and government, along with heritage, history, contemporary research and the future. In a similar way, this themed issue is a reminder that the most intriguing and thought-provoking insights often emerge at the interface between different disciplines, different eras, even different worlds. Data accessibility This article has no additional data. Competing interests The author is a member of the Medical Research Council and holds visiting professorships at the Dunn School, University of Oxford, and Department of Chemistry, University College London. Funding I received no funding for this study. Acknowledgements With thanks to my Science Museum colleagues: Tilly Blyth, Head of Collections and Principal Curator, Natasha McEnroe, Keeper of Medicine and assistant Katie Dowler, for their help and advice on this issue. FootnotesOne contribution of 19 to a theme issue 'COVID-19: science, history, culture and imagination'. © 2021 The Authors. Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the original author and source are credited. References1. Morris PJT. 2010 Science for the nation: perspectives on the history of the Science Museum. London, UK: Palgrave Macmillan. Crossref, Google Scholar2. Arnold K, Olsen D. 2020 Contagious cities. Sci. Mus. Gr. J. 14, 10.15180; 201404. (doi:10.15180/201405) Google Scholar3. Blatchford I. 2021 Vaccination and the Victorians: Lyon Playfair's battle for science. Science Museum Blog. https://blog.sciencemuseum.org.uk/vaccination-and-the-victorians-lyon-playfairs-battle-for-science/. Google Scholar4. Whitty CJM, Collet-Fenson LB. 2021 Formal and informal science advice in emergencies: COVID-19 in the UK. Interface Focus 11, 20210059. (doi:10.1098/rsfs.2021.0059) Link, ISI, Google Scholar5. Highfield R. 2020 Coronavirus: rise of mini-organs. Science Museum Group Blog. https://www.sciencemuseumgroup.org.uk/blog/coronavirus-rise-of-mini-organs/. Google Scholar6. Highfield R. 2020 Coronavirus: can AI solve future pandemics? Science Museum Group Blog. https://www.sciencemuseumgroup.org.uk/blog/coronavirus-can-ai-solve-future-pandemics/. Google Scholar7. Highfield R. 2021 Coronavirus: how to vaccinate a nation. Science Museum Group Blog. https://www.sciencemuseumgroup.org.uk/blog/coronavirus-how-to-vaccinate-a-nation/. Google Scholar8. Science Museum. 2021 Science Museum vaccination centre. https://www.sciencemuseum.org.uk/science-museum-vaccination-centre. Google Scholar9. Ball P. 2021 What the COVID-19 pandemic reveals about science, policy and society. Interface Focus 11, 20210022. (doi:10.1098/rsfs.2021.0022) Link, ISI, Google Scholar10. Phillips T, Zhang Y, Petherick A. 2021 A year of living distantly: global trends in the use of stay-at-home orders over the first 12 months of the COVID-19 pandemic. Interface Focus 11, 20210041. (doi:10.1098/rsfs.2021.0041) Link, ISI, Google Scholar11. Chinnery PF, Pearce JJ, Kinsey AM, Jenkinson JM, Wells G, Watt FM. 2021 How COVID-19 has changed medical research funding. Interface Focus 11, 20210025. (doi:10.1098/rsfs.2021.0025) Link, ISI, Google Scholar12. Smith JC, Goodhew DW. 2021 Personal observations on COVID-19 and the conduct and application of biomedical science. Interface Focus 11, 20210053. (doi:10.1098/rsfs.2021.0053) Link, ISI, Google Scholar13. Randall K, Ewing ET, Marr LC, Jimenez JL, Bourouiba L. 2021 How did we get here: what are droplets and aerosols and how far do they go? A historical perspective on the transmission of respiratory infectious diseases. Interface Focus 11, 20210049. (doi:10.1098/rsfs.2021.0049) Link, ISI, Google Scholar14. Greenhalgh T. 2021 Miasmas, mental models and preventive public health: some philosophical reflections on science in the COVID-19 pandemic. Interface Focus 11, 20210017. (doi:10.1098/rsfs.2021.0017) Link, ISI, Google Scholar15. Bhati AP et al.. 2021 Pandemic drugs at pandemic speed: infrastructure for accelerating COVID-19 drug discovery with hybrid machine learning- and physics-based simulations on high performance computers. Interface Focus 11, 20210018. (doi:10.1098/rsfs.2021.0018) Link, ISI, Google Scholar16. Coveney PV, Dougherty ER, Highfield RR. 2016 Big data need big theory too. Phil. Trans. R. Soc. A 374, 20160153. (doi:10.1098/rsta.2016.0153) Link, ISI, Google Scholar17. Hampshire A, Hellyer PJ, Trender W, Chamberlain SR. 2021 Insights into the impact on daily life of the Covid-19 pandemic and effective coping strategies from free text analysis of people's collective experiences. Interface Focus 11, 20210051. (doi:10.1098/rsfs.2021.0051) Link, ISI, Google Scholar18. Liu Z, Ting S, Zhuang X. 2021 COVID-19, circadian rhythms and sleep: from virology to chronobiology. Interface Focus 11, 20210043. (doi:10.1098/rsfs.2021.0043) Link, ISI, Google Scholar19. Snowden FM. 2019 Epidemics and society. New Haven, CT: Yale University Press. Crossref, Google Scholar20. Dabin K. 2021 Our mutual friends: cancer research in a time of COVID-19. Interface Focus 11, 20210052. (doi:10.1098/rsfs.2021.0052) Link, ISI, Google Scholar21. Nowak MA, Highfield R. 2011 Supercooperators: altruism, evolution, and why we need each other to succeed. New York, NY: Free Press. Google Scholar22. Emmens S, McEnroe N. 2021 Acquiring infection: the challenges of collecting epidemics and pandemics, past, present and future. Interface Focus 11, 20210030. (doi:10.1098/rsfs.2021.0030) Link, ISI, Google Scholar23. Honigsbaum M. 2021 Imagining pandemics now, and then: a century of medical failure. Interface Focus 11, 20210029. (doi:10.1098/rsfs.2021.0029) Link, ISI, Google Scholar24. Anderson RM, Vegvari C, Hollingsworth TD, Pi L, Maddren R, Ng CW, Baggaley RF. 2021 The SARS-CoV-2 pandemic: remaining uncertainties in our understanding of the epidemiology and transmission dynamics of the virus, and challenges to be overcome Interface Focus 11, 20210008. (doi:10.1098/rsfs.2021.0008) Link, ISI, Google Scholar25. McCabe R, Donnelly CA. 2021 Disease transmission and control modelling at the science–policy interface. Interface Focus 11, 20210013. (doi:10.1098/rsfs.2021.0013) Link, ISI, Google Scholar26. Barrett K, Belknap G. 2021 Locating disease spread: cholera to coronavirus and the art of the image. Interface Focus 11, 20210014. (doi:10.1098/rsfs.2021.0014) Link, ISI, Google Scholar27. Leigh KE, Modis Y. 2021 Imaging and visualizing SARS-CoV-2 in a new era for structural biology. Interface Focus 11, 20210019. (doi:10.1098/rsfs.2021.0019) Link, ISI, Google Scholar28. Gibb R et al.. 2020 Zoonotic host diversity increases in human-dominated ecosystems. Nature 584, 398-402. (doi:10.1038/s41586-020-2562-8) Crossref, PubMed, ISI, Google Scholar29. Morgan G. 2021 New ways: the pandemics of science fiction. Interface Focus 11, 20210027. (doi:10.1098/rsfs.2021.0027) Link, ISI, Google Scholar Next Article VIEW FULL TEXT DOWNLOAD PDF FiguresRelatedReferencesDetails This Issue06 December 2021Volume 11Issue 6Theme issue 'COVID-19: science, history, culture and imagination' organised by Roger Highfield Article InformationDOI:https://doi.org/10.1098/rsfs.2021.0070Published by:Royal SocietyOnline ISSN:2042-8901History: Manuscript accepted10/09/2021Published online12/10/2021 License:© 2021 The Authors.Published by the Royal Society under the terms of the Creative Commons Attribution License http://creativecommons.org/licenses/by/4.0/, which permits unrestricted use, provided the original author and source are credited. Citations and impact Subjectsmedical physics","",https://doi.org/10.1098/rsfs.2021.0070,"",,
rayyan-210805503,HumAID: Human-Annotated Disaster Incidents Data from Twitter with Deep Learning Benchmarks,,1,1,,,,,,,,en,,,"Social networks are widely used for information consumption and dissemination, especially during time-critical events such as natural disasters. Despite its significantly large volume, social media content is often too noisy for direct use in any application. Therefore, it is important to filter, categorize, and concisely summarize the available content to facilitate effective consumption and decision-making. To address such issues automatic classification systems have been developed using supervised modeling approaches, thanks to the earlier efforts on creating labeled datasets. However, existing datasets are limited in different aspects (e.g., size, contains duplicates) and less suitable to support more advanced and data-hungry deep learning models. In this paper, we present a new large-scale dataset with ~77K human-labeled tweets, sampled from a pool of ~24 million tweets across 19 disaster events that happened between 2016 and 2019. Moreover, we propose a data collection and sampling pipeline, which is important for social media data sampling for human annotation. We report multiclass classification results using classic and deep learning (fastText and transformer) based models to set the ground for future studies. The dataset and associated resources are publicly available. https://crisisnlp.qcri.org/humaid_dataset.html","",https://doi.org/10.48550/arxiv.2104.03090,"",,
rayyan-210807609,Near-Real-Time Seismic Human Fatality Information Retrieval from Social Media with Few-Shot Large-Language Models,,1,1,,,,,,,,en,,,"Real-time disaster-induced human fatality information is critical for rapid and accurate disaster impact and loss estimation and effective emergency response. Systems like PAGER incorporate online reported death tolls and loss projection models trained on significant historical earthquake events and ground shaking data to provide projected final seismic loss estimations. However, the input reported death toll data are mainly retrieved from news platforms manually, which is time-consuming and may have a large time bias. In recent years, platforms such as Facebook and Twitter have become hot spots for witness reporting and communication during disaster events, producing large volumes of immediate fatality information without the hindrances of official channels. Though lucrative, social media data is very noisy both in syntax and accuracy, necessitating robust solutions. In this work, we design and deploy a new online system that automatically extracts near-realtime multi-lingual human fatality information including death tolls and injury tolls, from a variety of information sources immediately after an earthquake occurs. Past studies have proposed to use popular machine learning methods such as SVMs, CNNs and Logistic Regression in conjunction with word embeddings to classify the relevancy of each social media message. However, these techniques suffer from impeding requirements of annotated data, which are unavailable at the onset of natural disasters, and cannot directly extract disaster information, instead relying on statistical analysis on their classification results. To address such challenges, we propose a Large Language Model-based approach that leverages its robust language understanding and few-shot learning abilities. In combination with our novel multilingual Hierarchical Event Classifier, another contribution, we achieve effective automatic earthquake casualty information retrieval from social media, which we test by deploying our framework to two recent earthquakes.","",https://doi.org/10.1145/3560905.3568431,"",,
rayyan-210807710,Sentimental wildfire: a social-physics machine learning model for wildfire nowcasting,,1,1,,,,,,,,en,,,"Abstract The intensity of wildfires and wildfire season length is increasing due to climate change, causing a greater threat to the local population. Much of this population are increasingly adopting social media, and sites like Twitter are increasingly being used as a real-time human-sensor network during natural disasters; detecting, tracking and documenting events. The human-sensor concept is currently largely omitted by wildfire models, representing a potential loss of information. By including Twitter data as a source in our models, we aim to help disaster managers make more informed, socially driven decisions, by detecting and monitoring online social media sentiment over the course of a wildfire event. This paper implements machine learning in a wildfire prediction model, using social media and geophysical data sources with Sentiment Analysis to predict wildfire characteristics with high accuracy. We also use wildfire-specific attributes to predict online social dynamics, as this has been shown to be indicative of localised disaster severity. This may be useful for disaster management teams in identifying areas of immediate danger. We combine geophysical satellite data from the Global Fire Atlas with social data provided by Twitter. We perform data collection and subsequent analysis &amp; visualisation, and compare regional differences in online social sentiment expression. Following this, we compare and contrast different machine learning models for predicting wildfire attributes. We demonstrate social media is a predictor of wildfire activity, and present models which accurately model wildfire attributes. This work develops the concept of the human sensor in the context of wildfires, using users’ Tweets as noisy subjective sentimental accounts of current localised conditions. This work contributes to the development of more socially conscious wildfire models, by incorporating social media data into wildfire prediction and modelling.","",https://doi.org/10.1007/s42001-022-00174-8,"",,
rayyan-210812900,Mining Public Opinion on Twitter about Natural Disaster Response Using Machine Learning Techniques.,,1,1,,,,,,,,en,,,"With the development of the Internet, social media has become an essential channel for posting disaster-related information. Analyzing attitudes hidden in these texts, known as sentiment analysis, is crucial for the government or relief agencies to improve disaster response efficiency, but it has not received sufficient attention. This paper aims to fill this gap by focusing on investigating public attitudes towards disaster response and analyzing targeted relief supplies during disaster relief. The research comprises four steps. First, this paper implements Python in grasping Twitter data, and then, we assess public perceptron quantitatively by these opinioned texts, which contain information like the demand for targeted relief supplies, satisfactions of disaster response and fear of the public. A natural disaster dataset with sentiment labels is created, which contains 49,816 Twitter data about natural disasters in the United States. Second, this paper proposes eight machine learning models for sentiment prediction, which are the most popular models used in classification problems. Third, the comparison of these models is conducted via various metrics, and this paper also discusses the optimization method of these models from the perspective of model parameters and input data structures. Finally, a set of real-world instances are studied from the perspective of analyzing changes of public opinion during different natural disasters and understanding the relationship between the same hazard and time series. Results in this paper demonstrate the feasibility and validation of the proposed research approach and provide relief agencies with insights into better disaster response.","",,"",,
rayyan-210813125,Natural Hazards Twitter Dataset,,1,1,,,,,,,,en,,,"With the development of the Internet, social media has become an important channel for posting disaster-related information. Analyzing attitudes hidden in these texts, known as sentiment analysis, is crucial for the government or relief agencies to improve disaster response efficiency, but it has not received sufficient attention. This paper aims to fill this gap by focusing on investigating attitudes towards disaster response and analyzing targeted relief supplies during disaster response. The contributions of this paper are fourfold. First, we propose several machine learning models for classifying public sentiment concerning disaster-related social media data. Second, we create a natural disaster dataset with sentiment labels, which contains nearly 50,00 Twitter data about different natural disasters in the United States (e.g., a tornado in 2011, a hurricane named Sandy in 2012, a series of floods in 2013, a hurricane named Matthew in 2016, a blizzard in 2016, a hurricane named Harvey in 2017, a hurricane named Michael in 2018, a series of wildfires in 2018, and a hurricane named Dorian in 2019). We are making our dataset available to the research community: this https URL. It is our hope that our contribution will enable the study of sentiment analysis in disaster response. Third, we focus on extracting public attitudes and analyzing the essential needs (e.g., food, housing, transportation, and medical supplies) for the public during disaster response, instead of merely targeting on studying positive or negative attitudes of the public to natural disasters. Fourth, we conduct this research from two different dimensions for a comprehensive understanding of public opinion on disaster response, since disparate hazards caused by different types of natural disasters.","",,"",,
rayyan-210813146,Conspiracy in the Time of Corona: Automatic detection of Covid-19 Conspiracy Theories in Social Media and the News,,1,1,,,,,,,,en,,,"Rumors and conspiracy theories thrive in environments of low confidence and low trust. Consequently, it is not surprising that ones related to the Covid-19 pandemic are proliferating given the lack of any authoritative scientific consensus on the virus, its spread and containment, or on the long term social and economic ramifications of the pandemic. Among the stories currently circulating are ones suggesting that the 5G network activates the virus, that the pandemic is a hoax perpetrated by a global cabal, that the virus is a bio-weapon released deliberately by the Chinese, or that Bill Gates is using it as cover to launch a global surveillance regime. While some may be quick to dismiss these stories as having little impact on real-world behavior, recent events including the destruction of property, racially fueled attacks against Asian Americans, and demonstrations espousing resistance to public health orders countermand such conclusions. Inspired by narrative theory, we crawl social media sites and news reports and, through the application of automated machine-learning methods, discover the underlying narrative frameworks supporting the generation of these stories. We show how the various narrative frameworks fueling rumors and conspiracy theories rely on the alignment of otherwise disparate domains of knowledge, and consider how they attach to the broader reporting on the pandemic. These alignments and attachments, which can be monitored in near real-time, may be useful for identifying areas in the news that are particularly vulnerable to reinterpretation by conspiracy theorists. Understanding the dynamics of storytelling on social media and the narrative frameworks that provide the generative basis for these stories may also be helpful for devising methods to disrupt their spread.","",,"",,
rayyan-210814406,HumAID: Human-Annotated Disaster Incidents Data from Twitter,,1,1,,,,,,,,en,,,"Social networks are widely used for information consumption and dissemination, especially during time-critical events such as natural disasters. Despite its significantly large volume, social media content is often too noisy for direct use in any application. Therefore, it is important to filter, categorize, and concisely summarize the available content to facilitate effective consumption and decision-making. To address such issues automatic classification systems have been developed using supervised modeling approaches, thanks to the earlier efforts on creating labeled datasets. However, existing datasets are limited in different aspects (e.g., size, contains duplicates) and less suitable to support more advanced and data-hungry deep learning models. In this paper, we present a new large-scale dataset with ~77K human-labeled tweets, sampled from a pool of ~24 million tweets across 19 disaster events that happened between 2016 and 2019. Moreover, we propose a data collection and sampling pipeline, which is important for social media data sampling for human annotation. We report multiclass classification results using classic and deep learning (fastText and transformer) based models to set the ground for future studies. The dataset and associated resources are publicly available.\url{this https URL}","",,"",,
rayyan-210814822,Revealing hidden patterns in political news and social media with machine learning,,1,1,,,,,,,,en,,,"As part of our everyday life we consume breaking news and interpret it based on our own viewpoints and beliefs. We have easy access to online social networking platforms and news media websites, where we inform ourselves about current affairs and often post about our own views, such as in news comments or social media posts. The media ecosystem enables opinions and facts to travel from news sources to news readers, from news article commenters to other readers, from social network users to their followers, etc. The views of the world many of us have depend on the information we receive via online news and social media. Hence, it is essential to maintain accurate, reliable and objective online content to ensure democracy and verity on the Web. To this end, we contribute to a trustworthy media ecosystem by analyzing news and social media in the context of politics to ensure that media serves the public interest. In this thesis, we use text mining, natural language processing and machine learning techniques to reveal underlying patterns in political news articles and political discourse in social networks.

Mainstream news sources typically cover a great amount of the same news stories every day, but they often place them in a different context or report them from different perspectives. In this thesis, we are interested in how distinct and predictable newspaper journalists are, in the way they report the news, as a means to understand and identify their different political beliefs. To this end, we propose two models that classify text from news articles to their respective original news source, i.e., reported speech and also news comments. Our goal is to capture systematic quoting and commenting patterns by journalists and news commenters respectively, which can lead us to the newspaper where the quotes and comments are originally published. Predicting news sources can help us understand the potential subjective nature behind news storytelling and the magnitude of this phenomenon. Revealing this hidden knowledge can restore our trust in media by advancing transparency and diversity in the news.

Media bias can be expressed in various subtle ways in the text and it is often challenging to identify these bias manifestations correctly, even for humans. However, media experts, e.g., journalists, are a powerful resource that can help us overcome the vague definition of political media bias and they can also assist automatic learners to find the hidden bias in the text. Due to the enormous technological advances in artificial intelligence, we hypothesize that identifying political bias in the news could be achieved through the combination of sophisticated deep learning modelsxi and domain expertise. Therefore, our second contribution is a high-quality and reliable news dataset annotated by journalists for political bias and a state-of-the-art solution for this task based on curriculum learning. Our aim is to discover whether domain expertise is necessary for this task and to provide an automatic solution for this traditionally manually-solved problem. User generated content is fundamentally different from news articles, e.g., messages are shorter, they are often personal and opinionated, they refer to specific topics and persons, etc. Regarding political and socio-economic news, individuals in online communities make use of social networks to keep their peers up-to-date and to share their own views on ongoing affairs. We believe that social media is also an as powerful instrument for information flow as the news sources are, and we use its unique characteristic of rapid news coverage for two applications. We analyze Twitter messages and debate transcripts during live political presidential debates to automatically predict the topics that Twitter users discuss. Our goal is to discover the favoured topics in online communities on the dates of political events as a way to understand the political subjects of public interest. With the up-to-dateness of microblogs, an additional opportunity emerges, namely to use social media posts and leverage the real-time verity about discussed individuals to find their locations.
That is, given a person of interest that is mentioned in online discussions, we use the wisdom of the crowd to automatically track her physical locations over time. We evaluate our approach in the context of politics, i.e., we predict the locations of US politicians as a proof of concept for important use cases, such as to track people that
are national risks, e.g., warlords and wanted criminals.","",https://doi.org/10.25932/publishup-50273,"",,
rayyan-210815673,DisDSS 2.0: A Multi-Hazard Web-based Disaster Management System to Identify Disaster-Relevancy of a Social Media Message for Decision-Making Using Deep Learning Techniques,,1,1,,,,,,,,en,,,"&amp;lt;p&amp;gt;According to UNDRR2021, there are 389 reported disasters in 2020. Disasters claim the lives of 15,080 people, 98.4 million people are affected globally, and US171.3 billion dollars are spent on economic damage. International agreements such as the Sendai framework for disaster risk reduction encourage the use of social media to strengthen disaster risk communication. With the advent of new technologies, social media has emerged out to be an important source of information in disaster management, and there is an increase in social media activity whilst disasters. Social media is the fourth most used platform for accessing emergency information. People seek to contact family, friends and search for food, water, transportation, and shelter. &amp;lt;strong&amp;gt;During cataclysmic events, the critical information posted on social media is immersed in irrelevant information&amp;lt;/strong&amp;gt;. To assist and streamline emergency situations, staunch methodologies are required for extracting relevant information. The research study explores new-fangled deep learning methods for automatically identifying the relevancy of disaster-related social media messages. The contributions of this study are three-fold. Firstly, we present a hybrid deep learning-based framework to ameliorate the classification of disaster-related social media messages. The data is gathered from the Twitter platform, using the Search Application Programming Interface. The messages that contain information regarding the need, availability of vital resources like food, water, electricity, etc., and provide situational information are categorized into &amp;lt;em&amp;gt;relevant messages. &amp;lt;/em&amp;gt;The rest of the messages are categorized into &amp;lt;em&amp;gt;irrelevant messages. &amp;lt;/em&amp;gt;To demonstrate the applicability and effectiveness of the proposed approach, it is applied to the thunderstorm and cyclone Fani dataset. Both the disasters happened in India in 2019. Secondly, the performance of the proposed approach is compared with baseline methods, i.e., convolutional neural network, long short-term memory network, bidirectional long short-term memory network. The results of the proposed approach outperform the baseline methods. The performance of the proposed approach is evaluated using multiple metrics. The considered evaluation metrics are accuracy, precision, recall, f-score, area under receiver operating curve, area under precision-recall curve. The accurate and inaccurate classifications are shown on both the datasets. Thirdly, to incorporate our evaluated models into a working application, we extend an existing application DisDSS, which has been granted copyright invention award by Government of India. We call the newly extended system DisDSS 2.0, which integrates our framework to address the disaster relevancy identification issue. The output from the research study is helpful for disaster managers to make effective decisions on time. It bridges the gap between the decision-makers and citizens during disasters through the lens of deep learning.&amp;lt;/p&amp;gt;","",https://doi.org/10.5194/egusphere-egu22-266,"",,
rayyan-210815694,Multi-temporal deep learning-based social media analysis for disaster relief,,1,1,,,,,,,,en,,,"In recent years, using social media images to assess natural disasters and the structural damage they cause has become an increasingly prevalent research approach. Particularly, deep learning methods have enabled rapid assessment of crisis situations on the ground. As social media platforms contain firsthand accounts of these devastating instances during and after events, they provide an unprecedented opportunity for disaster relief efforts. Comparatively, for example, while satellite imagery has been previously lauded for its effective use in training deep learning models, concerns about cost of obtainment and ease of access make social media, with its multitemporal properties, potentially more useful. These computational methods provide for rapid and efficient allocation of resources and personnel, saving lives and property and minimizing economic loss. In this position paper, we discuss how social media imagery, as extracted in real time from a variety of networks, can be the most useful source of data for disaster relief when combined with machine learning and computer vision techniques, enabling effective deployment pipelines in mobile applications for use by individuals, NGOs, and local governments in disaster-prone areas.","",https://doi.org/10.1145/3498361.3538796,"",,
rayyan-210816275,Evaluation and Monitoring of the Cumbre Vieja Volcano Activity on the Island of La Palma (Canary Islands): A Machine Learning Analysis to the News Published During the Volcanic Eruption of the Year 2021,,1,1,,,,,,,,en,,,"During the last few years numerous natural disasters have been proliferating all over the planet. Many of the papers that evaluate different facets of a disaster use social networks as a source of information. In this work, and using as a source of information the press articles published during 2021 about the eruption of the Cumbre Vieja volcano on the island of La Palma (Canary Islands), we show how the emotions and sentiments expressed in a press article reflect the impact of a disaster at the time when it took place. We studied the usefulness of different classifiers combining sentiment analysis with multivariate statistical analysis techniques and machine learning. Applying this methodology we were able to classify a newspaper article within a certain time frame of the eruption, finding significant differences between local news published in Spanish and those written in English in the foreign newspapers. We also found different patterns by applying the Fourier transform to valence changes as a function of narrative time. In addition, we found a significant relationship between the surface area occupied by lava and the emotions and sentiments expressed in a newspaper article. The main findings of this research may constitute helpful resources for developing ameliorated insights into the way society react to volcanic activity, and into the manner such reaction constitute the foundation for decision-taking under different temporal horizons.","",https://doi.org/10.2139/ssrn.4292722,"",,
rayyan-210816576,Analysis of Social Media Data Using Deep Learning and NLP Method for potential use as Natural Disaster Management in Indonesia,,1,1,,,,,,,,en,,,"During the last decade, the use of social media has exploded. One of the internet's most popular and accessible social media sites is Twitter in which people can have micro-blog to post their views on any subject, called a tweet. Indonesia becomes one of country which has the most active user of social media. On the other side, Indonesia has experienced a great deal of natural disasters because it is located in a pacific ring of fire. It is needed effective disaster management used in Indonesia, especially with the help of social media data. Big data analysis obtained during turbulent and unorganized emergency situations is the perfect fit for effective management. During a disaster, it is vital to manage the proper decision to help people affected with their needs. This research investigated some methods used in social media analysis and then apply deep learning model for supervised tasks which classify the related and unrelated disasters on tweet datasets and Latent Dirichlet Allocation (LDA) for unsupervised learning which extracts the details category on the disaster Twitter data. The LSTM model architecture obtained a higher score accuracy than CNN. Moreover, the LDA topic modeling obtained potential results on the details topic from the datasets which could describe useful information to help disaster management.","",https://doi.org/10.1109/cosite60233.2023.10249849,"",,
rayyan-210816923,Role of Social Media Imagery in Disaster Informatics,,1,1,,,,,,,,en,,,"The recent literature reports several practical and important use cases of social media informatics where artificial intelligence (AI), machine learning (ML), and other relevant technologies are employed to analyze human sufferings and infrastructure damage in natural disasters. While the textual content of social media platforms conveys relevant and useful information during a disaster, social media imagery content has also been proven very effective in analyzing the scale of damage to infrastructures such as roads, bridges, and buildings. Moreover, disaster-related visual content could also be analyzed to extract people's perceptions, emotions, sentiments, and responses to disasters, which can help different stakeholders, such as humanitarian organizations and policy-makers. Assessing such aspects of disaster events requires effective and efficient image processing methods to process a large amount social media content. This chapter reviews state-of-the-art techniques and shows their utility in processing social media image streams during disaster response for a diversified set of applications. It also highlights the key applications, challenges, available shared resources (datasets and models), tasks, and future research directions. This chapter will provide a ground for future research and a good starting point for the researchers in the domain.","",https://doi.org/10.1007/978-981-16-8800-3_170-1,"",,
rayyan-210816938,MAM: Multimodel Attention Mechanism for Social Media Natural Disaster Management Tweet Classification,,1,1,,,,,,,,en,,,"People have been using social media as a category for exchanging content for decades. It has revolutionized communication and enhanced the sharing of information during emergency situations. The key features of social media are collective action, connectivity, comprehensiveness, and clarity. Consequently, it performed a significant function in natural disaster management by keeping track of and reporting disaster-related incidents. The volume and diversity of the data acquired from social media during a natural disaster pose the greatest challenge. For natural disaster management it is extremely difficult to derive actionable information from the data collected from social platforms. Various strategies have been presented in the literature to address the difficulties posed by social media for natural disaster management. The proposed work is a semi-supervised machine learning model for detecting and classifying tweets. The proposed work centre's on preparing the data by performing cleansing and various transformations, generating word embedding vectors with DistillBERT, using the vision transformer, the image model was constructed. The attention mechanism is utilized for text and image model integration. In the proposed work the data pertaining to seven distinct natural disasters, such as cyclones, floods, and earthquakes are analyzed. A novel decision diffusion technique is proposed for classifying them into informative and non-informative groups and evaluating the accuracy of the results. The MAM model increases the accuracy to 97% for crisisMMD dataset.","",https://doi.org/10.1109/aiccsa59173.2023.10479344,"",,
rayyan-210817502,Role of Social Media Imagery in Disaster Informatics,,1,1,,,,,,,,en,,,"The recent literature reports several practical and important use cases of social media informatics where artificial intelligence (AI), machine learning (ML), and other relevant technologies are employed to analyze human sufferings and infrastructure damage in natural disasters. While the textual content of social media platforms conveys relevant and useful information during a disaster, social media imagery content has also been proven very effective in analyzing the scale of damage to infrastructures such as roads, bridges, and buildings. Moreover, disaster-related visual content could also be analyzed to extract people's perceptions, emotions, sentiments, and responses to disasters, which can help different stakeholders, such as humanitarian organizations and policy-makers. Assessing such aspects of disaster events requires effective and efficient image processing methods to process a large amount social media content. This chapter reviews state-of-the-art techniques and shows their utility in processing social media image streams during disaster response for a diversified set of applications. It also highlights the key applications, challenges, available shared resources (datasets and models), tasks, and future research directions. This chapter will provide a ground for future research and a good starting point for the researchers in the domain.","",https://doi.org/10.1007/978-981-19-8388-7_170,"",,
