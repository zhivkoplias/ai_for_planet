id,openalexid,primary_topic,doi,title,abstract,AI_gen_key_words,AI_gen,Is_key_words,Is_gen
https://openalex.org/W1528805538,W1528805538,,https://doi.org/10.1609/aiide.v10i1.12721,Emotion-Based Interactive Storytelling with Artificial Intelligence,"Artificial Intelligence (AI) techniques have been widely used in video games to control non-playable characters. More recently, AI has been applied to automated story generation and game-mastering: managing the player’s experience in an interactive narrative on-the-fly. Such methods allow the narrative to be generated dynamically, in response to the player’s in-game actions. As a result, it is more difficult for the human game designers to ensure that each possible narrative trajectory will elicit desired emotional response from the player. We tackle this problem by computationally predicting the player’s emotional response to a narrative segment. We use the predictions within an AI experience manager to shape the narrative dynamically during the game to keep the player on an author-supplied target emotional curve.",[],Other,N/A,N/A
https://openalex.org/W1797455416,W1797455416,,https://doi.org/10.54941/ahfe100330,From ICT-Machine Determinism to a Socio-ICT Organic Design of Knowledge Sharing Systems,"The transfer of knowledge between individuals, groups, practices, communities or systems is regarded as Knowledge Sharing (KS) in organizations. Research suggests that understanding social interaction between different interest groups within an organization is a critical component of effective KS. The relevance of social interaction approach has been debated in areas such as systems design, organizational process redesign, process improvement and artificial intelligence. Organizational science literature also highlights that information and communications technology (ICT) network structures provide insight about the communication patterns of individuals working in an organization. Therefore, an understanding of the ICT networks at play needs to be viewed as an essential element of the design of KS systems in organizations. We posit Mechorganics in terms of ‘the synergistic combination of civil mechanical systems engineering, social network dynamics, ICT and the management of interconnected knowledge, information (and data) infrastructures in the designing and composing of adaptive (resilient and sustainable) organizations’. It is further suggested that organization structures have both a formal and informal structure that may be considered to be a coalition of individuals, with implications for methods of communication and collective decision-making and taking, In this paper, we provide a background to organization as a network of people.",['Foundation Models'],New Generation of AI,0,0
https://openalex.org/W2217278910,W2217278910,,https://doi.org/10.31838/ijpr/2020.12.01.223,Intelligent Traffic Management System,"Urbanization has presented opportunities of progress which has attracted people from rural areas to the cities thus leading to mass migration. This migration has been going on for decades all around the globe and has reached a point of saturation. The area of the city remains the same but the population density has increased multiple times. Commuting for work is a scene of chaos on the roads. Though there are modes of public transport, roadway is the major mode of commute and the load on roadways is ever increasing due to the rise in population. There is hardly any scope to expand the area of the roadways. The rise in the number of vehicles each year has saturated the capacity the roads were built to carry. This leads to congestion and long hours of traffic on a daily basis which tests the patience of citizens. This provokes the daily commuters to violate the traffic rules which may sometimes amount to grave accidents. Even on Highways, the empty roads entice drivers to experience the thrill of speed overlooking the fact that they are putting themselves at risk. There have been regulations imposed to reduce the chance of an accidents by implementing rules and levying heavy fines on traffic violations. Traffic cameras have been installed all around the city to monitor for traffic violations and get hold of violators. With the technological advancements to store and process large chunks of data efficiently using techniques like Deep Learning and Computer Vision, this paper proposes an automated system to detect Traffic Violations using YOLOv3 to detect and track vehicles and save a snapshot in case a violation is committed.",['YOLOv3'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W2225093001,W2225093001,,https://doi.org/10.1609/aiide.v9i1.12684,Evaluating Planning-Based Experience Managers for Agency and Fun in Text-Based Interactive Narrative,"Artificial intelligence (AI) techniques have been applied to video games to make the overall experience more enjoyable. In games with interactive storytelling (IS), player actions can substantially affect plot events and plot characters. Therefore, AI planning techniques have been used to shape the plot inresponse to player actions that conflict with authorial goals. While such methods are poised to increase player fun andagency, two recent implementations (ASD and PAST) have not been formally evaluated to date. In this paper we do so via a series of user studies for the first time. We show that ASD significantly enhances fun and agency, whereas PAST gets mixed results with an interaction between effects of the experience manager and player prior gaming experience in one user study, and marginally significant results for increased agency in a study with a constrained story domain.",['AI planning techniques'],Other,1,1
https://openalex.org/W2409918409,W2409918409,,https://doi.org/10.18260/1-2--2880,A Real Introduction To Engineering And Biotechnology,"Abstract NOTE: The first page of text has been automatically extracted and included below in lieu of an abstract A Real Introduction to Engineering and Biotechnology Abstract We have developed a unique section of the required Freshman Introduction to Engineering course for the College of Engineering, University of Michigan, Ann Arbor: Biotechnology and Human Values. Our course is predicated on the assumptions that a meaningful introduction to Biomedical Engineering and biotechnology includes 1. solving problems for a real client, 2. exploring the leading edges of the field, and 3. learning strategies to solve novel problems. Our challenge has been to turn teenagers straight out of high school into individuals with a real appreciation, based on experience, of what it takes to be an engineer. To this end, the course is organized as a company, Blue Genes Research and Development, and our students are formed into project teams, each assigned to a client, a specialist physician at the University of Michigan Hospitals. Each team must work with the physician to develop a diagnostic test to detect a disease before the onset of symptoms. Course material emphasizes the fundamental doctrines of systems biology, the central role of quantification in design and validation, and the economic, legal, social and ethical implications of our technology. In class, students explore basic sciences and emerging diagnostic technologies for genetic disease, including lab-on-a-chip, gene chip, and MRI imaging. Students receive hands on experience through lab modules dealing with genetic sequencing and molecular imaging of proteins. In addition, students receive formal instruction in technical communications, and problem solving strategies, including brain- storming and research organization. Performance on an individual and team basis is evaluated through a series of homework sets, exams, lab reports, journals, team minutes, and oral project reports, in addition to a final formal report prepared for the client. As students attest, this course stretches them, but the experience with their clients encourages them to perform beyond their own expectations and also provides them with invaluable confidence in their ability to tackle new challenges. Introduction Biotechnology and Human Values, one section of the Introduction to Engineering course required of all incoming College of Engineering freshmen at the University of Michigan, Ann Arbor, was originally designed and developed by Matthew O’Donnell, former chair of the Biomedical Engineering Department, under a Life Sciences Grant. The pilot for this course was initially taught by two instructors - lead engineer, Prof. O’Donnell, and a co-lead in technical communications, Mimi Adam. Over time, the course expanded to include two wet labs under the lead of Dr. Robert Sulewski, a technical communication instructor with background in pharmacology and public health. At the conclusion of the 3 year grant, Dr. Rachael Schmedlen was recruited to assume the position of lead engineering instructor and has continued to develop and refine the course together with the instructional team. Although the Introduction to Engineering course has undergone a number of evolutionary cycles, in its present form it is a project based, experiential course, with each section representing a different engineering discipline. The stated objectives of the Freshman course, in accordance with ABET guidelines, include the introduction of basic engineering concepts, including design concept, basic statistics, ethics, environmental and societal impact of technology, technical communications and team management. Although the college provides specific guidelines regarding both general and",[],Other,N/A,N/A
https://openalex.org/W2428222171,W2428222171,,https://doi.org/10.18260/1-2--17251,Invited Paper - Preparing the Global Engineer: How learning to teach in a Service-Learning Project Develops Effective Communication Skills in Engineering Students,"Abstract Paper ID #8368Invited Paper - Preparing the Global Engineer: How learning to teach in aService-Learning Project Develops Effective Communication Skills in Engi-neering StudentsMrs. Robyne Bowering, Monash University Robyne Bowering began lecturing in science teacher education at Monash University in 1991. In 2006 she became the Schools’ Technology Project Coordinator. The Project operates as a partnership between the Faculties of Engineering and Education and has been speciﬁcally developed to enhance the profes- sional skill competencies of ﬁnal year engineering students through their placement in schools, where they design and teach a STEM-based unit of work. Robyne’s pedagogical focus is on providing the best learn- ing environment for individual student growth and her current research interest is how learning to teach provides engineering students with the cognitive, conative and metacognitive skills needed for effective problem-solving in the engineering workplace. c American Society for Engineering Education, 2013 Preparing the Global Engineer: How learning to teach in a Service-LearningProject Develops Effective Oral Communication Skills in Engineering Students.AbstractGlobalisation, mass migration, the digital revolution and a growing need for environmentalstewardship are changing the way goods and services are designed, produced, distributed,consumed and disposed of. To be able to work successfully, both domestically and globally,engineers need the capacity to understand changing contexts, constraints and cultures andhave the capability and drive to work with people who define and solve problems differently.As the engineering workplace evolves, there are increasing demands from industry forengineering faculties to produce student graduates who are technically able and possessproficient professional skills. Monash University’s Schools’ Technology Project has beenspecifically designed to develop a range of professional skills in their final-year engineeringstudents. The project is a service-learning program placing students into schools to designand teach STEM-based (Science, Technology, Engineering and Mathematics) units of work.This paper is a phenomenological description of how the experiential learning opportunitiesprovided during the project enhance one aspect of student professional skill development:effective oral communication.Introduction‘Engineers are hired, retained and rewarded for solving problems’[1]. Globalization, massmigration, the digital revolution and a growing need for environmental stewardship arecreating new contexts and new types of problems for engineers to solve.[2] To be successful inthe rapidly changing world, engineers need to be globally competent and locally relevant.Downey et al.[3] define global competent engineers as those who possess ‘the knowledge,ability, and predisposition to work effectively with people who define problems differentlythan they do.’ Engineering has become a discipline where the social and technical havebecome inextricably intertwined.[4] Engineers need to be technically able and proficient atmanaging relationships and building networks. They need strong social skills (a sub set ofprofessional skills/soft skills/generic skills/transferable skills) in particular:  effective oral communication skills - able to differentiate and cater to different audiences.[2, 5] They need to be able to communicate efficiently in English, the official international language of business and the sciences.[6] They need to be purposeful when delivering information and instructions, and competent at interpreting information – verbal, non-verbal, written, visual and electronic;[7]  cogent interpersonal skills – enthusiastic, collaborative workers who are open-minded and aware of their own perspectives and assumptions, and those of others.[2] They need to have cultural awareness, not just in terms of different ethnicities, but also the culture of organisations.[8]Earl Dowell, Dean of Engineering at Duke University stated “…engineers who are adept atcommunications have a considerable advantage over those who are not...”[9] Effectivetechnical and non-technical communication, as a two-way process, is paramount to anengineer’s success. Yet the emphasis on developing communication skills in manyengineering courses is limited to the one-way delivery of discipline-specific informationthrough technical writing and the occasional oral presentation, supported by text and imageson a screen. Oral communication in the broadest context is a learnable skill.[5] Despite this,studies from around the world reveal that it is the competency most frequently reported asbeing deficient in the engineering workplace. [6-8, 10]Oral communication, like many skills identified by employers as insufficiently developed ingraduates, can be enhanced through improved faculty teaching and learning methods. Thenew curricula should encourage deeper learning and understanding of context. They shouldcontain among other things: integrated experiential activities, interdisciplinary perspectives,addressing different learning styles and helping students to develop life-long learning skillsby assisting them to understand how they learn and provide a connectedness to the needs andissues of the broader community.[11-13]Service-learning is a pedagogical practice that deliberately integrates community serviceactivities with educational objectives. Students engage in meaningful learning throughapplied, active, project-based learning, drawing on multiple knowledge sources (academicand community knowledge, student knowledge and experience,).[14] They use what they learnin the classroom to solve real-life problems. They not only learn the practical applications oftheir studies, they become actively contributing citizens and community members through theservice they perform.[15]Trevelyan advocates that ‘… many aspects of engineering practice are closely related toteaching, particularly technical coordination and training. This creates an interestingopportunity to improve engineering education. If students learn effective teaching skills, firstthey will acquire social skills that will enable them to be more effective engineers, secondthey will learn the ‘real technical stuff’ better ...’[16]This paper provides a brief overview of oral communication practice in the engineeringworkplace. It looks at the awareness that final-year engineering students have of the valuethat employers place on effective oral communication skills and then demonstrates how theSchools’ Technology Project provides opportunities for engineering students to practise andrefine their oral communication skills in a range of contexts with different audiences.The role of oral communication in engineering practiceStudies suggest that engineers spend around 60% of their working day interacting withpeople. The majority of this interaction is orally based communication: informal face to face,on site, in meetings, in training sessions, over the phone, etc.[4] Darling and Dannels’ ‘Reporton the Role of Oral Communication in the Workplace’[10] indicated that practising engineersdeemed message construction (being concise, clear and logical) to be the most important oralcommunication skill to have in the workplace. Interaction with others was a close second(interpersonal skills, teamwork, negotiation, asking and answering questions), followed bypublic speaking skills and delivery (confidence, preparation, etc.).Trevelyan[17] reports that young engineers spend more time listening than talking duringconversations, while Lee[18] suggests that the work performance of novice engineers can oftenbe predicted by the quality of the social relationships they form with ‘expert’ engineers, andtheir willingness to ask for and accept guidance.What is the Schools’ Technology Project?The Schools’ Technology Project (STP) is a semester-long, service-learning elective, open tofourth Year students from all engineering disciplines at Monash University’s ClaytonCampus. The Project operates as a partnership between the Faculties of Engineering andEducation and local elementary and high schools. It is one of two engineering unitsrecognised in the Monash Passport: Act Program, a University-wide framework, ‘providingstudents with the opportunity to develop a range of skills and abilities, through communityengagement, work-integrated learning activities and peer-to-peer learning, that not only serveas a foundation for career development, but can also be applied to transform local andinternational communities’.[19]At the start of the semester, the STP students participate in a series of workshops on:understanding how we construct and retain knowledge, different learning styles, effectivecommunication and presentation skills, motivation, goal setting, lesson planning, leadershipand reflection. They are then placed into a suitably matched school to plan, organise andteach a STEM-based unit of work. The STP students specifically design their unit of work(project) around the brief given to them by their supervising teacher and the interests andcapabilities of the children that they work with. The projects are typically 12+ hours long andare delivered over six weeks. Two or more STP students, preferably from differentengineering disciplines, are placed at the same school; they work with the same grade level ofstudents, on the same topic but with different classes. This enables the students to plan theirclasses and reflect on their learning with a colleague.For the schools involved in the Project, the engineering students bring to the classroom novel,authentic learning experiences and an understanding of the work of engineers. Peter Hall,Victorian Minister for the Teaching Profession, described the project as ‘…not only brilliantbecause of the unique learning experience it creates for students, but it doubles as hands-onprofessional development for teachers. The Schools’ Technology Project inspires not only thestudents, but the teachers themselves. They see how hands-on, inquiry-based learningactivities can energise theoretical concepts and in turn motivate and excite students’.[20]The school placement provides the STP students with a supportive, professional workplace,where they are encouraged to step outside their comfort zone, in order to develop a widerange of professional skills.“The STP has been one of the most rewarding units I have taken during my time at University. The variousteaching sessions have put me into situations where I can learn and improve on my soft skills in real-lifesituations, which is much better than learning purely based on theory. It also allowed me freedom to fail, learnfrom my mistakes and practise what I have learnt effectively.” (Andrew)Since its inception in 1991, nearly 1300 engineering students and over 30000 elementary andhigh school students (and their teachers) have benefitted from their involvement in theProject.Setting the context for the need to develop effective oral communication skillsIn the first week of the elective the students complete an assessment task requiring them to: 1. Look at the student competency outcomes outlined by the following engineering program accrediting agencies: Engineers’ Australia, ABET, Inc. and EUR-ACE®, and at the CDIO Syllabus to get a feel for the engineering competencies that are considered to be important around the world. 2. Conduct an informal audit of their personal professional skills. 3. Analyse and respond to Nair et al.’s ‘Re-engineering graduate skills - a case study’.[21] A study of the 2007 Monash University survey of employers’ satisfaction levels of their Engineering graduates. The students are reassured that the findings are typical for similar surveys conducted throughout the world, and certainly not unique to Monash or Engineering. In their response, the students need to state whether they agree or disagree or are surprised with the survey findings and back up their statements with relevant examples from their studies or work experience. 4. Identify three professional skills that they will specifically work on developing during the semester and the measures they propose using to evaluate how successful they are in meeting their goals.Analysis of the student responses from 2010 to 2012 (322 students) indicated that nearly half(48%) of the students were unaware of the value that employers placed on professionalskills. Most assumed that their technical skills, based on their subject selections and results atUniversity, would be more than adequate for them to secure and thrive in their firstengineering job.“I was under the impression that the best person for the job was always the person who was the mosttechnically able, this article has broadened my understanding of the credentials that are required byemployers.” (David)Eleven per cent of the students were indignant at the findings, convinced that they possessedmore than adequate professional skill levels. Unfortunately, these students tended to have alimited understanding of the range and context in which many of the skills are used theworkplace. For example, two students attached a copy of a mark sheet their group hadreceived for an oral presentation in another subject, whose opening comment was ‘Yourpresentation was better than 99% of the presentations I see at conferences’. From myexperience, this is not necessarily the highest bench-mark to assess effective presentationstandards by and this one comment led the students to believe that they had outstanding oralcommunication skills.A total of 4% of students were complacent about the findings.“Engineers around the world are hired for their technical skills and problem-solving abilities.They are not known for their communication skills and people skills.” (William)The remaining 37% of students were not surprised by the important role that proficientprofessional skills play in the workplace; interestingly, most of these students were alreadyworking part-time in industry.Two thirds (68%) of the students believed that Universities need to be more proactive inaddressing industry concerns, or at least alerting their students to the concerns.“The issue is best addressed with a complete restructure of HOW subjects are taught and assessed, rather thanWHAT is taught...apart from group projects, the engineering course is primarily just counter-productive solowork and self-reliant study.” (Peter)A number of students lamented that a lack of lecturers with competent social skills wasprobably a contributing factor to them not placing much value on developing their ownskills.“Most lecturers are dry, have terrible communication skills, and form no personal one-on-one relationshipswith students. There is never any attempt to make learning interesting, relevant or fun.” (James)The two most frequently selected professional skill goals set by students enrolled in the STPover the past 3 years have been improving oral communication (66% of students) anddeveloping interpersonal skills with colleagues and clients (28%). This formative assessmenttask explicitly informs the students that developing their professional skills is an integral partof their engineering education. Allowing the students to identify and choose the professionalskills they most need to work on gives them ownership and responsibility and is a powerfulmotivating tool.How the placement provides authentic contexts for oral communication developmentUnderstanding the client’s problem and perspectives to define the project: The abilityto accurately deconstruct ill-defined problems and interpret the client’s desired explicit andimplicit project outcomes is vital to the overall success of a project. The client’s wholeproject experience impacts on the professional reputation of those directly involved in thenegotiation process and their employer.The week before the STP teaching placements begin, a briefing meeting is held between theSTP students working at the same school and their supervising teachers (the client). The STPcoordinator attends each meeting as facilitator and mentor. The main purpose of the meetingis to negotiate the commitments (days/times when the STP students will teach, teacherexpectations, e.g. lesson plans will be emailed through two days before each session; andMonash and student 
expectations, e.g. the type of feedback required) and to establish thebroader aims and learning objectives of the project (e.g. hands-on, problem-based learning,with an emphasis on fair testing and team-work). The meeting also provides an opportunityfor the STP students to begin building a rapport and trust with their client.The teachers come to the meeting knowing the big-picture learning outcomes they want fortheir students, but don’t know how to achieve them authentically using engineeringknowledge and skills (Engineering as a subject, is not officially included the AustralianSchool Curriculum). To ensure that their first meeting with the client is productive, the STPstudents need to have conducted some preliminary research and bring relevant suggestionsand ideas to the discussion table. The STP students learn that the effort they put intopreparing for the meeting not only provides them with the confidence to ‘sell’ their ideas, butalso provides a tangible structure for the discussion and a guide to the types of questions theyneed to ask their client e.g. can we conduct parts of our lessons outside? Do any studentshave special needs that we should accommodate in our planning?“We knew that our teachers were keen for the Grade 5 classes to work in small teams on a design/constructionproject. We were keen to work on a project that we thought the children would find exciting and would useinformation from both of our backgrounds - civil and materials engineering. Designing and building trebuchetsthat could launch a tennis ball across the school oval, sounded like a great idea. Dave and I took the liberty ofattending our first meeting with a draft of our proposed lessons, a prototype of a simple trebuchet that could bebuilt by the students and a You-tube clip, showing trebuchets in action. The teachers loved the idea and wereimpressed with our initiative.” (Simon)At the conclusion of the briefing meeting, the STP students spend at least one hour observingtheir client teaching the children that they will work with. They are provided with a list ofteacher and student behaviours to pay attention to. For example: how did the teacher give outinstructions; were they written, verbal, demonstrated or a combination? Were they repeatedmore than once? Were they ‘chunked’[22] into bundles? What non-verbal communicationoccurred? How did the children respond? Guided observation[23] plays an important role inthe STP students seeing that effective communication is often more about how a message isdelivered rather than what the message is.[24] The observation session provides the studentswith the opportunity to see how their learning from the STP workshops translates into theclassroom. The modelling of effective communication and interpersonal skills by the teacherprovides the STP students with a concrete experience to reflect on and consider using whenthey start teaching.[25]At the conclusion of the observation session, the engineering students spend 10-15 minutesintroducing themselves to the children, explaining what engineering is, what they are going tobe teaching over the next few weeks and discovering what in particular the children mightlike to find out about or do during the project sessions. This short introduction to standing upand talking in front of a relatively large group on a topic that they know more about thananyone else in the room, provides the STP students with a much-needed confidence boost. Italso gives them some insight into the prior knowledge and interests of the children they willwork with. The initial visit to the school provides the STP students with some understandingof the culture of the school. They get a feel for the types of relationships that exist betweenteachers and their students, the type of learning that occurs in the classrooms (student-centredor teacher-centred, prescriptive or exploratory, intrinsically or extrinsically motivated) andthe protocols around being a visitor to the school. The quicker the STP students can fit inwith the accepted norms, the more enjoyable their placement is for them, their client and thechildren.Before the engineering students officially begin planning the scope and sequence for theirproject, they meet with the STP coordinator to clarify their understanding of their client’sobjectives for the project. This meeting provides the STP students with a timely reminder ofthe importance of listening to their client and keeping their client’s perspective of theproject’s outcomes at the forefront of their thinking. For many of the STP students, theirfocus for the project has become centred on what the children will do, rather than what thechildren will learn as a result of doing…The importance of purpose and learning the skills of collaboration: Effective oralcommunicators in the classroom, the boardroom or on site speak with a purpose. They knowupfront whether they want to convince, inform, identify a problem or open up a discussionand they structure their conversations and presentations accordingly.To be successful in their teaching, the STP students need to visualise the ‘big picture’ oftheir project first, so that they can plan and structure the individual lessons appropriately. Tosee their project as a whole and to begin the process of collaboration, students working at thesame school (planning team) work together to construct one concept map[26] containing allthe key ideas, terms and activities that could be included in the project. As they create linkson the map, groupings of like information and activities form helping the students to identifyindividual lessons, and they begin to recognise which ideas are critical to meet the project’sobjectives versus those that are ‘nice to know but not necessary’ and where contingenciesneed to be considered. The process of forming the project’s overall structure brings outinteresting interdisciplinary discussions can reveal misconceptions in individuals’understandings.Most teams then make the decision to split the planning for the individual lessons betweenthem. The sharing of the responsibility for developing lesson plans often brings a moresophisticated level of team-work than is typically seen in other student group projects. Theycan’t simply rely on the ‘divide and conquer’ approach to doing a group assignment, as allmembers of the team ultimately need to take ownership of each lesson plan as they will besolely responsible for understanding and delivering all the content, organising the activitiesand answering questions once they begin working in their separate classrooms. When thestudents meet again to share their plans, it is done critically and collaboratively. Everymember of the team needs to leave the meeting with more than just the physical plans andPowerPoint presentation of ‘what’ will be done ‘when’ and by ‘whom’. They also need aclear understanding of ‘why’ specific components have been included in that particularsequence, excluded or modified and be aware of ‘how’ to introduce/demonstrate an idea orrun an activity so the children will learn how to apply, analyse, evaluate or create. Having aclear understanding of the purpose of each lesson component increases the chance that themessages delivered in the classroom are valid, logical, concise and clear, and gives the STPstudent the confidence to deliver the lesson and the flexibility to appropriately changecomponents of the lesson on the spot if necessary.“Being an international student, I have had a lot of self-doubts especially when it comes to communicating withpeople from different language and culture backgrounds. The school placement had given me a huge confidentboost as it made me realize that I could actually communicate efficiently and it was my lack of knowing how toprepare and lack of confidence in my head all along that was preventing me from doing it.” (Jacky)Knowing and catering to your audience: Effective communication is measured by thequality of the message that is received and understood rather than by the quality of themessage that is delivered.[27] If we want to be effective communicators, we must be preparedto connect with our audience and adapt to their needs.The STP students are encouraged to use BSCS’s 5E Instructional Model[28] for their lessonplanning. This approach uses Engage, Explore, Explain, Elaborate and Evaluate phases toidentify the prior knowledge of the children in their classes and creates the interest/motivation for them to want to know more. The different phases provide relevantopportunities for the children to investigate and question new ideas, language and conceptsuntil they can comfortably scaffold the new knowledge onto their existing knowledge andare able to own and apply it. The Explore phase is particularly useful for connecting withaudiences with a non-technical background or a language background different to thepresenter, as the audience can learn the basics in their language, which can later be translatedinto the appropriate jargon during the Explain’ phase.“This week I learnt my second lesson of teaching… There is no such thing as a concept too difficult for a studentto grasp – the key is teaching in a way that students can understand.” (Hoon)The 5E model also encourages instructors to design learning environments that areaccessible to audiences with a variety of different learning styles and preferences. The STPstudents are introduced to, and complete an assessment task on, two learning style theories,Felder-Silverman’s Index of Learning Styles[29] and Fleming’s VARK[30], in the workshopsthat run before the school placement. In their lesson planning, they are expected to considerthe learning style preferences of the children they teach so that they include the appropriatemeans (analogies, associations, demonstrations, models, small group discussion etc.) andmethods (verbal and non-verbal communication, timing of questions and thinking etc.) ofcommunication to ensure the successful understanding of instructions/, ideas and concepts.One of the advantages of the STP students working with children is that children are notembarrassed to say that they don’t understand the idea being explained and will quite happilyask for the same concept to be re-explained multiple times. Explaining the idea the sameway, using the same example each time does not help. The STP students quickly learn that aspart of their planning for effective communication, they need to think of multiple ways ofexplaining the same idea and consider what types of examples would be most appropriate fortheir audience.“Before STP, I wasn’t aware of the different learning and communication styles and often found myselffrustrated and annoyed when people didn’t get ideas that I found easy and straight forward. Understanding thedifferent styles means that I can now change the way I explain things so that more will understand what I amtrying to say. This will definitely benefit me when I transition into the workplace, and will give me an edge incommunication.” (Ellen)Oral communication during the placement: The teaching placement provides theSTP students with the opportunity to practise effective two-way communication in a varietyof contexts with multiple audience types, requiring them to adjust their style accordingly.They talk with their client to establish and clarify expectations, to discuss and negotiate ideas,to establish a rapport and trust and to seek and respond to constructive feedback. Theyexplain their project to the School Principal and what learning they are gaining from theexperience. They communicate with a large group of children to engage, inform and convincethem, to explain technical concepts, give instructions and demonstrate how to do things. Theywork with small groups of children to motivate them, build team work, identify problems,resolve conflict and discuss and consolidate ideas, and work with individuals to understandtheir thinking and answer their questions. They collaborate with their peers to exchangeideas, create resources and solve problems and they talk with their mentor (STP coordinator)about their progress, concerns and learning and to organise the loan and use of equipment.While there is a considerable emphasis on teaching children and working with the constraintsand culture of a school during their placement, the students are also required to reflect onlessons learnt in the classroom and how they will be able to transfer their new learning intothe workplace.The role of feedback and reflection: The opportunity to teach a lesson, receiveimmediate constructive feedback and reflect on what worked and why, and what didn’t workand why with their teacher, colleagues and STP coordinator before planning the next lessonplays an important role in developing student capacity and confidence. Feeling comfortableabout asking for guidance and strategies empowers the students to try new means andmethods of communication and grow as a result.“I have learnt that asking for help appropriately is a sign of strength, not a sign of weakness."" (Andrew)ConclusionStudents learn best when they are active participants in their own learning, when theirlearning is purposeful and challenging and they are provided with opportunities to applytheir new understandings to authentic tasks. Students need to be able to evaluate their ownlearning and see opportunities to apply it to new contexts.The Schools’ Technology Project provides engineering students with a comprehensiveapproach to enhancing their oral communication skills required for global competence. Thestudents understand up front the value that accrediting bodies and employers place oneffective communication skills, providing the motivation for knowledge, skill and attitudedevelopment throughout the elective. The students are active participants in their learningand their communication of knowledge and collaborations with others are authentic.The school placement provides a supportive, professional environment for the engineeringstudents to practise and refine their oral communication skills. Schools are places whereeffective two-way communication is the focus, and where planning for effectivecommunication, having a purpose, knowing one’s audience and reflecting on learning isparamount. Schools are places of multiple perspectives and personalities, where there isnever one right way for communication to occur. They are places of learning, where steppingoutside comfort zones is encouraged and mistakes made are viewed as opportunities forlearning and growth. Teachers have the expertise to guide and give constructive feedbackand children are the barometers of communication success.Bibliography1. Jonassen, D., J. Strobel, and C.B. Lee, Everyday problem solving in engineering: Lessons for engineering educators. Journal of engineering education, 2006. 95(2): pp. 139-151.2. Mansilla, V.B. and A. Jackson, Educating for Global Competence: Preparing Our Youth to Engage the World, 2011.3. Downey, G.L., et al., The globally competent engineer: Working effectively with people who define problems differently. Journal of Engineering Education, 2006. 95(2): p. 1.4. Trevelyan, J.P. Engineering education requires a better model of engineering practice. in Proceedings of the Research in Engineering Education Symposium. 2009.5. Chan, A.D. and J. Fishbein, A global engineer for the global community. The Journal of Policy Engagement, 2009. 1(2): pp. 4-9.6. Riemer, M.J., English and communication skills for the global engineer. Global Journal of Engineering Education, 2002. 6(1): pp. 91-100.7. Siller, T.J., et al., Development of undergraduate students’ professional skills. Journal of Professional Issues in Engineering Education and Practice, 2009. 135(3): pp. 102-108.8. Iles, P., Learning to work with difference. Personnel Review, 1995. 24(6): pp. 44-60.9. Dowell, E.H. Introduction: Four Carrots and a Stick. Available from: http://wac.colostate.edu/llad/v3n2/dowell.pdf.10. Darling, A.L. and D.P. Dannels, Practicing engineers talk about the importance of talk: A report on the role of oral communication in the workplace. Communication Education, 2003. 52(1): pp. 1-16.11. Fink, L.D., S. Ambrose, and D. Wheeler, Becoming a professional engineering educator: A new role for a new era. Journal of Engineering Education, 2005. 94(1): pp. 185-194.12. Felder, R.M., et al., 
The future of engineering education II. Teaching methods that work. Chemical Engineering Education, 2000. 34(1): pp. 26-39.13. Duderstadt, J.J., Engineering for a Changing Road, A Roadmap to the Future of Engineering Practice, Research, and Education. 2007.14. Furco, A., Service-learning: A balanced approach to experiential education. Expanding boundaries: Serving and learning, 1996. 1: pp. 1-6.15. Hurd, C.A. Is Service-Learning Effective?: A Look at Current Research. 2006; Available from: http://tilt.colostate.edu/sl/faculty/Is_Service-Learning_Effective.pdf.16. Trevelyan, J. Engineering students need to learn to teach. in Frontiers in Education Conference (FIE), 2010 IEEE. 2010. IEEE.17. Trevelyan, J.P. Mind the gaps: engineering education and practice. in The 21 st Annual Conference for the Australasian Association for Engineering Education. 2010.18. Lee, D.M.S., Social ties, task-related communication and first job performance of young engineers. Journal of Engineering and Technology Management, 1994. 11(3–4): pp. 203-228.19. University', M. The Monash Passport. Available from: http://opvclt.monash.edu.au/passport/.20. Hall, P. Primary school-made prosthetic legs a step ahead in science education 2011; Available from: http://www.premier.vic.gov.au/media-centre/media-releases/1878-primary-school-made-prosthetic- legs-a-step-ahead-in-science-education.html21. Nair, C.S., A. Patil, and P. Mertova, Re-engineering graduate skills - a case study. European Journal of Engineering Education, 2009. 34(2): pp. 131-139.22. Baddeley, A., The magical number seven: Still magic after all these years? Psychological Review, 1994. 101(2): pp. 353-356.23. Bringle, R.G. and J.A. Hatcher, Reflection in service learning: Making meaning of experience. Educational Horizons, 1999. 77: pp. 179-185.24. Chaiken, S. and A.H. Eagly, Communication modality as a determinant of message persuasiveness and message comprehensibility. Journal of Personality and Social Psychology, 1976. 34(4): p. 605.25. Hatton, N. and D. Smith, Reflection in teacher education: Towards definition and implementation. Teaching and teacher education, 1995. 11(1): pp. 33-49.26. Novak, J.D. and A.J. Cañas, The theory underlying concept maps and how to construct and use them. Florida Institute for Human and Machine Cognition Pensacola Fl, Available from: www. ihmc. us.[http://cmap. ihmc. us/Publications/ResearchPapers/T heoryCmaps/TheoryUnderlyingConceptMaps. htm], 2008. 284.27. Hattie, J. and H. Timperley, The power of feedback. Review of educational research, 2007. 77(1): pp. 81-112.28. Bybee, R.W., et al., The BSCS 5E instructional model: Origins and effectiveness. Colorado Springs, CO: BSCS, 2006.29. Felder, R.M. and R. Brent, Understanding student differences. Journal of engineering education, 2005. 94(1): pp. 57-72.30. Fleming, N.D. I'm different; not dumb. Modes of presentation (VARK) in the tertiary classroom. in Research and Development in Higher Education, Proceedings of the 1995 Annual Conference of the Higher Education and Research Development Society of Australasia (HERDSA), HERDSA. 1995.",['Foundation Models'],New Generation of AI,0,0
https://openalex.org/W2439525429,W2439525429,,https://doi.org/10.3390/books978-3-7258-0106-0,Biotechnology and Bioethics,"Biotechnology produces numerous and significant benefits for humanity and the environment, but is often controversial regarding its societal implications.Over the recent decades, traditional but also novel technologies in this field of study have raised complex ethical concerns, which-in certain cases-necessitate policy changes at the national and/or international level.This Special Issue aims to discuss the ethical, legal, and societal challenges raised by biotechnological applications and highlights the interdisciplinary approach that needs to be adopted to responsibly address such problems.For this reason, it explores the ethical issues and potential legal and societal consequences generated by the use of genome editing, genetic testing, gene therapy, organoid technology, synthetic biology, and artificial intelligence by bringing together scholars from diverse fields-including medicine, law, genetics and genomics",['artificial intelligence'],New Generation of AI,1,0
https://openalex.org/W2476884965,W2476884965,,https://doi.org/10.18260/1-2--10235,A New Cellular And Molecular Engineering Curriculum At Rice University,"Abstract NOTE: The first page of text has been automatically extracted and included below in lieu of an abstract Main Menu Session A New Cellular and Molecular Engineering Curriculum at Rice University Ka-Yiu San, Larry V. McIntire, Ann Saterbak Department of Bioengineering, Rice University Houston, Texas 77005 Abstract The tremendous advances in cellular and molecular biology over the last 25 years have fundamentally changed our understanding of living organisms. This new understanding at the level of cells and their array of associated molecules is having a tremendous impact on both medicine and technology. Appreciating the complexities of the cell and its inner workings will be crucial to turning our knowledge into effective treatment strategies at the tissue, organ and whole individual levels. Because of its tradition of applying the fundamentals of physics and mathematics to the understanding and control of biological systems, biomedical engineering is especially well positioned to advance cellular and molecular-based medicine and technology. To accomplish this, the Bioengineering Department at Rice University is developing a curriculum that educates students in cellular and molecular processes and their control. In this talk, we will describe the structure of a bioengineering undergraduate program at Rice University begun in 1998. We will present the development of a series of new courses for the cell and molecular engineering program. This series of courses starts with the basic concepts of engineering fundamentals at the sophomore level. This introductory course provides the foundation for the more advanced quantitative treatment of cell structure and function at the cellular and tissue levels taught in the junior and senior levels. In particular, we will discuss the development of three specific courses that cover topics ranging from molecular to tissue level: molecular engineering, cellular engineering and tissue engineering. This sequence of courses exposes students to the cutting-edge synthesis of molecular and cellular information into design of tissue systems. Coupled with these lecture-based courses is a hands-on tissue culture laboratory course. With the emphasis on cellular and molecular engineering, we believe our bioengineering undergraduate students will obtain the necessary training to become leaders in this rapidly emerging field of the biomedical/biotechnology industry. Introduction The Bioengineering undergraduate program at Rice University is designed to prepare students for careers in rapidly developing areas of biomedical engineering and bioprocessing. The undergraduate educational program in Bioengineering (BIOE) has the goal of producing a new type of biomedical engineer, fully conversant with modern biochemistry and cell and molecular biology. This type of biomedical engineer will translate bench-scale scientific advances in biological sciences into cost-effective new products and processes. New and innovative curricula are being developed to educate biomedical engineers who will not only create new tissues and cell-based therapies but also deliver them at a cost affordable to our health care system. Proceedings of the 2002 American Society for Engineering Education Annual Conference & Exposition Copyright Ó 2002, American Society for Engineering Education” Main Menu",[],Other,N/A,N/A
https://openalex.org/W2501897184,W2501897184,,https://doi.org/10.1201/9781003078630-86,Invited lecture: A real time early warning and modelling system for red tides in Hong Kong,"Harmful algal blooms (HAB) can lead to great economic losses to fisheries and significant adverse impacts on the environment. And yet the onset of HAB, a worldwide problem, is notoriously difficult to predict. This paper describes the design, development, and initial operation of a real time, remotely controlled, early warning system for algal blooms and red tides in a coastal field research station. The system measures solar radiation, wind velocity, tidal level and velocity, dissolved oxygen and chlorophyll fluorescence at three depths, supplemented by regular onsite sampling for subsequent chemical analysis of nutrient and chlorophyll concentrations, and taxonomic examination. An example of successful detection and monitoring of an algal bloom event (and also a red tide) is given. Preliminary results of modelling chlorophyll concentrations using artificial neural networks (ANN) are also presented. Different network structures are trained on a six year biweekly water quality data set, and tested on an independent 3 year data set. Unlike previous work on limnological and riverine applications, the results show that rather good predictions of long term trends in algal biomass can be obtained using only Chlorophyll-a and (or without) total inorganic nitrogen (time delayed for one week) as input nodes. On the other hand, the phase error of predictions renders the ANN method unsuitable for short term forecasts of algal blooms - which can take off and collapse in 7-10 days.",['artificial neural networks'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W2527395255,W2527395255,,https://doi.org/10.5370/kiee.2020.69.7.1040,A Development of Rose Leaf Disease Classification System using Convolutional Neural Network,"The classification of plant disease by images has been studied over past decades. In this paper, convolutional neural network models were applied to perform rose leaf disease diagnosis using simple leaves images of healthy and diseased rose leaves, through deep learning methodologies. Training of the models was performed with the use of an open database of 13,125 images, containing field and laboratory images with five different disease and healthy leaves. Based on experiments, the precision and recall are 98.7% and 97.4% and the F1-score is 0.98. The significantly high success rate makes the model a very effective advisory or early warning tool, and an approach that could be further expanded to support an rose leaf disease identification system to operate in real cultivation conditions.","['convolutional neural networks', 'deep learning']",Classic AI & Neural Network Architectures,1,1
https://openalex.org/W2552340832,W2552340832,,https://doi.org/10.1609/aiide.v11i4.12828,"Cinematic, Ambient, Inhabitable Narrative Environments: Story Systems in Search of an Artificial Intelligence Engine","Cinematic, Ambient, Inhabitable Narrative Environments (CAINEs) are conceptual AI-driven interactive story systems combining text, audio, and visual imagery that are scalable and adaptable to a wide range of storytelling needs and interactor inputs. Conceived by at artist outside the AI community, they represent an opportunity to use AI in a nontraditional and immersive narrative fashion that relies not on the goal-based arrangement of story elements, but on the accretion and association of those elements in the minds of interactors. This paper represents the initial phase of the project’s development.",['CAINEs'],Other,1,1
https://openalex.org/W2586459719,W2586459719,,https://doi.org/10.18260/1-2--12148,A Longitudinal Retention Study In An Urban Engineering School,"Abstract NOTE: The first page of text has been automatically extracted and included below in lieu of an abstract Session 1430 A Longitudinal Retention Study in an Urban Engineering School Ann Marie Flynn and Richard H. Heist School of Engineering, Manhattan College Riverdale, New York 10471 Introduction The retention of undergraduate students in engineering programs has attracted considerable attention at Colleges and Universities across the Country. From an academic institutional standpoint, losing students from engineering programs can have serious resource and resource allocation ramifications. From a broader perspective, however, losing engineering students exacerbates the already serious problem of the shortage of engineers in the National workforce. While the number of undergraduate engineering degrees has decreased from roughly 85,000 in the mid-1980’s to roughly 60,000 at the turn of the century, the anticipated increase in the number of engineering positions by 2008 over that existing at the turn of the century is roughly 290,000. Attracting more students (particularly women and minorities) into engineering and retaining them are critically important concerns. While losing some students from engineering programs is expected, even desirable, it is important to measure and to evaluate the reasons for migration away from engineering in order to help determine optimum levels of retention for a given institution. Manhattan College is a small, private, Catholic college located in the Riverdale section of the Bronx in New York City. The total enrollment is roughly 2800 with approximately 2500 undergraduate students and 300 Masters-level students. The ratio of male to female undergraduates in the College is roughly 52%/48% and 78%/22% in the School of Engineering. The undergraduate diversity (ratio of Caucasian to non-Caucasian) in the College as well as the School of Engineering is roughly 72%/28%. The ratio of commuting to resident undergraduate students in the College is roughly 27%/73% and 38%/62% in the School of Engineering. The School of Engineering offers BS and MS degrees in Civil, Chemical, Computer, Electrical, Environmental, and Mechanical Engineering. The Mission of the College is to provide a contemporary, person-centered educational experience characterized by high academic standards, reflection on values and principles, and preparation for a life-long career. In this regard it is also important to note that, consistent with this Mission, there is a strong emphasis on providing educational opportunities to first generation college students. As mentioned earlier, retention of students has both institutional and global ramifications. Considering the stringent economic constraints facing most colleges and universities, the “costs” “Proceedings of the 2003 American Society for Engineering Education Annual Conference & Exposition Copyright © 2003, American Society for Engineering Education”","['longitudinal retention study', 'engineering school', 'student demographics', 'academic performance indicators']",Other,1,1
https://openalex.org/W2596034120,W2596034120,,https://doi.org/10.18260/1-2--1215,"Integration Of Interactive Simulations And Virtual Experiments In Telecommunications Courses For Onsite, Online And Hybrid Delivery","Abstract NOTE: The first page of text has been automatically extracted and included below in lieu of an abstract Integration of Interactive Simulations and Virtual Experiments in Telecommunications Courses for Onsite, Online and Hybrid Delivery Abstract The rapid pace of technological growth and the convergence of Information Technology, Biotechnology and Nanotechnology are placing new demands on the knowledgebase and skill- sets of engineering and engineering technology graduates. The engineering and engineering technology graduates are not only expected to understand the theory behind state-of-the-art technologies, but also to exhibit hands-on, analytical, problem solving, expert thinking, and complex communication skills. To address these changing needs, it is essential that new technological tools and teaching methodologies be incorporated in the curricula so that students can acquire Digital-age literacy for becoming “Deep Learners.”. However, incorporation and implementation of state-of-art technological tools requires considerable investment of time and economic resources. Keeping curricula and lab resources current with respect to the swift pace of technological advances in the field is another challenge for faculty. Educators can address these challenges by using the simulation and virtual experiments. With the availability of broadband technologies, which offer high data rate connections, simulation- based e-learning is rapidly becoming a significant and effective component of the teaching and learning process. The use of virtual systems enables students engaged in distance learning to master practical skills at any time and at any place. This paper presents an introduction to “Active Learning Suite (ALSuite)” software developed for interactive simulations and virtual experiments, and discusses its application for Telecommunication (Fiber Optics and Wireless Communications) Courses, for onsite, online and hybrid delivery modes. I. Introduction To achieve success in learning and in pursuing a successful career, a student in the 21st century needs to attain proficiency in science, technology, and culture, in addition to the reading, writing and calculating skills. The Digital-age literacy requires students to gain understanding of information in all its forms: basic literacy, scientific literacy, economic literacy, technological literacy, visual literacy, information literacy, multicultural literacy, and global awareness. Moreover, a student has to become proficient in “ Deep Learning” in contrast to :Surface Learning” (See Table 1).1 In the book In The New Division of Labor: How Computers are Creating the Next Job Market, Harvard Professor Richard Murnane and MIT economist Frank Levy have examined the role of computers in reshaping the job market and types of human skills required in today’s marketplace. Professors Levy and Murnane contend that the jobs growing in numbers share two general skills that the computer cannot replicate: expert thinking and complex communication. The first skill, expert thinking, addresses the ability to solve new problems that cannot be solved by rules. The second general skill, complex communications, addresses the ability not only to transmit information, but to convey a particular interpretation of information to others in jobs like teaching, selling, and negotiation. 2,3 According to Professor R. Murnane “Training all","['Simulation-based e-learning', 'Virtual experiments', 'Telecommunications courses']",Other,1,1
https://openalex.org/W2605239093,W2605239093,,https://doi.org/10.18260/1-2--17599,Challenges in Assessing Interdisciplinary Engineering Programs,"Abstract Challenges in Assessing Interdisciplinary Engineering Programs Margaret A. Krudysz and Ann E. Wittig The City College of New York, The City University of New York mkrudysz@ccny.cuny.edu, awittig@ccny.cuny.eduAbstractThe accreditation of engineering programs by the Accreditation Board for Engineering andTechnology (ABET) requires that faculty assess and evaluate student performance across theprogram to demonstrate that the program achieves its outcomes. This is a challenging exercisegiven the level of effort of faculty to strategize, collect, and then evaluate meaningful evidenceof student performance. These challenges are even greater for interdisciplinary engineeringprograms. Interdisciplinary programs have substantial coursework requirements in non-engineering disciplines, resulting in fewer engineering courses to assess than in conventionalengineering programs. Interdisciplinary programs are also likely to use existing engineeringcourses from different disciplines to fulfill coursework requirements. Even though departmentsperiodically assess their students through coursework, their assessment approaches andfrequency may vary and they may not assess the particular courses offered in theinterdisciplinary program. Finally, the faculty in an interdisciplinary program are spread acrossschools and disciplines, and as a result have differing opinions on the importance ofaccreditation, their responsibilities to the assessment process, or the approach to assess thestudents.This paper discusses the challenges and possible approaches to accrediting interdisciplinaryengineering programs. Two programs at CUNY City College of New York (CCNY) arepresented as examples: an undergraduate program in Earth System Science and EnvironmentalEngineering (ESE) which is preparing for its first accreditation visit this Fall, and a mastersprogram in Sustainability in the Urban Environment (SUS) which will go up for accreditation ina few years. Both programs have substantial coursework in non-engineering topics: science inthe case of the ESE program, and science and architecture in the case of the SUS program. Theprograms have a few introductory courses and a capstone design course designed specifically forthe program, and existing courses offered across the multiple schools to fulfill the remainingcoursework requirements. In addition, the faculty in both programs are spread across multipleschools and disciplines within the schools.The unique curricula and methods for assessment of the ESE program are presented. Theseapproaches address the selection of courses in which individual student performance can beassessed. Also discussed are the challenges in presenting and evaluating assessment results fromdifferent disciplines in a sufficiently cohesive manner to adequately determine studentachievement across the program. The efficacy of these approaches as applied to the SUSprogram is also discussed. Finally, the appropriateness of our assessment methods tointerdisciplinary programs at other universities is considered.",[],Other,N/A,N/A
https://openalex.org/W2605239093,W2605239093,,https://doi.org/10.18260/1-2--17599,Challenges in Assessing Interdisciplinary Engineering Programs,"Abstract Challenges in Assessing Interdisciplinary Engineering Programs Margaret A. Krudysz and Ann E. Wittig The City College of New York, The City University of New York mkrudysz@ccny.cuny.edu, awittig@ccny.cuny.eduAbstractThe accreditation of engineering programs by the Accreditation Board for Engineering andTechnology (ABET) requires that faculty assess and evaluate student performance across theprogram to demonstrate that the program achieves its outcomes. This is a challenging exercisegiven the level of effort of faculty to strategize, collect, and then evaluate meaningful evidenceof student performance. These challenges are even greater for interdisciplinary engineeringprograms. Interdisciplinary programs have substantial coursework requirements in non-engineering disciplines, resulting in fewer engineering courses to assess than in conventionalengineering programs. Interdisciplinary programs are also likely to use existing engineeringcourses from different disciplines to fulfill coursework requirements. Even though departmentsperiodically assess their students through coursework, their assessment approaches andfrequency may vary and they may not assess the particular courses offered in theinterdisciplinary program. Finally, the faculty in an interdisciplinary program are spread acrossschools and disciplines, and as a result have differing opinions on the importance ofaccreditation, their responsibilities to the assessment process, or the approach to assess thestudents.This paper discusses the challenges and possible approaches to accrediting interdisciplinaryengineering programs. Two programs at CUNY City College of New York (CCNY) arepresented as examples: an undergraduate program in Earth System Science and EnvironmentalEngineering (ESE) which is preparing for its first accreditation visit this Fall, and a mastersprogram in Sustainability in the Urban Environment (SUS) which will go up for accreditation ina few years. Both programs have substantial coursework in non-engineering topics: science inthe case of the ESE program, and science and architecture in the case of the SUS program. Theprograms have a few introductory courses and a capstone design course designed specifically forthe program, and existing courses offered across the multiple schools to fulfill the remainingcoursework requirements. In addition, the faculty in both programs are spread across multipleschools and disciplines within the schools.The unique curricula and methods for assessment of the ESE program are presented. Theseapproaches address the selection of courses in which individual student performance can beassessed. Also discussed are the challenges in presenting and evaluating assessment results fromdifferent disciplines in a sufficiently cohesive manner to adequately determine studentachievement across the program. The efficacy of these approaches as applied to the SUSprogram is also discussed. Finally, the appropriateness of our assessment methods tointerdisciplinary programs at other universities is considered.",[],Other,N/A,N/A
https://openalex.org/W2609028368,W2609028368,,https://doi.org/10.1609/aiide.v12i1.12873,A Cognitive-Based Model of Flashbacks for Computational Narratives,"The flashback is a well-known storytelling device used to invoke surprise, suspense, or fill in missing details in a story. Film literature provides a deeper and more complex grounding of flashbacks by explaining their role to stimulate the viewer's memory in order to guide and change viewer comprehension. Yet, in adapting flashback mechanisms to AI storytelling systems, existing approaches have not fully modelled the roles of a flashback event on the viewer's comprehension and memory. To expand the scope of AI generated stories, we propose a formal definition of flashbacks based on the identification of four different impacts on the viewer's beliefs. We then establish a cognitive model that can predict how viewers would perceive a flashback event. We finally design a user-evaluation to demonstrate that our model correctly predicts the effects of different flashbacks. This opens great opportunities for creating compelling and temporally complex interactive narratives grounded on cognitive models.","['cognitive model', 'user-evaluation']",Other,1,1
https://openalex.org/W2614101929,W2614101929,,https://doi.org/10.3390/books978-3-03921-854-7,Artificial Superintelligence,"Attention in the AI safety community has increasingly started to include strategic considerations of coordination between relevant actors in the field of AI and AI safety, in addition to the steadily growing work on the technical considerations of building safe AI systems. This shift has several reasons: Multiplier effects, pragmatism, and urgency. Given the benefits of coordination between those working towards safe superintelligence, this book surveys promising research in this emerging field regarding AI safety. On a meta-level, the hope is that this book can serve as a map to inform those working in the field of AI coordination about other promising efforts. While this book focuses on AI safety coordination, coordination is important to most other known existential risks (e.g., biotechnology risks), and future, human-made existential risks. Thus, while most coordination strategies in this book are specific to superintelligence, we hope that some insights yield ""collateral benefits"" for the reduction of other existential risks, by creating an overall civilizational framework that increases robustness, resiliency, and antifragility.",['AI safety'],Other,1,1
https://openalex.org/W2624004095,W2624004095,,https://doi.org/10.18260/1-2--9124,Development Of A Novel Foundation Course For Biomedical Engineering Curriculum,"Abstract NOTE: The first page of text has been automatically extracted and included below in lieu of an abstract Session 1309 Development of a Novel Foundation Course for Biomedical Engineering Curriculum Ann Saterbak, Ka-Yiu San, Larry V. McIntire Department of Bioengineering, Rice University, Houston TX 77005 Abstract The Bioengineering undergraduate program at Rice University is developing novel courses to meet its primary program objectives. Students are required to take seven core Bioengineering courses and five elective courses in one of the three tracks of Cellular and Molecular Engineering, Systems Engineering and Biomedical Instrumentation, or Biomaterials and Biomechanics. The authors have developed a new sophomore-level course, Conservation Principles in Biology and Medicine, that lays the foundation for achieving the program objectives, prepares students for upper-level core courses, and exposes students to material in all three tracks. This course introduces the general conservation law and then focuses on the application of conservation of mass, momentum, charge and energy in biological systems. Course examples span the breath of modern bioengineering: physiology, biochemistry, tissue engineering, kinematics, biomaterials, biotechnology, cellular engineering, and instrumentation. One unique feature is the use of case studies at the end of the course to illustrate the concept that various conservation principles can be applied to understand and to model different aspects of a system. Case studies of the kidney, cellular metabolism and the circulatory system have been developed. Finally, a group term project focused on modeling an organ and describing an assist device synthesizes material. The term project also emphasizes team work and written and oral presentation skills which are taught in conjunction with the Cain Project in Engineering and Professional Communication. Assessment includes extensive mid-year and terminal surveys which focus on content, mode of presentation and quality of teaching. Conservation Principles in Biology and Medicine is serving as the template for incorporating ABET 2000 into a new department. Course notes are being developed into a textbook for biomedical engineering students. Biomedical Engineering Curriculum at Rice University The Bioengineering undergraduate program at Rice University is designed to prepare students for careers in the rapidly developing areas of biomedical engineering and bioprocessing. The undergraduate educational program in Bioengineering has the goal of producing a new type of biomedical engineer, fully conversant with modern biochemistry and cell and molecular biology. This type of biomedical engineer translates bench-scale scientific advances in biological sciences into cost-effective new products and processes. New and innovative curricula are being developed to educate biomedical engineers who not only create new tissues and cell-based therapies but also deliver them at a cost affordable to our health care system. The educational program objectives of the B.S. degree in Bioengineering are to: Proceedings of the 2001 American Society for Engineering Education Annual Conference & Exposition Copyright 2001 American Society for Engineering Education",['Conservation Principles in Biology and Medicine'],Other,1,1
https://openalex.org/W2725324378,W2725324378,,https://doi.org/10.1609/aiide.v12i1.12855,Predicting Proppian Narrative Functions from Stories in Natural Language,"Computational narrative systems usually require knowledge about the story world and narrative theory to be encoded in some form of structured knowledge representation formalism, a notoriously time-consuming task requiring expertise in both storytelling and knowledge engineering. In this paper we present an approach that combines supervised machine learning with narrative domain knowledge toward automatically extracting such knowledge from natural language stories, focusing specifically on predicting Proppian narrative functions. Our experiments on a dataset of Russian fairy tales show that our system outperforms an informed baseline and that combining top-down narrative theory and bottom-up statistical models inferred from an annotated dataset increases prediction accuracy with respect to using them in isolation.","['supervised machine learning', 'statistical models']",Classic Machine Learning,1,1
https://openalex.org/W2727343154,W2727343154,,https://doi.org/10.18260/1-2--13929,"Development Of The Textbook, Conservation Principles In Bioengineering","Abstract NOTE: The first page of text has been automatically extracted and included below in lieu of an abstract Session 1309 Development of the Textbook, Conservation Principles in Bioengineering Ann Saterbak,1 Ka-Yiu San,1 Larry V. McIntire2 1 Department of Bioengineering, Rice University, Houston TX 77005 2 Department of Biomedical Engineering, Georgia Tech, Atlanta GA 30332 Summary The textbook, Conservation Principles in Bioengineering, which covers the conservation laws with applications in biological and medical systems, has been written. Its publication by Prentice Hall is expected in 2005. The conservation laws of mass, energy, charge and momentum form the foundation of engineering. Focusing on applications in biological systems to teach these conservation laws provides a new and unifying approach to the introductory, interdisciplinary fundamentals course in Biomedical Engineering departments. Chapters 1 and 2 provide exposure to bioengineering problems and motivation for a quantitative engineering approach. The manuscript begins with a basic review of engineering calculations with an emphasis on elaborating the physical variables, which are introduced in the context of different biomedical technologies. The fundamental framework of the conservation laws is described in Chapter 2. Chapters 3-6 cover conservation of mass, energy, charge, and momentum in biomedical systems. Each chapter begins with a challenge problem that present a current bioengineering design challenge. Within each chapter, basic concepts are reviewed, and the accounting and conservation equations are restated and explicitly formulated for the property of interest. Open, closed, steady-state, dynamic, reacting and non-reacting systems are covered. The derivation of Kirchhoff’s current and voltage laws, Newton’s laws of motions, Bernoulli’s equation, and others from the key accounting and conservation equations are also presented. The text deliberately includes ten or more worked examples per chapter that span physiology, kinematics, biomaterials, cellular engineering, instrumentation, imaging, and biotechnology. Presently, each chapter has 25-40 homework problems. One unique feature of this textbook is the inclusion of three case studies in Chapter 7 that integrate the different conservation applications of mass, energy, charge, and momentum. The case studies include the heart, the lungs, and the kidneys. Problem-based learning (PBL) modules on these systems are being developed as part of a NSF Division of Undergraduate Education grant. The effectiveness of the textbook and students’ progress toward established educational goals are being assessed in several bioengineering departments across the country where the manuscript is Proceedings of the 2004 American Society for Engineering Education Annual Conference & Exposition Copyright 2004, American Society of Engineering Education","['Conservation Laws', 'Engineering Calculations', 'Physical Variables', 'Biomedical Technologies', 'Conservation of Mass', 'Energy', 'Charge', 'Momentum']",Other,,
https://openalex.org/W2887300797,W2887300797,,https://doi.org/10.2139/ssrn.3685748,Modelling Systemic Risk Using Neural Network Quantile Regression,"We propose a novel approach to calibrate the conditional value-at-risk (CoVaR) of financial institutions based on neural network quantile regression. Building on the estimation results, we model systemic risk spillover effects in a network context across banks by considering the marginal effects of the quantile regression procedure. An out-of-sample analysis shows great performance compared to a linear baseline specification, signifying the importance that nonlinearity plays for modelling systemic risk. We then propose three network-based measures from our fitted results. First, we use the Systemic Network Risk Index (SNRI) as a measure for total systemic risk. A comparison to existing network-based risk measures reveals that our approach offers a new perspective on systemic risk due to the focus on the lower tail and to the allowance for nonlinear effects. We also introduce the Systemic Fragility Index (SFI) and the Systemic Hazard Index (SHI) as firm-specific measures, which allow us to identify systemically relevant firms during the financial crisis.","['quantile regression', 'neural network']",Classic AI & Neural Network Architectures,,
https://openalex.org/W2891162071,W2891162071,,https://doi.org/10.18260/1-2--29638,Identifying the Best Admission Criteria for Data Science Using Machine Learning,"Abstract Big data is taking the world by storm. What we can do today with the abundant of data and the available technology is extraordinary. Big data analytics has become a game changer in many industries: Healthcare analytics has the potential to reduce cost and improve the quality of patientcare; Insurance companies use data analytics for risk assessment and fraud detection; Legal analytics has made it possible for law professionals to gain deep insight from past litigations to develop better informed strategies and improve efficiency. Number of industries employing big data analytics to improve business decisions is countless. Due to utilization of analytics by large array of industries, this field has attracted many people from diverse academic backgrounds to purse a degree in Analytics and Data Science. Considering this tremendous demand for data scientists, our institution launched a Masters degree in Data Science in 2014. This is a two-year program covering courses in rigorous Math and programming, as well as courses entailing soft skills such as visual storytelling and consulting skills. One of the challenges that has faced faculty on the admission committee in the past few years is selecting the right criteria for student admission. Typically, in engineering disciplines the admission decision is based on students’ performance on courses such as calculus, physics and pre-engineering topics. However, due to the nature of Data Science field the applicants come from very diverse undergraduate programs. For instance, some of our top graduating students had an undergraduate degree in Creative Writing or Healthcare. We have witnessed many cases in which the admission criteria that are commonly used in other technical fields did not necessarily translate to identification of successful candidates for the Data Science program. Finding the right students who will be successful in this program is crucial both for the candidates and the university to save resources. The objective of this study is to identify a set of rules based on previous admission decisions and achievement of admitted students to capture the characteristics of a successful admission. We apply statistical and machine learning techniques (using 4 cohorts’ information for training and 1 cohort for test) to provide us with a better set of guidelines for future admission processes.","['statistical methods', 'machine learning techniques']",Classic Machine Learning,,
https://openalex.org/W2896182080,W2896182080,,https://doi.org/10.5040/9781350258587,The Principles and Processes of Interactive Design,"<JATS1:p>This much anticipated second edition of The Principles and Processes of Interactive Design is aimed at new designers and creatives from across the design and media disciplines who want to learn the fundamentals of designing for user experience and user interface (UX/UI) projects.</JATS1:p> <JATS1:p>The blurring of boundaries between disciplines is leading to a new breed of hybrid designers and creative practitioners who are fusing different discipline perspectives, principles and processes to support their new practices.</JATS1:p> <JATS1:p>It is these shared principles and processes that this book explores, including: - The fundamentals of design research and UX development- Classic visual design topics such as colour, image, layout and typography- Essential media-specific topics such as working with data, interactivity, motion and sound- Important guidance on how to present your work</JATS1:p> <JATS1:p>For this new editions there are brand new chapters on Motion and Sound (including storyboarding, sonic interaction and UX storytelling), Data (including data as a material, AI and anticipatory design) and Interactivity (including accessibility, gesture control and voice UI).</JATS1:p> <JATS1:p>With over 150 inspirational examples from a diverse range of leading international creatives and award-winning agencies, this is a must-have guide for budding designers. In addition, industry perspectives from key design professionals provide fascinating insights into this exciting creative field. Each chapter concludes with a workshop tutorial to help you put what you’ve learnt into practice.</JATS1:p>",['AI'],New Generation of AI,,
https://openalex.org/W2906822812,W2906822812,,https://doi.org/10.1109/jstars.2020.3011907,Deepti: Deep-Learning-Based Tropical Cyclone Intensity Estimation System,"Tropical cyclones are one of the costliest natural disasters globally because of the wide range of associated hazards. Thus, an accurate diagnostic model for tropical cyclone intensity can save lives and property. There are a number of existing techniques and approaches that diagnose tropical cyclone wind speed using satellite data at a given time with varying success. This article presents a deep-learning-based objective, diagnostic estimate of tropical cyclone intensity from infrared satellite imagery with 13.24-kn root mean squared error. In addition, a visualization portal in a production system is presented that displays deep learning output and contextual information for end users, one of the first of its kind.","['Deep-learning-based', 'Infrared satellite imagery', 'Visualization portal']",Classic Deep Learning,,
https://openalex.org/W2917321954,W2917321954,,https://doi.org/10.1145/3574318.3574319,Overview of the FIRE 2022 track: Information Retrieval from Microblogs during Disasters (IRMiDis),"Microblogging sites such as Twitter play an important role in dealing with various mass emergencies including natural disasters and pandemics. Over the last several years, the track on Information Retrieval from Microblogs during Disasters (IRMiDis), organized as part of the FIRE conference series, has provided annotated datasets for developing ML/NLP techniques for utilizing microblogs for various practical tasks that would help authorities better deal with disaster situations. In particular, the FIRE 2022 IRMiDis track focused on two important tasks – (i) to detect the vaccine-related stance of tweets related to COVID-19 vaccines, and (ii) to detect reporting of COVID-19 symptom in tweets.","['Logistic Regression', 'Support Vector Machines (SVMs)']",Classic Machine Learning,,
https://openalex.org/W2922771925,W2922771925,,https://doi.org/10.1111/ecno.12181,GDP‐network CoVaR: A tool for assessing growth‐at‐risk,"Abstract We propose a tool to predict risks to economic growth and international business cycles spillovers: the gross domestic product (GDP)‐Network conditional value at risk (CoVaR). Our methodology to assess Growth‐at‐Risk is composed of two building blocks. In the first step, we apply a machine learning methodology, namely the network‐based NETS by Barigozzi and Brownlees, to identify significant linkages between pair of countries. In the second step, applying the CoVaR methodology by Adrian and Brunnermeier, and exploiting international statistics on trade flows and GDPs, we derive the entire distribution of Economic Growth spillover exposures at the bilateral, country and global level for different quantiles of tail events on economic growth. We find that Economic Growth Spillover probability distribution is time‐varying, left‐skewed and in some cases bi‐ or even multi‐modal. Second, we prove that our two‐step approach outperforms alternative one‐step quantile regression models in predicting risks to economic growth. Finally, we show that Global exposure to economic growth tail events is decreasing over time.","['NETS', 'CoVaR']",Classic Machine Learning,,
https://openalex.org/W2937082058,W2937082058,,https://doi.org/10.5194/acp-20-2303-2020,Technical note: Deep learning for creating surrogate models of precipitation in Earth system models,"Abstract. We investigate techniques for using deep neural networks to produce surrogate models for short-term climate forecasts. A convolutional neural network is trained on 97 years of monthly precipitation output from the 1pctCO2 run (the CO2 concentration increases by 1 % per year) simulated by the second-generation Canadian Earth System Model (CanESM2). The neural network clearly outperforms a persistence forecast and does not show substantially degraded performance even when the forecast length is extended to 120 months. The model is prone to underpredicting precipitation in areas characterized by intense precipitation events. Scheduled sampling (forcing the model to gradually use its own past predictions rather than ground truth) is essential for avoiding amplification of early forecasting errors. However, the use of scheduled sampling also necessitates preforecasting (generating forecasts prior to the first forecast date) to obtain adequate performance for the first few prediction time steps. We document the training procedures and hyperparameter optimization process for researchers who wish to extend the use of neural networks in developing surrogate models.",['Convolutional Neural Networks (CNNs)'],Classic AI & Neural Network Architectures,,
https://openalex.org/W2947720450,W2947720450,,https://doi.org/10.3390/rs12060900,High-Resolution Inundation Mapping for Heterogeneous Land Covers with Synthetic Aperture Radar and Terrain Data,"Floods are one of the most wide-spread, frequent, and devastating natural disasters that continue to increase in frequency and intensity. Remote sensing, specifically synthetic aperture radar (SAR), has been widely used to detect surface water inundation to provide retrospective and near-real time (NRT) information due to its high-spatial resolution, self-illumination, and low atmospheric attenuation. However, the efficacy of flood inundation mapping with SAR is susceptible to reflections and scattering from a variety of factors including dense vegetation and urban areas. In this study, the topographic dataset Height Above Nearest Drainage (HAND) was investigated as a potential supplement to Sentinel-1A C-Band SAR along with supervised machine learning to improve the detection of inundation in heterogeneous areas. Three machine learning classifiers were trained on two sets of features dual-polarized SAR only and dual-polarized SAR along with HAND to map inundated areas. Three study sites along the Neuse River in North Carolina, USA during the record flood of Hurricane Matthew in October 2016 were selected. The binary classification analysis (inundated as positive vs. non-inundated as negative) revealed significant improvements when incorporating HAND in several metrics including classification accuracy (ACC) (+36.0%), critical success index (CSI) (+39.95%), true positive rate (TPR) (+42.02%), and negative predictive value (NPV) (+17.26%). A marginal change of +0.15% was seen for positive predictive value (PPV), but true negative rate (TNR) fell −14.4%. By incorporating HAND, a significant number of areas with high SAR backscatter but low HAND values were detected as inundated which increased true positives. This in turn also increased the false positives detected but to a lesser extent as evident in the metrics. This study demonstrates that HAND could be considered a valuable feature to enhance SAR flood inundation mapping especially in areas with heterogeneous land covers with dense vegetation that interfere with SAR.","['Supervised Machine Learning', 'classifiers']",Classic Machine Learning,,
https://openalex.org/W2948167981,W2948167981,,https://doi.org/10.5194/acp-20-3439-2020,Characterization of the radiative impact of aerosols on CO&amp,"Abstract. In vegetation canopies with complex architectures, diffuse solar radiation can enhance carbon assimilation through photosynthesis because isotropic light is able to reach deeper layers of the canopy. Although this effect has been studied in the past decade, the mechanisms and impacts of this enhancement over South America remain poorly understood. Over the Amazon deforestation arch large amounts of aerosols are released into the atmosphere due to biomass burning, which provides an ideal scenario for further investigation of this phenomenon in the presence of canopies with complex architecture. In this paper, the relation of aerosol optical depth and surface fluxes of mass and energy are evaluated over three study sites with artificial neural networks and radiative transfer modeling. Results indicate a significant effect of the aerosol on the flux of carbon dioxide between the vegetation and the atmosphere, as well as on energy exchange, including that surface fluxes are sensitive to second-order radiative impacts of aerosols on temperature, humidity, and friction velocity. CO2 exchanges increased in the presence of aerosol in up to 55 % in sites with complex canopy architecture. A decrease of approximately 12 % was observed for a site with shorter vegetation. Energy fluxes were negatively impacted by aerosols over all study sites.",['artificial neural networks'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W2965580012,W2965580012,,https://doi.org/10.1029/2019ms001958,Analog Forecasting of Extreme‐Causing Weather Patterns Using Deep Learning,"Abstract Numerical weather prediction models require ever‐growing computing time and resources but, still, have sometimes difficulties with predicting weather extremes. We introduce a data‐driven framework that is based on analog forecasting (prediction using past similar patterns) and employs a novel deep learning pattern‐recognition technique (capsule neural networks, CapsNets) and an impact‐based autolabeling strategy. Using data from a large‐ensemble fully coupled Earth system model, CapsNets are trained on midtropospheric large‐scale circulation patterns (Z500) labeled 0–4 depending on the existence and geographical region of surface temperature extremes over North America several days ahead. The trained networks predict the occurrence/region of cold or heat waves, only using Z500, with accuracies (recalls) of 69–45% (77–48%) or 62–41% (73–47%) 1–5 days ahead. Using both surface temperature and Z500, accuracies (recalls) with CapsNets increase to 80% (88%). In both cases, CapsNets outperform simpler techniques such as convolutional neural networks and logistic regression, and their accuracy is least affected as the size of the training set is reduced. The results show the promises of multivariate data‐driven frameworks for accurate and fast extreme weather predictions, which can potentially augment numerical weather prediction efforts in providing early warnings.",['CapsNets'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W2970088747,W2970088747,,https://doi.org/10.1101/2020.12.13.422580,Characterization of habitat requirements of European fishing spiders,"Abstract Wetlands are among the most threatened habitats in the world, and so are their species, which suffer habitat loss due to climate and land use changes. Freshwater species and arthropods receive little attention in research and conservation, and the goals to stop and reverse the destruction of wetlands published 25 years ago in a manifesto by the Union of Concerned Scientists have not been reached. In this study, we investigated the occurrence and habitat requirements at two spatial scales of two species of European fishing spiders Dolomedes , which rely heavily on declining wetland habitats in Sweden and southern Norway. We collected occurrence data for Dolomedes plantarius and Dolomedes fimbriatus , using a live-determination-method. We modelled the placement of nursery webs to describe fine scaled habitat requirements related to vegetation and microclimate. Using a machine learning approach, we described the habitat features for each species, and for co-occurrence sites, to provide insight into variables relevant for the detectability of Dolomedes . We found that habitat requirements were narrower for D. plantarius compared to D. fimbriatus ; that the detection of nursery webs can be affected by weather conditions and that nursery placement is mostly dependent on the proximity to water, the presence of Carex sp. (Sedges) and of crossing vegetation structures, and on humidity. Furthermore, co-occurring sites were more similar to D. plantarius sites than to D. fimbriatus sites, whereby surrounding forest, water type and velocity, elevation and latitude were of importance for explaining which species of Dolomedes was present. We provide a detailed field protocol for Dolomedes studies, including a novel live-determination method, and recommendations for future field protocols.","['machine learning', 'feature engineering']",Classic Machine Learning,1,1
https://openalex.org/W2972978269,W2972978269,,https://doi.org/10.5194/acp-20-1607-2020,"Evaluation of aerosol and cloud properties in three climate models using MODIS observations and its corresponding COSP simulator, as well as their application in aerosol–cloud interactions","Abstract. The evaluation of modelling diagnostics with appropriate observations is an important task that establishes the capabilities and reliability of models. In this study we compare aerosol and cloud properties obtained from three different climate models (ECHAM-HAM, ECHAM-HAM-SALSA, and NorESM) with satellite observations using Moderate Resolution Imaging Spectroradiometer (MODIS) data. The simulator MODIS-COSP version 1.4 was implemented into the climate models to obtain MODIS-like cloud diagnostics, thus enabling model-to-model and model-to-satellite comparisons. Cloud droplet number concentrations (CDNCs) are derived identically from MODIS-COSP-simulated and MODIS-retrieved values of cloud optical depth and effective radius. For CDNC, the models capture the observed spatial distribution of higher values typically found near the coasts, downwind of the major continents, and lower values over the remote ocean and land areas. However, the COSP-simulated CDNC values are higher than those observed, whilst the direct model CDNC output is significantly lower than the MODIS-COSP diagnostics. NorESM produces large spatial biases for ice cloud properties and thick clouds over land. Despite having identical cloud modules, ECHAM-HAM and ECHAM-HAM-SALSA diverge in their representation of spatial and vertical distributions of clouds. From the spatial distributions of aerosol optical depth (AOD) and aerosol index (AI), we find that NorESM shows large biases for AOD over bright land surfaces, while discrepancies between ECHAM-HAM and ECHAM-HAM-SALSA can be observed mainly over oceans. Overall, the AIs from the different models are in good agreement globally, with higher negative biases in the Northern Hemisphere. We evaluate the aerosol–cloud interactions by computing the sensitivity parameter ACICDNC=dln⁡(CDNC)/dln⁡(AI) on a global scale. However, 1 year of data may be considered not enough to assess the similarity or dissimilarities of the models due to large temporal variability in cloud properties. This study shows how simulators facilitate the evaluation of cloud properties and expose model deficiencies, which are necessary steps to further improve the parameterisation in climate models.","['MODIS-COSP', 'Cloud Droplet Number Concentrations (CDNC)', 'Climate Models', 'Satellite Observations', 'Bias Analysis']",Other,1,1
https://openalex.org/W2981064878,W2981064878,,https://doi.org/10.1007/978-3-030-36841-8_5,Deep Learning and Machine Learning in Hydrological Processes Climate Change and Earth Systems a Systematic Review,,,,N/A,N/A
https://openalex.org/W2981066841,W2981066841,,https://doi.org/10.5194/acp-20-7125-2020,Linking large-scale circulation patterns to low-cloud properties,"Abstract. The North Pacific High (NPH) is a fundamental meteorological feature present during the boreal warm season. Marine boundary layer (MBL) clouds, which are persistent in this oceanic region, are influenced directly by the NPH. In this study, we combine 11 years of reanalysis and an unsupervised machine learning technique to examine the gamut of 850 hPa synoptic-scale circulation patterns. This approach reveals two distinguishable regimes – a dominant NPH setup and a land-falling cyclone – and in between a spectrum of large-scale patterns. We then use satellite retrievals to elucidate for the first time the explicit dependence of MBL cloud properties (namely cloud droplet number concentration, liquid water path, and shortwave cloud radiative effect – CRESW) on 850 hPa circulation patterns over the northeast Pacific Ocean. We find that CRESW spans from −146.8 to −115.5 W m−2, indicating that the range of observed MBL cloud properties must be accounted for in global and regional climate models. Our results demonstrate the value of combining reanalysis and satellite retrievals to help clarify the relationship between synoptic-scale dynamics and cloud physics.",['unsupervised machine learning'],Classic Machine Learning,1,1
https://openalex.org/W2982539576,W2982539576,,https://doi.org/10.4337/9781789900057.00014,"New ways of valuing ecosystem services: big data, machine learning, and the value of urban green spaces","There is considerable policy interest to integrate the value of ecosystem services into systems of national accounts. Urban green spaces are traditionally valued by merging spatial household data with administrative data on land use to obtain their amount around households; this is then related to residential wellbeing or real estate prices to arrive at a monetary valuation. This traditional approach, however, neglects not only the large heterogeneity in the quality of urban green spaces but also issues of measuring outcomes and issues of reverse causality. We discuss new data and methods to overcome some of these issues. We focus on the use of high-frequency experience-sampling methods on wellbeing or web-scraped real estate prices to better understand impacts; big data from crowdsourced imagery of urban green spaces or satellite imagery of chlorophyll activity to better understand quality; and machine learning to make better use of data. Finally, we discuss the potential of field experiments and quasi-experiments to deal with reverse causality. Together, these approaches can greatly complement our traditional toolkit for valuing ecosystem services.",['machine learning'],Classic Machine Learning,1,1
https://openalex.org/W2989635319,W2989635319,,https://doi.org/10.3389/fenrg.2019.00147,Strategic Research on the Urban Natural Gas Energy System Under the Path to Ecological Civilization: Fuyang City Case Study,"To help meet the strategic development needs of urban energy systems today and reduce carbon emissions, natural gas can play a pivotal transition role, especially in a country such as China which has relied very heavily on coal for decades. Though making significant towards the maximum possible use of clean, renewable forms of energy, such as hydro, thermal, solar and wind power, it will be a long time yet before China can completely abandon the use of fossil fuels. . In this paper, using Fuyang City in Anhui Province as a case study, a four-dimensional differential equation model, based on the consumption, price, economic growth, and ""ecological civilization construction"" of natural gas energy, is developed which incorporates concepts and calculations of natural gas energy intensity, ""natural gas ecological civilization intensity"", and ""economic ecological civilization intensity"". It is the first attempt ever made to quantify the construction of urban ecological civilization and discuss the evolutionary relationship among the internal variables of the system . Regression analysis, data fitting, neural network, and other methods are used to confirm the parameters of the system model. Through Matlab simulation of each variable and using an evolution map, a quantitative understanding of the role of natural gas is generated. The research findings reveal that paying attention to the environmental aspects of energy consumption is beneficial to economic growth. The paper concludes that, at present, the best ways for China to reduce its carbon emissions are to implement a market price and peak–valley prices for natural gas, improve the tiered price mechanism, appropriately reduce the economic growth rate, continue to adjust the industrial structure away from heavy industry and scientifically manage the natural gas energy system. These reforms are of great practical significance in working towards a sustainable development path for the city.","['regression analysis', 'neural network']",Classic AI & Neural Network Architectures,1,1
https://openalex.org/W2991298899,W2991298899,,https://doi.org/10.5194/tc-14-1209-2020,Unprecedented atmospheric conditions (1948–2019) drive the 2019 exceptional melting season over the Greenland ice sheet,"Abstract. Understanding the role of atmospheric circulation anomalies on the surface mass balance of the Greenland ice sheet (GrIS) is fundamental for improving estimates of its current and future contributions to sea level rise. Here, we show, using a combination of remote sensing observations, regional climate model outputs, reanalysis data, and artificial neural networks, that unprecedented atmospheric conditions (1948–2019) occurring in the summer of 2019 over Greenland promoted new record or close-to-record values of surface mass balance (SMB), runoff, and snowfall. Specifically, runoff in 2019 ranked second within the 1948–2019 period (after 2012) and first in terms of surface mass balance negative anomaly for the hydrological year 1 September 2018–31 August 2019. The summer of 2019 was characterized by an exceptional persistence of anticyclonic conditions that, in conjunction with low albedo associated with reduced snowfall in summer, enhanced the melt–albedo feedback by promoting the absorption of solar radiation and favored advection of warm, moist air along the western portion of the ice sheet towards the north, where the surface melt has been the highest since 1948. The analysis of the frequency of daily 500 hPa geopotential heights obtained from artificial neural networks shows that the total number of days with the five most frequent atmospheric patterns that characterized the summer of 2019 was 5 standard deviations above the 1981–2010 mean, confirming the exceptional nature of the 2019 season over Greenland.",['artificial neural networks'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W2993514765,W2993514765,,https://doi.org/10.1029/2019ms002002,Physically Interpretable Neural Networks for the Geosciences: Applications to Earth System Variability,"Neural networks have become increasingly prevalent within the geosciences, although a common limitation of their usage has been a lack of methods to interpret what the networks learn and how they make decisions. As such, neural networks have often been used within the geosciences to most accurately identify a desired output given a set of inputs, with the interpretation of what the network learns used as a secondary metric to ensure the network is making the right decision for the right reason. Neural network interpretation techniques have become more advanced in recent years, however, and we therefore propose that the ultimate objective of using a neural network can also be the interpretation of what the network has learned rather than the output itself. We show that the interpretation of neural networks can enable the discovery of scientifically meaningful connections within geoscientific data. In particular, we use two methods for neural network interpretation called backwards optimization and layerwise relevance propagation, both of which project the decision pathways of a network back onto the original input dimensions. To the best of our knowledge, LRP has not yet been applied to geoscientific research, and we believe it has great potential in this area. We show how these interpretation techniques can be used to reliably infer scientifically meaningful information from neural networks by applying them to common climate patterns. These results suggest that combining interpretable neural networks with novel scientific hypotheses will open the door to many new avenues in neural network-related geoscience research.","['Backwards optimization', 'Layerwise relevance propagation']",New Generation of AI,1,1
https://openalex.org/W2996767420,W2996767420,,https://doi.org/10.1088/1742-6596/1427/1/012004,Harnessing technology for mitigating water woes in the city of Bengaluru,"Abstract Industrialization has caused most of the world’s environmental problems like climate change, water security issues, biodiversity issues among others. Water-related issues like water scarcity, lack of water quality, water sanitation issues, lack of proper water resources management are some of them. Urbanization, population increase, pollution has led to an increase in water demand. Water being the elixir of life, is essential for the day-to-day living of an individual. The Fourth Industrial Revolution technologies like AI, IoT, Blockchain, Machine Learning have the capability of bringing solutions to these issues. The current study focuses on the water woes of Bengaluru, a fast-growing urban city, due to its migrating population. The woes are also due to the irresponsible behaviour of builders converting lakes into real estate infrastructure leading to clogged drains, excess sewage creation and flooding. A huge mismatch between demand and supply of water is created due to these issues. Before the city hits the Day Zero – no water day, it is significant to set up water infrastructure along with technology implementation which will help resolve this burning issue at the earliest.",['AI'],Classic Machine Learning,1,0
https://openalex.org/W2996821337,W2996821337,,,Social Media Attributions in the Context of Water Crisis,"Attribution of natural disasters/collective misfortune is a widely-studied political science problem. However, such studies are typically survey-centric or rely on a handful of experts to weigh in on the matter. In this paper, we explore how can we use social media data and an AI-driven approach to complement traditional surveys and automatically extract attribution factors. We focus on the most-recent Chennai water crisis which started off as a regional issue but rapidly escalated into a discussion topic with global importance following alarming water-crisis statistics. Specifically, we present a novel prediction task of attribution tie detection which identifies the factors held responsible for the crisis (e.g., poor city planning, exploding population etc.). On a challenging data set constructed from YouTube comments (72,098 comments posted by 43,859 users on 623 relevant videos to the crisis), we present a neural classifier to extract attribution ties that achieved a reasonable performance (Accuracy: 81.34\% on attribution detection and 71.19\% on attribution resolution).",['neural classifier'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W2996821337,W2996821337,,,Social Media Attributions in the Context of Water Crisis,"Attribution of natural disasters/collective misfortune is a widely-studied political science problem. However, such studies are typically survey-centric or rely on a handful of experts to weigh in on the matter. In this paper, we explore how can we use social media data and an AI-driven approach to complement traditional surveys and automatically extract attribution factors. We focus on the most-recent Chennai water crisis which started off as a regional issue but rapidly escalated into a discussion topic with global importance following alarming water-crisis statistics. Specifically, we present a novel prediction task of attribution tie detection which identifies the factors held responsible for the crisis (e.g., poor city planning, exploding population etc.). On a challenging data set constructed from YouTube comments (72,098 comments posted by 43,859 users on 623 relevant videos to the crisis), we present a neural classifier to extract attribution ties that achieved a reasonable performance (Accuracy: 81.34\% on attribution detection and 71.19\% on attribution resolution).",['neural classifier'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W2997288388,W2997288388,,https://doi.org/10.2514/6.2020-1862,Comprehensive Piezoelectric Material Application Issues on Energy Harvesting for Artificial Intelligence Systems,"Artificial intelligence (AI) technologies are integrated into various modem devices and systems to make our living more convenience and comfortable. The initial of a fully functional AI system is integrated with computer, sensor network, actuator (robotic), and electrical power for the hardware components. For many situations, city power sources might not available. Therefore, a reliable, renewable and sustainable, local power generators-based self-powered AI system is desired. Piezoelectric energy harvesting (PEH) technology, which use piezoelectric material-based device to harvest vibration/motion mechanical energy to electrical energy has the highest possibility to make self-powered AI system since 1) vibration/motion mechanical energy is unique that not weather dependent, 2) PEH can harvest either tiny or massive vibration/motion mechanical energy into electrical energy. The piezoelectric materials are materials that generate electrical charges when a mechanical stress or force is exerted on them, on the other hand, they deformation when an electric voltage is applied on it. The implementation of piezoelectric materials-based energy harvesters are effective devices that promises future engineering systems that are more intelligent, reliable and environment friendly. However, designing a piezoelectric device is complicated and require comprehensive understating of many engineering disciplines including mechanical engineering, electrical engineering, materials sciences, and device physics. This paper offers a comprehensive discussion on the major piezoelectric materials and devices classifications as well as the state-of-the-art designs. In addition, the performance of various PEH devices are also summarized.","['Piezoelectric materials', 'Energy harvesters', 'Device classifications', 'Performance summaries']",Other,1,1
https://openalex.org/W2997297439,W2997297439,,https://doi.org/10.1609/aaai.v34i02.5538,Draft and Edit: Automatic Storytelling Through Multi-Pass Hierarchical Conditional Variational Autoencoder,"Automatic Storytelling has consistently been a challenging area in the field of natural language processing. Despite considerable achievements have been made, the gap between automatically generated stories and human-written stories is still significant. Moreover, the limitations of existing automatic storytelling methods are obvious, e.g., the consistency of content, wording diversity. In this paper, we proposed a multi-pass hierarchical conditional variational autoencoder model to overcome the challenges and limitations in existing automatic storytelling models. While the conditional variational autoencoder (CVAE) model has been employed to generate diversified content, the hierarchical structure and multi-pass editing scheme allow the story to create more consistent content. We conduct extensive experiments on the ROCStories Dataset. The results verified the validity and effectiveness of our proposed model and yields substantial improvement over the existing state-of-the-art approaches.",['Conditional Variational Autoencoder'],New Generation of AI,1,1
https://openalex.org/W2998696763,W2998696763,,https://doi.org/10.1101/2020.01.03.894071,A semi-automated machine learning-aided approach to quantitative analysis of centrosomes and microtubule organization,"ABSTRACT Microtubules (MTs) perform important cellular functions including migration, intracellular trafficking, and chromosome segregation. The centrosome, comprised of two centrioles surrounded by the pericentriolar material (PCM), is the cell’s central MT organizing center. The PCM proteins, including γ -tubulin and Pericentrin, promote MT nucleation and organization. Centrosomes in cancer cells are commonly numerically amplified. However, the question of how amplification of centrosomes alters the MT organization capacity is not well-studied. We developed a quantitative image-processing and machine learning-aided approach for the automated analysis of MT organization. We designed a convolutional neural network-based approach for detecting centrosomes and an automated pipeline for analyzing MT organization around centrosomes, encapsulated in a semi-automatic graphical tool. Using this tool, we analyzed the spatial distribution of PCM proteins, the growing ends of MTs and the total MT density in breast cancer cells. We find that breast cancer cells with supernumerary centrosomes not only have increased PCM protein but also exhibit expansion in PCM size. Moreover, centrosome amplified cells have a greater MT density and more growing MT ends near centrosomes than unamplified cells. The semi-automated approach developed here enables facile, unbiased and quantitative measurements of centrosome aberrations. We show that these aberrations increase MT nucleation and promote changes to MT density and the spatial distribution of MTs around amplified centrosomes.",['Convolutional Neural Networks (CNNs)'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W2998741341,W2998741341,,https://doi.org/10.1051/shsconf/20207402015,Technological Change and Innovation as Security Threats,"Technological change and innovation, together with the related development of science, have been perceived as drivers of social and economic progress and public optimism in the globalizing world. Indeed, in the past centuries and especially decades, there has been a huge advancement of humankind that can be both felt and measured. However, people have also learned that science and technology can be misused or abused, or they can have unintended consequences (cf. nuclear fission). Especially in times when the public feels that the change is fast and unprecedented, they also provoke fear and resentment. Science, technological change, and innovation can be presented and perceived as security threats, i.e. securitized. It seems that, now, we are living in one of such historical periods. The goal of the paper is to analyse if and how technological change and innovation are presented or perceived as security threats, especially in the Czech political and public discourse. To reach the goal, we can ask the following research questions: Are science, technological change, and innovation securitized? What are the concrete examples of emerging technologies and innovations that are securitized? (e.g. artificial intelligence and robotics, biotechnologies) Is the narrative present in the Czech political and public discourse? Is the securitization process successful? What are the lessons learned and recommendations for policy?",['artificial intelligence'],Other,1,1
https://openalex.org/W2998893621,W2998893621,,https://doi.org/10.1074/mcp.ra119.001667,Discovery of Species-unique Peptide Biomarkers of Bacterial Pathogens by Tandem Mass Spectrometry-based Proteotyping,"Mass spectrometry (MS) and proteomics offer comprehensive characterization and identification of microorganisms and discovery of protein biomarkers that are applicable for diagnostics of infectious diseases. The use of biomarkers for diagnostics is widely applied in the clinic and the use of peptide biomarkers is increasingly being investigated for applications in the clinical laboratory. Respiratory-tract infections are a predominant cause for medical treatment, although, clinical assessments and standard clinical laboratory protocols are time-consuming and often inadequate for reliable diagnoses. Novel methods, preferably applied directly to clinical samples, excluding cultivation steps, are needed to improve diagnostics of infectious diseases, provide adequate treatment and reduce the use of antibiotics and associated development of antibiotic resistance. This study applied nano-liquid chromatography (LC) coupled with tandem MS, with a bioinformatics pipeline and an in-house database of curated high-quality reference genome sequences to identify species-unique peptides as potential biomarkers for four bacterial pathogens commonly found in respiratory tract infections (RTIs): Staphylococcus aureus; Moraxella catarrhalis; Haemophilus influenzae and Streptococcus pneumoniae. The species-unique peptides were initially identified in pure cultures of bacterial reference strains, reflecting the genomic variation in the four species and, furthermore, in clinical respiratory tract samples, without prior cultivation, elucidating proteins expressed in clinical conditions of infection. For each of the four bacterial pathogens, the peptide biomarker candidates most predominantly found in clinical samples, are presented. Data are available via ProteomeXchange with identifier PXD014522. As proof-of-principle, the most promising species-unique peptides were applied in targeted tandem MS-analyses of clinical samples and their relevance for identifications of the pathogens, i.e. proteotyping, was validated, thus demonstrating their potential as peptide biomarker candidates for diagnostics of infectious diseases. Mass spectrometry (MS) and proteomics offer comprehensive characterization and identification of microorganisms and discovery of protein biomarkers that are applicable for diagnostics of infectious diseases. The use of biomarkers for diagnostics is widely applied in the clinic and the use of peptide biomarkers is increasingly being investigated for applications in the clinical laboratory. Respiratory-tract infections are a predominant cause for medical treatment, although, clinical assessments and standard clinical laboratory protocols are time-consuming and often inadequate for reliable diagnoses. Novel methods, preferably applied directly to clinical samples, excluding cultivation steps, are needed to improve diagnostics of infectious diseases, provide adequate treatment and reduce the use of antibiotics and associated development of antibiotic resistance. This study applied nano-liquid chromatography (LC) coupled with tandem MS, with a bioinformatics pipeline and an in-house database of curated high-quality reference genome sequences to identify species-unique peptides as potential biomarkers for four bacterial pathogens commonly found in respiratory tract infections (RTIs): Staphylococcus aureus; Moraxella catarrhalis; Haemophilus influenzae and Streptococcus pneumoniae. The species-unique peptides were initially identified in pure cultures of bacterial reference strains, reflecting the genomic variation in the four species and, furthermore, in clinical respiratory tract samples, without prior cultivation, elucidating proteins expressed in clinical conditions of infection. For each of the four bacterial pathogens, the peptide biomarker candidates most predominantly found in clinical samples, are presented. Data are available via ProteomeXchange with identifier PXD014522. As proof-of-principle, the most promising species-unique peptides were applied in targeted tandem MS-analyses of clinical samples and their relevance for identifications of the pathogens, i.e. proteotyping, was validated, thus demonstrating their potential as peptide biomarker candidates for diagnostics of infectious diseases. Respiratory tract infections (RTIs) 1The abbreviations used are:RTIrespiratory tract infectionAMRantimicrobial resistanceTCUPtyping and characterization of bacteria using bottom-up tandem MS proteomicsHRAMhigh-resolution accurate-massLPIlipid-based protein immobilizationANIaverage nucleotide identityBLASTBasic Local Alignment Search ToolSDCsodium deoxycholateNCBINational Center for Biotechnology InformationPRMparallel reaction monitoringSRMselected reaction monitoringMRMmultiple reaction monitoring. 1The abbreviations used are:RTIrespiratory tract infectionAMRantimicrobial resistanceTCUPtyping and characterization of bacteria using bottom-up tandem MS proteomicsHRAMhigh-resolution accurate-massLPIlipid-based protein immobilizationANIaverage nucleotide identityBLASTBasic Local Alignment Search ToolSDCsodium deoxycholateNCBINational Center for Biotechnology InformationPRMparallel reaction monitoringSRMselected reaction monitoringMRMmultiple reaction monitoring. are a major reason for hospital admissions and are often treated with antibiotics (1Kronman M.P. Zhou C. Mangione-Smith R. Bacterial prevalence and antimicrobial prescribing trends for acute respiratory tract infections.Pediatrics. 2014; 134: e956-e965Crossref PubMed Scopus (102) Google Scholar). Today, a clinical assessment performed by the physician, is mainly based on symptoms, together with supporting clinical laboratory microbiological confirmation (2van Houten C.B. de Groot J.A.H. Klein A. Srugo I. Chistyakov I. de Waal W. Meijssen C.B. Avis W. Wolfs T.F.W. Shachor-Meyouhas Y. Stein M. Sanders E.A.M. Bont L.J. A host-protein based assay to differentiate between bacterial and viral infections in preschool children (OPPORTUNITY): a double-blind, multicentre, validation study.Lancet Infect. Dis. 2017; 17: 431-440Abstract Full Text Full Text PDF PubMed Scopus (67) Google Scholar). Microbiological characterization of a clinical sample traditionally relies on cultivation of bacteria, which not only takes precious time, but in many cases is inconclusive because of the difficulty to recover viable bacteria. For example, in only ∼50% of the cases, are Streptococcus pneumoniae, a responsible agent for pneumococcal infections, recovered by culturing (3Song J.Y. Eun B.W. Nahm M.H. Diagnosis of pneumococcal pneumonia: current pitfalls and the way forward.Infect. Chemother. 2013; 45: 351-366Crossref PubMed Scopus (52) Google Scholar). Because bacterial infection can lead rapidly to invasive life-threatening situations, physicians may prescribe broad-spectrum antibiotics before knowing whether the infection is caused by bacteria or virus. Overuse of broad-spectrum antibiotics is a significant contributor to the emergence of anti-microbial resistance (AMR). One of the key counter-measures in the battle against AMR will be the development of improved, rapid, accurate and comprehensive diagnostic methods. respiratory tract infection antimicrobial resistance typing and characterization of bacteria using bottom-up tandem MS proteomics high-resolution accurate-mass lipid-based protein immobilization average nucleotide identity Basic Local Alignment Search Tool sodium deoxycholate National Center for Biotechnology Information parallel reaction monitoring selected reaction monitoring multiple reaction monitoring. respiratory tract infection antimicrobial resistance typing and characterization of bacteria using bottom-up tandem MS proteomics high-resolution accurate-mass lipid-based protein immobilization average nucleotide identity Basic Local Alignment Search Tool sodium deoxycholate National Center for Biotechnology Information parallel reaction monitoring selected reaction monitoring multiple reaction monitoring. DNA-based diagnostic approaches, such as real-time polymerase chain reaction (RT-PCR) is currently implemented in the routine protocols of the clinical microbiology laboratory and whole-genome sequencing is increasingly applied. However, PCR is a targeted approach and, thus, detects and identifies only the known and selected targets, which can lead to biased results and insufficient species resolution and characterization. One example is in the differentiation of closely related species within the Mitis Group of the genus Streptococcus, using PCR-based analyses of house-keeping genes or virulence factors (4Johnston C. Hinds J. Smith A. van der Linden M. Van Eldere J. Mitchell T.J. Detection of large numbers of pneumococcal virulence genes in streptococci of the mitis group.J. Clin. Microbiol. 2010; 48: 2762-2769Crossref PubMed Scopus (58) Google Scholar, 5Rolo D.A.S.S Domenech A. Fenoll A. Linares J. de Lencastre H. Ardanuy C. Sa-Leao R. Disease isolates of Streptococcus pseudopneumoniae and non-typeable S. pneumoniae presumptively identified as atypical S. pneumoniae in Spain.PloS One. 2013; 8: e57047Crossref PubMed Scopus (35) Google Scholar, 6Simoes A.S. Sa-Leao R. Eleveld M.J. Tavares D.A. Carrico J.A. Bootsma H.J. Hermans P.W. Highly penicillin-resistant multidrug-resistant pneumococcus-like strains colonizing children in Oeiras, Portugal: genomic characteristics and implications for surveillance.J. Clin. Microbiol. 2010; 48: 238-246Crossref PubMed Scopus (30) Google Scholar). Matrix-Assisted Laser Desorption/Ionization-Time-Of-Flight (MALDI-TOF) MS-based microbial species identification has emerged as an alternative to traditional phenotypic- or genotypic-based methods (7Erhard M. von Dohren H. Jungblut P. Rapid typing and elucidation of new secondary metabolites of intact cyanobacteria using MALDI-TOF mass spectrometry.Nat. Biotechnol. 1997; 15: 906-909Crossref PubMed Scopus (130) Google Scholar, 8Welker M. Moore E.R. Applications of whole-cell matrix-assisted laser-desorption/ionization time-of-flight mass spectrometry in systematic microbiology.Systematic Appl. Microbiol. 2011; 34: 2-11Crossref PubMed Scopus (231) Google Scholar, 9Singhal N. Kumar M. Kanaujia P.K. Virdi J.S. MALDI-TOF mass spectrometry: an emerging technology for microbial identification and diagnosis.Front. Microbiol. 2015; 6: 791Crossref PubMed Scopus (507) Google Scholar, 10Florio W. Tavanti A. Barnini S. Ghelardi E. Lupetti A. Recent advances and ongoing challenges in the diagnosis of microbial infections by MALDI-TOF mass spectrometry.Front. Microbiol. 2018; 9: 1097Crossref PubMed Scopus (41) Google Scholar). Demonstrating benefits, such as reliable species-level resolution, in most cases, ease-of-use and speed of processing samples, as well as low cost per analysis, MALDI-TOF MS identification is now used in clinics world-wide. However, a significant drawback of MALDI-TOF MS analyses is that it, in most cases, requires time-consuming cultivation and isolation of the relevant microorganisms. Further drawbacks include limitations in discriminating closely related species, including some species of the Mitis Group of the genus Streptococcus, and, except in some limited cases (11Hrabak J. Walkova R. Studentova V. Chudackova E. Bergerova T. Carbapenemase activity detection by matrix-assisted laser desorption ionization-time of flight mass spectrometry.J. Clin. Microbiol. 2011; 49: 3222-3227Crossref PubMed Scopus (229) Google Scholar, 12Jung J.S. Eberl T. Sparbier K. Lange C. Kostrzewa M. Schubert S. Wieser A. Rapid detection of antibiotic resistance based on mass spectrometry and stable isotopes.Eur. J. Clin. Microbiol. Infect. Dis. 2014; 33: 949-955Crossref PubMed Scopus (63) Google Scholar, 13Sparbier K. Schubert S. Weller U. Boogen C. Kostrzewa M. Matrix-assisted laser desorption ionization-time of flight mass spectrometry-based functional assay for rapid detection of resistance against beta-lactam antibiotics.J. Clin. Microbiol. 2012; 50: 927-937Crossref PubMed Scopus (238) Google Scholar), it has proven ineffective for obtaining information on characteristic features, such as AMR and virulence (14Karlsson R. Gonzales-Siles L. Gomila M. Busquets A. Salva-Serra F. Jaen-Luchoro D. Jakobsson H.E. Karlsson A. Boulund F. Kristiansson E. Moore E.R.B. Proteotyping bacteria: Characterization, differentiation and identification of pneumococcus and other species within the Mitis Group of the genus Streptococcus by tandem mass spectrometry proteomics.PloS One. 2018; 13: e0208804Crossref PubMed Scopus (16) Google Scholar). To increase the discriminative power and resolution for differentiating closely related species, even to strain-level typing, tandem MS approaches at the peptide level have been employed (14Karlsson R. Gonzales-Siles L. Gomila M. Busquets A. Salva-Serra F. Jaen-Luchoro D. Jakobsson H.E. Karlsson A. Boulund F. Kristiansson E. Moore E.R.B. Proteotyping bacteria: Characterization, differentiation and identification of pneumococcus and other species within the Mitis Group of the genus Streptococcus by tandem mass spectrometry proteomics.PloS One. 2018; 13: e0208804Crossref PubMed Scopus (16) Google Scholar, 15Chen S.H. Parker C.H. Croley T.R. McFarland M.A. Identification of Salmonella taxon-specific peptide markers to the serovar level by mass spectrometry.Anal. Chem. 2019; 91: 4388-4395Crossref PubMed Scopus (5) Google Scholar, 16Chenau J. Fenaille F. Caro V. Haustant M. Diancourt L. Klee S.R. Junot C. Ezan E. Goossens P.L. Becher F. Identification and validation of specific markers of Bacillus anthracis spores by proteomics and genomics approaches.Mol. Cell. Proteomics. 2014; 13: 716-732Abstract Full Text Full Text PDF PubMed Scopus (23) Google Scholar, 17Dworzanski J.P. Deshpande S.V. Chen R. Jabbour R.E. Snyder A.P. Wick C.H. Li L. Mass spectrometry-based proteomics combined with bioinformatic tools for bacterial classification.J. Proteome Res. 2006; 5: 76-87Crossref PubMed Scopus (62) Google Scholar, 18Karlsson R. Davidson M. Svensson-Stadler L. Karlsson A. Olesen K. Carlsohn E. Moore E.R. Strain-level typing and identification of bacteria using mass spectrometry-based proteomics.J. Proteome Res. 2012; 11: 2710-2720Crossref PubMed Scopus (37) Google Scholar, 19Misra R.V. Ahmod N.Z. Parker R. Fang M. Shah H. Gharbia S. Developing an integrated proteo-genomic approach for the characterisation of biomarkers for the identification of Bacillus anthracis.J. Microbiol Methods. 2012; 88: 237-247Crossref PubMed Scopus (8) Google Scholar, 20Wang H. Drake S.K. Yong C. Gucek M. Lyes M.A. Rosenberg A.Z. Soderblom E. Arthur Moseley M. Dekker J.P. Suffredini A.F. A Genoproteomic approach to detect peptide markers of bacterial respiratory pathogens.Clin. Chem. 2017; 63: 1398-1408Crossref PubMed Scopus (11) Google Scholar, 21Semanjski M. Macek B. Shotgun proteomics of bacterial pathogens: advances, challenges and clinical implications.Exp. Rev. Proteomics. 2016; 13: 139-156Crossref PubMed Scopus (17) Google Scholar). Peptide biomarker discovery has been facilitated by development of MS-instruments performing bottom-up ""high-resolution accurate-mass (HRAM)"" tandem MS proteomics, enabling identification of thousands of peptides simultaneously, in a single analysis (16Chenau J. Fenaille F. Caro V. Haustant M. Diancourt L. Klee S.R. Junot C. Ezan E. Goossens P.L. Becher F. Identification and validation of specific markers of Bacillus anthracis spores by proteomics and genomics approaches.Mol. Cell. Proteomics. 2014; 13: 716-732Abstract Full Text Full Text PDF PubMed Scopus (23) Google Scholar). At the peptide level, tandem MS has the power to elucidate expressed point mutations (22Ronsein G.E. Pamir N. von Haller P.D. Kim D.S. Oda M.N. Jarvik G.P. Vaisar T. Heinecke J.W. Parallel reaction monitoring (PRM) and selected reaction monitoring (SRM) exhibit comparable linearity, dynamic range and precision for targeted quantitative HDL proteomics.J. Proteomics. 2015; 113: 388-399Crossref PubMed Scopus (121) Google Scholar), enabling high levels of resolution. Biomarkers for resistance and virulence factors can be detected simultaneously in the same analysis, providing crucial information for diagnoses and proper treatments (23Cecchini T. Yoon E.J. Charretier Y. Bardet C. Beaulieu C. Lacoux X. Docquier J.D. Lemoine J. Courvalin P. Grillot-Courvalin C. Charrier J.P. Deciphering multifactorial resistance phenotypes in Acinetobacter baumannii by genomics and targeted label-free proteomics.Mol. Cell. Proteomics. 2018; 17: 442-456Abstract Full Text Full Text PDF PubMed Scopus (13) Google Scholar, 24Charretier Y. Dauwalder O. Franceschi C. Degout-Charmette E. Zambardi G. Cecchini T. Bardet C. Lacoux X. Dufour P. Veron L. Rostaing H. Lanet V. Fortin T. Beaulieu C. Perrot N. Dechaume D. Pons S. Girard V. Salvador A. Durand G. Mallard F. Theretz A. Broyer P. Chatellier S. Gervasi G. Van Nuenen M. Ann Roitsch C. Van Belkum A. Lemoine J. Vandenesch F. Charrier J.P. Rapid bacterial identification, resistance, virulence and type profiling using selected reaction monitoring mass spectrometry.Sci. Rep. 2015; 5: 13944Crossref PubMed Scopus (44) Google Scholar). Previously, we have shown that peptide biomarkers have the power to differentiate bacterial species (14Karlsson R. Gonzales-Siles L. Gomila M. Busquets A. Salva-Serra F. Jaen-Luchoro D. Jakobsson H.E. Karlsson A. Boulund F. Kristiansson E. Moore E.R.B. Proteotyping bacteria: Characterization, differentiation and identification of pneumococcus and other species within the Mitis Group of the genus Streptococcus by tandem mass spectrometry proteomics.PloS One. 2018; 13: e0208804Crossref PubMed Scopus (16) Google Scholar), as well as strains within the same species (18Karlsson R. Davidson M. Svensson-Stadler L. Karlsson A. Olesen K. Carlsohn E. Moore E.R. Strain-level typing and identification of bacteria using mass spectrometry-based proteomics.J. Proteome Res. 2012; 11: 2710-2720Crossref PubMed Scopus (37) Google Scholar). This ""proteotyping"" approach (14Karlsson R. Gonzales-Siles L. Gomila M. Busquets A. Salva-Serra F. Jaen-Luchoro D. Jakobsson H.E. Karlsson A. Boulund F. Kristiansson E. Moore E.R.B. Proteotyping bacteria: Characterization, differentiation and identification of pneumococcus and other species within the Mitis Group of the genus Streptococcus by tandem mass spectrometry proteomics.PloS One. 2018; 13: e0208804Crossref PubMed Scopus (16) Google Scholar, 25Grenga L.P. O Armengaud J. Pathogen proteotyping: A rapidly developing application of mass spectrometry to address clinical concerns.Clin. Mass Spectrom. 2019; 14: 9-17Crossref Scopus (18) Google Scholar, 26Karlsson R. Gonzales-Siles L. Boulund F. Svensson-Stadler L. Skovbjerg S. Karlsson A. Davidson M. Hulth S. Kristiansson E. Moore E.R. Proteotyping: Proteomic characterization, classification and identification of microorganisms–A prospectus.Syst. Appl. Microbiol. 2015; 38: 246-257Crossref PubMed Scopus (53) Google Scholar) can also be used for differentiating taxonomically-close species, such as the pathogen S. pneumoniae from commensal species, S. pseudopneumoniae and S. mitis of the Mitis Group of the genus Streptococcus (14Karlsson R. Gonzales-Siles L. Gomila M. Busquets A. Salva-Serra F. Jaen-Luchoro D. Jakobsson H.E. Karlsson A. Boulund F. Kristiansson E. Moore E.R.B. Proteotyping bacteria: Characterization, differentiation and identification of pneumococcus and other species within the Mitis Group of the genus Streptococcus by tandem mass spectrometry proteomics.PloS One. 2018; 13: e0208804Crossref PubMed Scopus (16) Google Scholar). In the present study, the workflow combines HRAM tandem MS and the TCUP (Typing and Characterization of bacteria Using bottom-up tandem mass spectrometry Proteomics) bioinformatics pipeline (27Boulund F. Karlsson R. Gonzales-Siles L. Johnning A. Karami N. Al-Bayati O. Ahren C. Moore E.R.B. Kristiansson E. Typing and characterization of bacteria using bottom-up tandem mass spectrometry proteomics.Mol. Cell. Proteomics. 2017; 16: 1052-1063Abstract Full Text Full Text PDF PubMed Scopus (35) Google Scholar) in the search for novel species-unique peptides as potential biomarkers for the respiratory tract pathogens, Staphylococcus aureus, Moraxella catarrhalis, Haemophilus influenzae and Streptococcus pneumoniae. In contrast to traditional cultivation-based methodologies, proteotyping is not relying on recovery of cultivable cells, but can be applied directly to clinical samples. The purpose of this study was to initially identify species-unique peptides as potential peptide biomarker candidates from bacterial cultures of reference strains of the target bacterial species and then to confirm these biomarker candidates in clinical respiratory-tract samples without any cultivation step (Fig. 1). Bacterial strains were selected of each of four common respiratory-tract infectious bacterial species: S. aureus (12 strains), M. catarrhalis (11 strains), H. influenzae (9 strains), and S. pneumoniae (7 strains); obtained from the Culture Collection, University of Gothenburg, Gothenburg, Sweden (CCUG; www.ccug.se) (supplemental Table S1). Cultures were grown overnight in the following way: S. aureus was grown on Blood Agar, at 37 °C, aerobically; M. catarrhalis and S. pneumoniae were grown on Blood Agar, at 37 °C, with 5% CO2; H. influenzae strains were grown on Chocolate Agar medium, at 36 °C, with 5% CO2. The classifications of the selected strains of H. influenzae, M. catarrhalis were confirmed by 16S rRNA gene sequence determinations and comparative sequence analyses (28Lane D.J. 16S/23S sequencing.Nucleic acid Techniques in Bacterial Systematics. John Wiley, Chichester, UK1991: 115-175Google Scholar). Classifications of the selected strains of S. aureus were confirmed by 16S rRNA gene and sodA sequence analyses (29Ghebremedhin B. Layer F. Konig W. Konig B. Genetic classification and distinguishing of Staphylococcus species based on different partial gap, 16S rRNA, hsp60, rpoB, sodA, and tuf gene sequences.J. Clin. Microbiol. 2008; 46: 1019-1025Crossref PubMed Scopus (158) Google Scholar). Classifications of the selected strains of S. pneumoniae were confirmed by whole genome sequence Average Nucleotide Identity based on BLAST (ANIb) analyses (30Goris J. Konstantinidis K.T. Klappenbach J.A. Coenye T. Vandamme P. Tiedje J.M. DNA-DNA hybridization values and their relationship to whole-genome sequence similarities.Int. J. System. Evolutionary Microbiol. 2007; 57: 81-91Crossref PubMed Scopus (2312) Google Scholar), using JSpeciesWS (31Richter M. Rossello-Mora R. Oliver Glockner F. Peplies J. JSpeciesWS: a web server for prokaryotic species circumscription based on pairwise genome comparison.Bioinformatics. 2016; 32: 929-931Crossref PubMed Scopus (930) Google Scholar), against the genome sequence of S. pneumoniae NCTC 7465T (GenBank accession number: LN831051). Bacterial biomass was collected from fresh cultures and suspended in phosphate-buffered saline (PBS). The bacteria were washed with PBS and lysed, by bead beating (14Karlsson R. Gonzales-Siles L. Gomila M. Busquets A. Salva-Serra F. Jaen-Luchoro D. Jakobsson H.E. Karlsson A. Boulund F. Kristiansson E. Moore E.R.B. Proteotyping bacteria: Characterization, differentiation and identification of pneumococcus and other species within the Mitis Group of the genus Streptococcus by tandem mass spectrometry proteomics.PloS One. 2018; 13: e0208804Crossref PubMed Scopus (16) Google Scholar). The bacterial lysates were frozen until further analysis. The Lipid-based Protein Immobilization (LPI®) methodology was employed for generating peptides from the cultured bacteria, as described previously (14Karlsson R. Gonzales-Siles L. Gomila M. Busquets A. Salva-Serra F. Jaen-Luchoro D. Jakobsson H.E. Karlsson A. Boulund F. Kristiansson E. Moore E.R.B. Proteotyping bacteria: Characterization, differentiation and identification of pneumococcus and other species within the Mitis Group of the genus Streptococcus by tandem mass spectrometry proteomics.PloS One. 2018; 13: e0208804Crossref PubMed Scopus (16) Google Scholar, 18Karlsson R. Davidson M. Svensson-Stadler L. Karlsson A. Olesen K. Carlsohn E. Moore E.R. Strain-level typing and identification of bacteria using mass spectrometry-based proteomics.J. Proteome Res. 2012; 11: 2710-2720Crossref PubMed Scopus (37) Google Scholar, 27Boulund F. Karlsson R. Gonzales-Siles L. Johnning A. Karami N. Al-Bayati O. Ahren C. Moore E.R.B. Kristiansson E. Typing and characterization of bacteria using bottom-up tandem mass spectrometry proteomics.Mol. Cell. Proteomics. 2017; 16: 1052-1063Abstract Full Text Full Text PDF PubMed Scopus (35) Google Scholar). Each strain of the four bacteria, S. aureus, M. catarrhalis, H. influenzae, and S. pneumoniae, were digested in triplicates (supplemental Fig. S1). To digest bacterial proteins into peptides, the cell lysate was injected into a LPI Hexalane FlowCell (Nanoxis Consulting AB, Gothenburg, Sweden, www.nanoxisconsulting.com; Patent Application No. WO2006068619), using a pipette to fill the FlowCell channel (channel volume of ∼30 μl). Proteins were immobilized to the FlowCell surface, after incubation for 1 h, at room temperature. The FlowCell channels were washed with 400 μl of ammonium bicarbonate, using a syringe pump, with a flow rate of 100 μl/min. Enzymatic digestion of the proteins was performed by injecting trypsin (V5111, Promega, Madison, WI) (2 μg/ml in 20 mm ammonium bicarbonate, pH 8.0) into the FlowCell channels and incubating for 1 h at room temperature. The generated peptides were eluted by injecting 200 μl ammonium bicarbonate buffer (20 mm, pH 8.0) into the channels. The eluted peptides were collected at the outlet ports, using a pipette, and transferred into tubes (2.0 ml, Axygen, Corning Life Sciences, MA). The peptide solutions were incubated at room temperature overnight and subsequently frozen at −20 °C until analysis by MS. The peptide samples were not reduced or alkylated prior to MS analysis. Clinical respiratory tract samples (nasopharyngeal and nasal swabs, n = 218), analyzed and reported as positive by the Clinical Microbiology Laboratory (Sahlgrenska University Hospital, Gothenburg, Sweden), were collected in Amies media (eSwab, Copan Diagnostics, Inc, CA). The clinical samples were reported to contain at least one of the four pathogens included in the study (S. aureus, M. catarrhalis, H. influenzae and/or S. pneumoniae). In many cases, the samples displayed co-infection with two or more of these pathogens. The pathogens in clinical samples were confirmed by the standard, accredited clinical microbiology laboratory protocols for selective and differential isolation of bacteria, including subsequent identification by MALDI-TOF MS analysis. Samples were supplemented with STGG (Skim milk, Tryptone, Glucose, Glycerol) to bolster the viability of bacteria as well as recovery of bacterial proteins during storage of respiratory tract samples and frozen until processing (32Kaijalainen T. Ruokokoski E. Ukkonen P. Herva E. Survival of Streptococcus pneumoniae, Haemophilus influenzae,Moraxella catarrhalis frozen in skim milk- tryptone-glucose-glycerol medium.J. Clin. Microbiol. 2004; 42: 412-414Crossref PubMed Scopus (27) Google Scholar). Only samples that were collected as part of the standard diagnostic protocols were included in this study; no additional or extra sampling from patients was carried out and no patient identifiable information was collected; hence, informed consent was not required. In the qualification phase, clinical respiratory tract samples, reported to be negative for bacteria by cultivation-based protocols and MALDI-TOF-MS, were spiked with cells of the type strains of the four species H. influenzae (CCUG 23945T), M. catarrhalis (CCUG 353T), S. aureus (CCUG 41582T) and S. pneumoniae (CCUG 28588T), to select the most promising peptide biomarker candidates for the validation phase. The number of added cells to the negative clinical samples ranged from 100 cells/ml to 1 million cells/ml (supplemental Fig. S2). The MolYsis kit (MolYsis Basic5 kit, Molzym GmbH & Co. Bremen, Germany) was used for removal of human biomass, according to the supplier's protocol, with minor modifications. After sample treatment, the resulting bacterial pellets were re-suspended in 120 μl ammonium bicarbonate (20 mm pH 8) and bacteria were lysed, using bead beating (14Karlsson R. Gonzales-Siles L. Gomila M. Busquets A. Salva-Serra F. Jaen-Luchoro D. Jakobsson H.E. Karlsson A. Boulund F. Kristiansson E. Moore E.R.B. Proteotyping bacteria: Characterization, differentiation and identification of pneumococcus and other species within the Mitis Group of the genus Streptococcus by tandem mass spectrometry proteomics.PloS One. 2018; 13: e0208804Crossref PubMed Scopus (16) Google Scholar). For digestion of proteins, to generate peptides, sodium deoxycholate (SDC, 5% in 20 mm ammonium bicarbonate, pH 8) was added to 1% (w/v) final concentration. Trypsin (2 μg/ml, 100 μl ammonium bicarbonate, 20 mm pH 8) was added and samples were digested for ∼8 h at 37 °C. SDC was removed by precipitation by addition of formic acid (FA) followed by centrifugation at 13,000 × g for 10 min. Supernatants containing the peptides were stored at −20 °C until analysis. The peptide samples were not reduced or alkylated prior to MS analysis (supplemental Fig. S3). Peptide samples were desalted, using PepClean C18 spin columns (Thermo Fisher Scientific, MA), according to the manufacturer's guidelines. MS analyses were carried out, using Q Exactive or a QExactive HF MS (Thermo Fisher Scientific) interfaced with an Easy nLC 1200 liquid chromatography system (Thermo Fisher Scientific). Peptides were trapped on an Acclaim Pepmap 100 C18 trap column (100 μm × 2 cm, particle size 5 μm, Thermo Fischer Scientific) and separated on an in-house packed analytical column (75 μm × 300 mm, particle size","['Q Exactive', 'Exactive HF MS']",Other,1,
https://openalex.org/W2998916450,W2998916450,,https://doi.org/10.3133/ofr20191117,Sustaining Environmental Capital Initiative summary report,"First posted January 6, 2020 For additional information, contact: Director, Fort Collins Science CenterU.S. Geological Survey2150 Centre Ave., Building CFort Collins, CO 80526-8118 Federal agencies need credible scientific information to determine the production and value of ecosystem services in an efficient and timely manner. The U.S. Geological Survey addresses this scientific information need through the Sustaining Environmental Capital Initiative project. The project has relied on U.S. Geological Survey expertise related to water, fisheries, advanced modeling, and economics and other social sciences to conduct eight case studies across a range of environment types, including water-based environments, deserts, sagebrush ecosystems, floodplains, and forests. The Sustaining Environmental Capital Initiative also supported the development and expansion of four tools with the intent of adding content and usability for partners’ decision-making needs. The tools are the Natural Value Resource Center, Benefit Transfer Toolkit, Riverine Environmental Flow Decision Support System, and Artificial Intelligence for Ecosystem Services modeling platform.",['Artificial Intelligence'],Classic AI & Neural Network Architectures,,1
https://openalex.org/W2998926617,W2998926617,,https://doi.org/10.1016/j.ejrh.2019.100652,A hybrid neural network-based technique to improve the flow forecasting of physical and data-driven models: Methodology and case studies in Andean watersheds,"The present study was conducted in the Machángara Alto and Chulco rivers, which belong to the Paute basin in the provinces of Azuay and Cañar in southern Ecuador. Andean watersheds are important providers of water supply for human consumption, food supply, energy generation, industrial water use, and ecosystem services and functions for many cities in Ecuador and in the rest of South America. In these regions, accurate quantification and prediction of water flow is challenging, mainly due to significant climatic variability and sparse monitoring networks. In the context of flow forecasting, this work evaluates the accuracy of two physical models (WEAP and GR2M) and two models based on artificial neural networks (ANN) that use meteorological data as input variables. Then, a hybrid technique is proposed, using the time series generated by the individual models as inputs of a new ANN. This approach aims to increase the accuracy of the simulated flow by combining and exploiting the information provided by physical and data-driven models. To assess the performance of the proposed methodology, statistical analyses are conducted for two case studies in the Andean region, where comparative analyses are performed for the individual models and the hybrid technique. The results indicate that the proposed technique is able to improve the individual performance of physical and ANN-based models, yielding good results in the calibration and validation stages for the two case studies. Specifically, increases in NSE were observed from 0.64 to 0.99 in the MachÁngara Alto river, and from 0.88 to 0.99 in the Chulco river. Higher accuracy of the hybrid technique was observed for all evaluation criteria considered in the analyses. The performance of the hybrid technique was also reflected in terms of water supply and demand, suggesting possible applications for the regional management of water resources, where accurate flow predictions are of utmost importance.","['ANN', 'GR2M']",Classic AI & Neural Network Architectures,1,1
https://openalex.org/W2999035787,W2999035787,,https://doi.org/10.2139/ssrn.3520735,A Machine Learning Approach to Biodiversity Time Series Analysis,"In this paper we have accessed the ecological changes of resources through time. A brief concept of time series and a case study of the observation of dragon flies in Kerala region have been studied. A machine learning approach of processing the bio diversity time series data, formulation of some forecasting phenomenon like migration, population growth, future presence etc. on a particular dragonfly species and a prediction approach is highlighted in this paper.","['time series', 'bio diversity time series data']",Classic Machine Learning,1,1
https://openalex.org/W2999104866,W2999104866,,https://doi.org/10.1051/shsconf/20207301027,Machine prediction of US imports from the PRC in the context of mutual sanctions,"The aim of this paper is to mechanically predict the import of the United States of America (USA) from the People's Republic of China (PRC). The trade restrictions of the USA and the PRC caused by the USA feeling of imbalance of trade between the two states have significantly influenced not only the trade between the two players, but also the overall climate of international trade. The result of this paper is the finding that multilayer perceptron networks (MLP) appear to be an excellent tool for predicting USA imports from the PRC. MLP networks can capture both the trend of the entire time series and its seasonal fluctuations. It also emerged that time series delays need to be applied. Acceptable results are shown to delay series of the order of 5 and 10 months. The mutual sanctions of both countries did not have a significant impact on the outcome of the machine learning prediction.",['Multilayer Perceptron networks'],Classic Machine Learning,1,1
https://openalex.org/W2999219571,W2999219571,,https://doi.org/10.1126/science.aax4953,A high-resolution summary of Cambrian to Early Triassic marine invertebrate biodiversity,"A finer record of biodiversity We have pressing, human-generated reasons to explore the influence of environmental change on biodiversity. Looking into the past can not only inform our understanding of this relationship but also help us to understand current change. Paleontological records depend on fossil availability and predictive modeling, however, and thus tend to give us a picture with large temporal jumps, millions of years wide. Such a scale makes it difficult to truly understand the action of environmental forces on ecological processes. Enabled by a supercomputer, Fan et al. used machine learning to analyze a large marine Paleozoic dataset, creating a record with time intervals of only ∼26,000 years (see the Perspective by Wagner). This fine-scale resolution revealed new events and important details of previously described patterns. Science , this issue p. 272 ; see also p. 249",,,N/A,N/A
https://openalex.org/W2999228179,W2999228179,,,Use of machine learning to improve simulations of climate,"Global climate models represent small-scale processes such as clouds and convection using quasi-empirical models known as parameterizations, and these parameterizations are a leading cause of uncertainty in climate projections. A promising alternative approach is to use machine learning to build new parameterizations directly from high-resolution model output. However, parameterizations learned from three-dimensional model output have not yet been successfully used for simulations of climate. Here we use a random forest to learn a parameterization of subgrid processes from output of a three-dimensional high-resolution atmospheric model. Integrating this parameterization into the atmospheric model leads to stable simulations at coarse resolution that replicate the climate of the high-resolution simulation. The parameterization obeys physical constraints and captures important statistics such as precipitation extremes. The ability to learn from a fully three-dimensional simulation presents an opportunity for learning parameterizations from the wide range of global high-resolution simulations that are now emerging.",['Random Forest'],Classic Machine Learning,1,1
https://openalex.org/W2999228179,W2999228179,,,Use of machine learning to improve simulations of climate,"Global climate models represent small-scale processes such as clouds and convection using quasi-empirical models known as parameterizations, and these parameterizations are a leading cause of uncertainty in climate projections. A promising alternative approach is to use machine learning to build new parameterizations directly from high-resolution model output. However, parameterizations learned from three-dimensional model output have not yet been successfully used for simulations of climate. Here we use a random forest to learn a parameterization of subgrid processes from output of a three-dimensional high-resolution atmospheric model. Integrating this parameterization into the atmospheric model leads to stable simulations at coarse resolution that replicate the climate of the high-resolution simulation. The parameterization obeys physical constraints and captures important statistics such as precipitation extremes. The ability to learn from a fully three-dimensional simulation presents an opportunity for learning parameterizations from the wide range of global high-resolution simulations that are now emerging.",['Random Forest'],Classic Machine Learning,1,1
https://openalex.org/W2999265262,W2999265262,,https://doi.org/10.1109/tcyb.2019.2957574,TiDEC: A Two-Layered Integrated Decision Cycle for Population Evolution,"Agent-based simulation is a useful approach for the analysis of dynamic population evolution. In this field, the existing models mostly treat the migration behavior as a result of utility maximization, which partially ignores the endogenous mechanisms of human decision making. To simulate such a process, this article proposes a new cognitive architecture called the two-layered integrated decision cycle (TiDEC) which characterizes the individual's decision-making process. Different from the previous ones, the new hybrid architecture incorporates deep neural networks for its perception and implicit knowledge learning. The proposed model is applied in China and U.S. population evolution. To the best of our knowledge, this is the first time that the cognitive computation is used in such a field. Computational experiments using the actual census data indicate that the cognitive model, compared with the traditional utility maximization methods, cannot only reconstruct the historical demographic features but also achieve better prediction of future evolutionary dynamics.",['deep neural networks'],New Generation of AI,1,1
https://openalex.org/W2999341640,W2999341640,,https://doi.org/10.5194/acp-20-561-2020,Altitude profiles of cloud condensation nuclei characteristics across the Indo-Gangetic Plain prior to the onset of the Indian summer monsoon,"Abstract. Concurrent measurements of the altitude profiles of the concentration of cloud condensation nuclei (CCN), as a function of supersaturation (ranging from 0.2 % to 1.0 %), and aerosol optical properties (scattering and absorption coefficients) were carried out aboard an instrumented aircraft across the Indo-Gangetic Plain (IGP) just prior to the onset of the Indian summer monsoon (ISM) of 2016. The experiment was conducted under the aegis of the combined South-West Asian Aerosol–Monsoon Interactions and Regional Aerosol Warming Experiment (SWAAMI–RAWEX) campaign. The measurements covered coastal, urban and arid environments. In general, the CCN concentration was highest in the central IGP, decreasing spatially from east to west above the planetary boundary layer (PBL), which is ∼1.5 km for the IGP during pre-monsoon period. Despite this, the CCN activation efficiency at 0.4 % supersaturation was, interestingly, the highest over the eastern IGP (∼72 %), followed by that in the west (∼61 %), and it was the least over the central IGP (∼24 %) within the PBL. In general, higher activation efficiency is noticed above the PBL than below it. The central IGP showed remarkably low CCN activation efficiency at all altitudes, which appears to be associated with high black carbon (BC) mass concentration there, indicating the role of anthropogenic sources in suppressing the CCN efficiency. These first-ever CCN measurements over the western IGP, encompassing “the Great Indian Desert” also known as “the Thar Desert”, showed high CCN efficiency, ∼61 % at 0.4 % supersaturation, indicating the hygroscopic nature of the dust. The vertical structure of CCN properties is found to be air mass dependent, with higher activation efficiency even over the central IGP during the prevalence of marine air mass. Wet scavenging associated with precipitation episodes seems to have reduced the CCN activation efficiency below cloud level. An empirical relation has emerged between the CCN concentration and the scattering aerosol index (AI), which would facilitate the prediction of CCN from aerosol optical properties.","['Empirical relation', 'Scattering aerosol index (AI)', 'Cloud condensation nuclei (CCN)']",Other,1,1
https://openalex.org/W2999364479,W2999364479,,https://doi.org/10.3390/info11010039,Artificial Intelligence-Enhanced Decision Support for Informing Global Sustainable Development: A Human-Centric AI-Thinking Approach,"Sustainable development is crucial to humanity. Utilization of primary socio-environmental data for analysis is essential for informing decision making by policy makers about sustainability in development. Artificial intelligence (AI)-based approaches are useful for analyzing data. However, it was not easy for people who are not trained in computer science to use AI. The significance and novelty of this paper is that it shows how the use of AI can be democratized via a user-friendly human-centric probabilistic reasoning approach. Using this approach, analysts who are not computer scientists can also use AI to analyze sustainability-related EPI data. Further, this human-centric probabilistic reasoning approach can also be used as cognitive scaffolding to educe AI-Thinking in the analysts to ask more questions and provide decision making support to inform policy making in sustainable development. This paper uses the 2018 Environmental Performance Index (EPI) data from 180 countries which includes performance indicators covering environmental health and ecosystem vitality. AI-based predictive modeling techniques are applied on 2018 EPI data to reveal the hidden tensions between the two fundamental dimensions of sustainable development: (1) environmental health; which improves with economic growth and increasing affluence; and (2) ecosystem vitality, which worsens due to industrialization and urbanization.",,,N/A,N/A
https://openalex.org/W2999553151,W2999553151,,https://doi.org/10.1097/ccm.0000000000004144,Too Many Definitions of Sepsis: Can Machine Learning Leverage the Electronic Health Record to Increase Accuracy and Bring Consensus?,"Department of Computer Science, Johns Hopkins University; Department of Health Policy and Management, Johns Hopkins Bloomberg School of Public Health; and Machine Learning, Artificial Intelligence, and Health Care Lab, Johns Hopkins University, Baltimore, MD Department of Computer Science, Johns Hopkins University, Baltimore, MD Dr. Saria has grants from Gordon and Betty Moore Foundation, the National Science Foundation, the National Institutes of Health, Defense Advanced Research Projects Agency, and the American Heart Association; she is a founder of and holds equity in Bayesian Health; she is the scientific advisory board member for PatientPing; and she has received honoraria for talks from a number of biotechnology, research, and healthtech companies. This arrangement has been reviewed and approved by the Johns Hopkins University in accordance with its conflict of interest policies. Ms. Henry is entitled to royalties from a licensing agreement between Johns Hopkins University and Bayesian Health LLC. This arrangement has been reviewed and approved by the Johns Hopkins University in accordance with its conflict of interest policies. For information regarding this article, E-mail: [email protected]",[],Other,1,1
https://openalex.org/W2999558057,W2999558057,,https://doi.org/10.3390/sym12010139,A Simplified Climate Change Model and Extreme Weather Model Based on a Machine Learning Method,"The emergence of climate change (CC) is affecting and changing the development of the natural environment, biological species, and human society. In order to better understand the influence of climate change and provide convincing evidence, the need to quantify the impact of climate change is urgent. In this paper, a climate change model is constructed by using a radial basis function (RBF) neural network. To verify the relevance between climate change and extreme weather (EW), the EW model was built using a support vector machine. In the case study of Canada, its level of climate change was calculated as being 0.2241 (“normal”), and it was found that the factors of CO2 emission, average temperature, and sea surface temperature are significant to Canada’s climate change. In 2025, the climate level of Canada will become “a little bad” based on the prediction results. Then, the Pearson correlation value is calculated as being 0.571, which confirmed the moderate positive correlation between climate change and extreme weather. This paper provides a strong reference for comprehensively understanding the influences brought about by climate change.","['Support Vector Machines (SVMs)', 'Radial basis function (RBF) neural network']",Classic Machine Learning,1,1
https://openalex.org/W2999624081,W2999624081,,https://doi.org/10.1051/shsconf/20207402001,Movement of autonomous systems after selected infrastructure as a globalization effect induced by initiate Industry 4.0,"The replacement of specialized, highly sophisticated human work with systems using artificial intelligence is one of the features of the 4th Industrial Revolution known as Industry 4.0. The upcoming innovations and transformations of production processes, the digitized of information and the automation will bring about changes at the social level. These are mainly changes in the company’s behavior. There is a significant risk for specific groups of people, especially those that can be replaced by new information technologies. In the context of the current sixth wave of globalization, new forms of migration of people and capital can be expected related to transnational nature of productive activities, the global form of communications and information. In the context of socio-economic structures, an individual is confronted with a set of factors. The aim of an individual’s behavior is usually to change his localization with respect to the values of the preferred socioeconomic variables, such as availability of work, safety, air quality, etc. On the other hand, the position of an individual will influence the values of socio-economic variables. Behavior can be simulated using multiagent systems. The paper informs about the first phase of the research. Local maxima of factor values were identified.",,,N/A,N/A
https://openalex.org/W2999638341,W2999638341,,https://doi.org/10.1002/essoar.10501494.1,Towards data-driven approaches for simulating rainfall in climate models,"Climate model simulations of rainfall in the tropics suffer from pervasive biases, and that can lead to degraded climate simulations in other regions as well. Over the past two decades, high-resolution satellite measurements of tropical rainfall have become available. These data are most commonly used to constrain physics-based climate models by validating statistical properties of rainfall such as means and variances. However, the satellite data contain a wealth of spatiotemporal information on sub-diurnal timescales that can be used to construct predictive models. This study explores the feasibility of predicting rainfall from atmospheric state using a hierarchy of empirical models. Our empirical approach is similar to the physics-based approach in that vertical profiles of atmospheric state at a particular instant of time serve as the predictors, and rainfall over a subsequent time period is the predictand. However, we allow the empirical model to “learn” from data to determine the model parameters. Empirical Orthogonal Function (EOF) decomposition is applied to vertical profiles from NASA MERRA-2 reanalysis to select the dominant predictor modes at analysis time 00 UTC. Rain predictions for the subsequent 6-hour period (00-06 UTC) are separated into different types from TRMM satellite data: stratiform, deep convective, and shallow convective. For each rain type, two generalized linear statistical models (logistic regression for rain occurrence and gamma regression for rain amount) are trained on 2003 data and used to predict during 2004. The results show that the statistical approach can predict spatial patterns and amplitudes of tropical rainfall in the time-averaged sense. The first EOF of humidity and the second EOF of temperature contribute most to prediction. In addition to generalized linear models, other common machine learning techniques (support vector machine and random forest) are compared. Furthermore, marginal nonlinear relationships between predictand and individual predictor are explored via a nonparametric regression technique. Interestingly, incorporating the identified marginal nonlinear relationship into the generalized linear model does not improve the prediction, suggesting that these marginal nonlinear effects are explained by other predictors in the model.","['Generalized Linear Models', 'Logistic Regression', 'Gamma Regression', 'Support Vector Machine', 'Random Forest']",Classic Machine Learning,1,1
https://openalex.org/W2999666473,W2999666473,,,Understanding the Great Recession Using Machine Learning Algorithms,"Nyman and Ormerod (2017) show that the machine learning technique of random forests has the potential to give early warning of recessions. Applying the approach to a small set of financial variables and replicating as far as possible a genuine ex ante forecasting situation, over the period since 1990 the accuracy of the four-step ahead predictions is distinctly superior to those actually made by the professional forecasters. Here we extend the analysis by examining the contributions made to the Great Recession of the late 2000s by each of the explanatory variables. We disaggregate private sector debt into its household and non-financial corporate components. We find that both household and non-financial corporate debt were key determinants of the Great Recession. We find a considerable degree of non-linearity in the explanatory models. In contrast, the public sector debt to GDP ratio appears to have made very little contribution. It did rise sharply during the Great Recession, but this was as a consequence of the sharp fall in economic activity rather than it being a cause. We obtain similar results for both the United States and the United Kingdom.",['Random Forests'],Classic Machine Learning,1,1
https://openalex.org/W2999666473,W2999666473,,,Understanding the Great Recession Using Machine Learning Algorithms,"Nyman and Ormerod (2017) show that the machine learning technique of random forests has the potential to give early warning of recessions. Applying the approach to a small set of financial variables and replicating as far as possible a genuine ex ante forecasting situation, over the period since 1990 the accuracy of the four-step ahead predictions is distinctly superior to those actually made by the professional forecasters. Here we extend the analysis by examining the contributions made to the Great Recession of the late 2000s by each of the explanatory variables. We disaggregate private sector debt into its household and non-financial corporate components. We find that both household and non-financial corporate debt were key determinants of the Great Recession. We find a considerable degree of non-linearity in the explanatory models. In contrast, the public sector debt to GDP ratio appears to have made very little contribution. It did rise sharply during the Great Recession, but this was as a consequence of the sharp fall in economic activity rather than it being a cause. We obtain similar results for both the United States and the United Kingdom.",['Random Forests'],Classic Machine Learning,1,1
https://openalex.org/W2999667975,W2999667975,,https://doi.org/10.1016/j.watres.2020.115490,Estimation of high frequency nutrient concentrations from water quality surrogates using machine learning methods,"Continuous high frequency water quality monitoring is becoming a critical task to support water management. Despite the advancements in sensor technologies, certain variables cannot be easily and/or economically monitored in-situ and in real time. In these cases, surrogate measures can be used to make estimations by means of data-driven models. In this work, variables that are commonly measured in-situ are used as surrogates to estimate the concentrations of nutrients in a rural catchment and in an urban one, making use of machine learning models, specifically Random Forests. The results are compared with those of linear modelling using the same number of surrogates, obtaining a reduction in the Root Mean Squared Error (RMSE) of up to 60.1%. The profit from including up to seven surrogate sensors was computed, concluding that adding more than 4 and 5 sensors in each of the catchments respectively was not worthy in terms of error improvement.","['Random Forests', 'machine learning models']",Classic Machine Learning,1,1
https://openalex.org/W2999824992,W2999824992,,,Should Artificial Intelligence Governance be Centralised? Design Lessons from History.,"Can effective international governance for artificial intelligence remain fragmented, or is there a need for a centralised international organisation for AI? We draw on the history of other international regimes to identify advantages and disadvantages in centralising AI governance. Some considerations, such as efficiency and political power, speak in favour of centralisation. Conversely, the risk of creating a slow and brittle institution speaks against it, as does the difficulty in securing participation while creating stringent rules. Other considerations depend on the specific design of a centralised institution. A well-designed body may be able to deter forum shopping and ensure policy coordination. However, forum shopping can be beneficial and a fragmented landscape of institutions can be self-organising. Centralisation entails trade-offs and the details matter. We conclude with two core recommendations. First, the outcome will depend on the exact design of a central institution. A well-designed centralised regime covering a set of coherent issues could be beneficial. But locking-in an inadequate structure may pose a fate worse than fragmentation. Second, for now fragmentation will likely persist. This should be closely monitored to see if it is self-organising or simply inadequate.",,,N/A,N/A
https://openalex.org/W2999824992,W2999824992,,,Should Artificial Intelligence Governance be Centralised? Design Lessons from History.,"Can effective international governance for artificial intelligence remain fragmented, or is there a need for a centralised international organisation for AI? We draw on the history of other international regimes to identify advantages and disadvantages in centralising AI governance. Some considerations, such as efficiency and political power, speak in favour of centralisation. Conversely, the risk of creating a slow and brittle institution speaks against it, as does the difficulty in securing participation while creating stringent rules. Other considerations depend on the specific design of a centralised institution. A well-designed body may be able to deter forum shopping and ensure policy coordination. However, forum shopping can be beneficial and a fragmented landscape of institutions can be self-organising. Centralisation entails trade-offs and the details matter. We conclude with two core recommendations. First, the outcome will depend on the exact design of a central institution. A well-designed centralised regime covering a set of coherent issues could be beneficial. But locking-in an inadequate structure may pose a fate worse than fragmentation. Second, for now fragmentation will likely persist. This should be closely monitored to see if it is self-organising or simply inadequate.",,,N/A,N/A
https://openalex.org/W2999986734,W2999986734,,https://doi.org/10.1126/science.367.6475.260-m,A finer record of biodiversity,"Paleontology
We have pressing, human-generated reasons to explore the influence of environmental change on biodiversity. Looking into the past can not only inform our understanding of this relationship but also help us to understand current change. Paleontological records depend on fossil availability and predictive modeling, however, and thus tend to give us a picture with large temporal jumps, millions of years wide. Such a scale makes it difficult to truly understand the action of environmental forces on ecological processes. Enabled by a supercomputer, Fan et al. used machine learning to analyze a large marine Paleozoic dataset, creating a record with time intervals of only ∼26,000 years (see the Perspective by Wagner). This fine-scale resolution revealed new events and important details of previously described patterns.

Science , this issue p. [272][1]; see also p. [249][2]

 [1]: /lookup/doi/10.1126/science.aax4953
 [2]: /lookup/doi/10.1126/science.aba4348",['machine learning'],Classic Machine Learning,1,1
https://openalex.org/W3000072164,W3000072164,,https://doi.org/10.5194/hess-2019-650,Predicting tile drainage discharge using machine learning algorithms,"Abstract. Drainage systems can significantly improve the water management in agricultural fields. However, they may transport contaminants originating from fertilizers and pesticides and threaten ecosystems. Determining the quantity of drainage water is an important factor for constructed wetlands and other drainage mitigation techniques. This study was carried out in Denmark where tile drainage systems are implemented in more than half of the agricultural fields. The first aim of the study was to predict the annual discharge of tile drainage systems using machine-learning methods, which have been highly popular in recent years. The second objective was to assess the importance of the parameters and their impact on the predictions. Data from 53 drainage stations distributed in different regions of Denmark were collected and used for the analysis. The covariates contained 35 parameters including the calculated percolation and geographic variables such as drainage probability, clay content in different depth intervals, and elevation, all extracted from existing national maps. Random Forest and Cubist were selected as predictive models. Both models were trained on the dataset and used to predict yearly drainage discharge. Results highlighted the importance of the cross-validation methods and indicated that both Random Forest and Cubist can perform as predictive models with a low complexity and good correlation between predicted and observed discharge. Covariate importance analysis showed that among all of the used predictors, the percolation and elevation have the largest effect on the prediction of tile drainage discharge. This work opens up for a better understanding of the dynamics of tile drainage discharge and proves that machine-learning techniques can perform as predictive models in this specific concept. The developed models can be used in regard to a national mapping of expected tile drain discharge.","['Random Forest', 'Cubist']",Classic Machine Learning,1,1
https://openalex.org/W3000120357,W3000120357,,https://doi.org/10.1051/shsconf/20207301017,Machine learning forecasting of CR import from PRC in context of mutual PRC and USA sanctions,"Mutual trade restrictions between the USA and the PRC caused by the USA feeling of imbalance of trade between these two countries have significantly influenced not only the trade between these two states but also the overall atmosphere of the international trade in the last few years. The objective of the contribution is to find out whether machine learning forecasting is capable of equalizing time series so that the model effectively forecasts the future development of the time series even in the context of an extraordinary situation caused by such factors as the mutual sanctions of the USA and PRC. The dataset shows the course of the time series at monthly intervals starting from January 2000 to June 2019. There is regression carried out using neural structures. Three sets of artificial neural networks are generated. They are differ in the considered time series lag. 10,000 neural networks are generated, out of which 5 with the best characteristics are retained. The mutual USA and PRC sanctions did not affect the success rate of the machine learning forecasting of the CR import from the PRC. It is evident that the mutual sanctions shall affect the trade between the CR and the PRC.",['artificial neural networks'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W3000145408,W3000145408,,https://doi.org/10.1101/2020.01.16.908962,Enhancing georeferenced biodiversity inventories: automated information extraction from literature records reveal the gaps,"Abstract We use natural language processing (NLP) to retrieve location data for cheilostome bryozoan species (text-mined occurrences [TMO]) in an automated procedure. We compare these results with data from the Ocean Biogeographic Information System (OBIS). Using OBIS and TMO data separately and in combination, we present latitudinal species richness curves using standard estimators (Chao2 and the Jackknife) and range-through approaches. Our combined OBIS and TMO species richness curves quantitatively document a bimodal global latitudinal diversity gradient for cheilostomes for the first time, with peaks in the temperate zones. 79% of the georeferenced species we retrieved from TMO (N = 1780) and OBIS (N = 2453) are non-overlapping and underestimate known species richness, even in combination. Despite clear indications that global location data compiled for cheilostomes should be improved with concerted effort, our study supports the view that latitudinal species richness patterns deviate from the canonical LDG. Moreover, combining online biodiversity databases with automated information retrieval from the published literature is a promising avenue for expanding taxon-location datasets.","['NLP', 'Chao2', 'Jackknife']",Classic Machine Learning,1,1
https://openalex.org/W3000385305,W3000385305,,https://doi.org/10.1061/9780784482742.056,Yangtze River Waterway Transportation Safety Early Warning Management System Based on Generalized Risk-Entropy,"This study put forward a generalized risk-entropy model in order to describe the complexity of Yangtze River waterway transport safety system, with the application of dynamic theory of energy transmission in nonlinear systems, and analysis methods for complex systems. The generalized risk-entropy model can characterize the overall risk evolution mechanism of the emergence promoted by risk network communication, superposition coupling, and level transition in waterway transport safety system. The method of artificial neural network is used to identify the model of generalized risk-entropy model, a BP neural network model is constructed for Yangtze River waterway transport risk assessment based on generalized risk-entropy. After that, waterway transport safety early warning management system framework, function structure, and logic structure, etc. are designed, and an early warning management system is developed for application demonstration in Wuhan waterway section. It hopes to provide a new idea and method for the risk prediction, evaluation, and early warning management of waterway transportation system.",['BP neural network'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W3000414570,W3000414570,,https://doi.org/10.9734/jamcs/2019/v34i630230,Proposing an Image Enhancement Algorithm Using CNN for Applications of Face Recognition System,"Many researches have been going on since last two decades for object recognition, shape matching, and pattern recognition in the field of computer vision. Face recognition is one of the important issues in object recognition and computer vision. Many face image datasets, related competitions, and evaluation programs have encouraged innovation, producing more powerful facial recognition technology with promising results. In recent years, we have witnessed tremendous improvements in face recognition performance from complex deep neural network architectures trained on millions of face images. Face recognition is the most important biometric and stills many challenges such as pose variation, illumination variation, etc. In order to achieve the desired performance when deploying in reality, the methods depend on many factors. One of the main factors is quality of input image. Therefore, facial recognition systems is installed outdoors which are always affected by extreme weather events such as haze, fog. The existence of haze dramatically degrades the visibility of outdoor images captured in inclement weather and affects many high-level computer vision tasks such as detection and recognition system. In this paper, we propose a preprocessing method to remove haze from input images that enhances their quality to improve effectiveness and recognition rate for face identification based on Convolutional Neural Network (CNN) based on the available datasets and our self-built data. To perform the proposed method for outdoor face recognition system, we have improved the system accuracy from 90.53% to 98.14%. The results show that the proposed method improves the quality of the image with other traditional methods.",['Convolutional Neural Networks (CNN)'],Classic Deep Learning,1,1
https://openalex.org/W3000435069,W3000435069,,https://doi.org/10.1051/shsconf/20207301004,Machine learning forecasting of CR and PRC balance of trade,"International trade is an important factor of economic growth. While foreign trade has existed throughout the history, its political, economic and social importance has grown significantly in the last centuries. The objective of the contribution is to use machine learning forecasting for predicting the balance of trade of the Czech Republic (CR) and the People´s Republic of China (PRC) through analysing and machine learning forecasting of the CR import from the PRC and the CR export to the PRC. The data set includes monthly trade balance intervals from January 2000 to June 2019. The contribution investigates and subsequently smooths two time series: the CR import from the PRC; the CR export to the PRC. The balance of trade of both countries in the entire monitored period is negative from the perspective of the CR. A total of 10,000 neural networks are generated. 5 neural structures with the best characteristics are retained. Neural networks are able to capture both the trend of the entire time series and its seasonal fluctuations, but it is necessary to work with time series lag. The CR import from the PRC is growing and it is expected to grow in the future. The CR export to the PRC is growing and it is expected to grow in the future, but its increase in absolute values will be slower than the increase of the CR import from the PRC.",['neural networks'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W3000609388,W3000609388,,https://doi.org/10.1061/(asce)he.1943-5584.0001880,"Impacts of Streamflow and Topographic Changes on Water Level during the Dry Season of Poyang Lake, China","Poyang Lake is the largest freshwater lake in China and is internationally recognized as an important lacustrine and wetland ecosystem with abundant biodiversity. Since 2003, the average lake water level has significantly declined by 1.35 m during the dry season. Quantifying the contribution of different factors to water level decline is necessary for lake management. The impact factors mainly include hydrological and topographic changes in terms of the decreased inflow from the five tributaries, lower water level in the Yangtze River, the decline of the lakebed, and the increased discharge ability of the lake. Back-propagation neural networks have been constructed to simulate the lake water level, considering preimpact and postimpact streamflow and topographic scenarios. The simulations verified the robustness and applicability of the networks and indicated that the streamflow and topographic changes contributed approximately 34% and 66% to the decline in the water level, respectively. The Three Gorges Reservoir exerts various impacts on the water level of Poyang Lake. The reservoir sedimentation causes riverbed erosion and lowers the downstream water level. The water release increases the downstream flow and is conducive to elevating the lake water level. But the impact is marginal because it is diluted by the topographic changes and the decreased runoff of the subbasins along the middle and lower Yangtze River. These results provide useful information to guide strategies for wetland and lacustrine ecological protection associated with water level fluctuations.",['Back-propagation neural networks'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W3000672671,W3000672671,,,"Understanding headwater baseflow contributions to the overall water supply of the Kathmandu Valley, Nepal","The Kathmandu Valley in Nepal is facing the combined effects of population growth, rapid urbanization, economic development, and climate change. This results in serious water management challenges: growing freshwater demands, declining water tables, drying of streams, and deteriorating water quality. Insufficient surface water supplies have led to increased reliance on groundwater, especially during the dry winter and pre-monsoon seasons (November - May). Despite groundwater’s importance, it is sparsely measured, poorly understood, and insufficiently managed. As it is difficult and costly to measure all groundwater extractions in the Valley, a water balance approach is an alternative method to estimate total net groundwater pumping. Therefore, the aim of this research was to develop and evaluate potential methods for quantifying total pre-monsoon baseflow supplies by extrapolating baseflow measurements of a subsample of watersheds to unmeasured watersheds. Estimated baseflow was used, together with other water balance fluxes and changes in storage, to evaluate net groundwater pumping in the Valley. Three different methods were used: (1) Spatial Analysis, (2) Regression Model, and (3) Black Box (machine learning). All methods relied on streamflow data from 2017 to 2019, collected by citizen scientists from S4W-Nepal. Based on the three methods we presented, we cautiously conclude that it is possible to determine the pre-monsoon baseflow contributions from a sub-sample of head water catchments. Total baseflow estimates for the Valley using Spatial Analysis, Regression Model, Black Box were 2.32, 2.30, 2.65 m3/s respectively. These values show orders of magnitude that correspond with expected values. By using the average baseflow values of all three methods, we were able to close the water balance and make an assumption for the net groundwater pumping in the Valley. Based on a population of 3.5 million, a net groundwater extraction of 96 L/person/day during pre-monsoon was found. This striking outcome emphasizes the need for more discharge and groundwater extraction measurements, to decrease the uncertainties and to refine the methods.","['Regression Model', 'Black Box']",Classic Machine Learning,1,1
https://openalex.org/W3000672671,W3000672671,,,"Understanding headwater baseflow contributions to the overall water supply of the Kathmandu Valley, Nepal","The Kathmandu Valley in Nepal is facing the combined effects of population growth, rapid urbanization, economic development, and climate change. This results in serious water management challenges: growing freshwater demands, declining water tables, drying of streams, and deteriorating water quality. Insufficient surface water supplies have led to increased reliance on groundwater, especially during the dry winter and pre-monsoon seasons (November - May). Despite groundwater’s importance, it is sparsely measured, poorly understood, and insufficiently managed. As it is difficult and costly to measure all groundwater extractions in the Valley, a water balance approach is an alternative method to estimate total net groundwater pumping. Therefore, the aim of this research was to develop and evaluate potential methods for quantifying total pre-monsoon baseflow supplies by extrapolating baseflow measurements of a subsample of watersheds to unmeasured watersheds. Estimated baseflow was used, together with other water balance fluxes and changes in storage, to evaluate net groundwater pumping in the Valley. Three different methods were used: (1) Spatial Analysis, (2) Regression Model, and (3) Black Box (machine learning). All methods relied on streamflow data from 2017 to 2019, collected by citizen scientists from S4W-Nepal. Based on the three methods we presented, we cautiously conclude that it is possible to determine the pre-monsoon baseflow contributions from a sub-sample of head water catchments. Total baseflow estimates for the Valley using Spatial Analysis, Regression Model, Black Box were 2.32, 2.30, 2.65 m3/s respectively. These values show orders of magnitude that correspond with expected values. By using the average baseflow values of all three methods, we were able to close the water balance and make an assumption for the net groundwater pumping in the Valley. Based on a population of 3.5 million, a net groundwater extraction of 96 L/person/day during pre-monsoon was found. This striking outcome emphasizes the need for more discharge and groundwater extraction measurements, to decrease the uncertainties and to refine the methods.","['Regression Model', 'Black Box']",Classic Machine Learning,1,1
https://openalex.org/W3000729826,W3000729826,,https://doi.org/10.1088/1757-899x/719/1/012062,Research on Assisted Driving Technology based on Improved YOLOv3,"Abstract In the era of automobile popularization, China and the developed countries such as Europe and the United States are facing the same problem of high car accidents. This paper uses deep learning technology to detect and identify lane lines, traffic lights, vehicles and pedestrians during driver driving. Improve the efficiency and accuracy of convolutional neural network training through migration learning and data enhancement techniques. Based on the current advanced YOLOv3 network, we have improved the network structure and loss function. The KITTI dataset has achieved the highest 2D target recognition accuracy, and the target recognition speed is higher than 36 frames/sec. The price of the assisted driving equipment we developed does not exceed RMB 5, 000, which has a good market prospect.","['Convolutional Neural Networks (CNNs)', 'YOLOv3 network']",Classic Deep Learning,1,1
https://openalex.org/W3000731341,W3000731341,,https://doi.org/10.1002/met.1881,Contrasting features of hydroclimatic teleconnections and the predictability of seasonal rainfall over east and west Japan,"Abstract Hydroclimatic teleconnections between global sea surface temperature (SST) anomaly fields and monthly rainfall over east and west Japan (divided along 138° E longitude) are identified for summer (June–August) and winter (December–February) using the concept of global climate pattern (GCP). The analysis indicates that the hydroclimatic teleconnections over both regions vary at both intra‐ and inter‐seasonal time scales. In addition, the teleconnections over the two regions have differing origins. The teleconnection features associated with rainfall anomalies over west Japan have origins in the tropical Pacific and Indian oceans, whereas those over east Japan are associated with high‐latitude SST anomalies. The early summer (winter) rainfall over west Japan is linked to the El Niño Modoki (La Niña Modoki) phenomena, whereas the early summer and winter rainfall anomalies over east Japan are associated with the SST anomaly over the eastern subtropical Pacific and South Pacific oceans, respectively. Having identified the teleconnections, prediction model approaches—a machine‐learning approach, namely support vector regression (SVR), and a hybrid graphical modelling/C‐Vine copula (GM‐Copula)—were developed to forecast the rainfall over both east and west Japan. The predictors were derived from the monthly SST anomalies at different lags (1–6 months), and whereas the hidden, nonlinear relationship was well captured by the SVR approach, the complex association was decidedly better captured by the GM‐Copula approach. Hence, it is recommended for forecasting the rainfall over east and west Japan.","['Support Vector Machines', 'GM-Copula']",Classic Machine Learning,0,1
https://openalex.org/W3001091914,W3001091914,,https://doi.org/10.5744/bi.2019.1014,"“Captain of All These Men of Death”: An Integrated Case Study of Tuberculosis in Nineteenth-Century Otago, New Zealand","The South Island of New Zealand saw several major waves of migration in the mid-nineteenth century, predominantly from Europe but also with an ethnically distinct Chinese presence. The rural community of Milton, Otago, was a settler community established primarily by immigrants from the United Kingdom in search of a better quality of life. However, these settlers faced unique challenges related to surviving in an isolated location with very little infrastructure compared to their origin populations. In 2016, excavation was undertaken at St. John’s burial ground, Milton, with the object of using bioarchaeological methods to elucidate the lived experience of the first organized European settlement of this region, particularly in terms of health and disease. Here we present a case study of Burial 21 (B21), a male individual of known identity and a documented cause of death. We use biochemical and paleopathological methods to ground-truth his written history, which includes a period of invalidism due to tuberculosis, and discuss the implications of our findings for the community, provision of care, and quality of life in rural colonial New Zealand. He maha tonu ngā hekenga tāngata ki Te Waka a Māui i ngā tau kei waenga pū o te rau tau 1800, ko te nuinga nō Ūropi, heoi he tokomaha tonu nō Haina. Nā ngā manene nō Peretānia te hapori o Milton i whakatū ki Tokomairaro, i Ōtākou, i tō rātou hiahia ki tētehi oranga kounga ake i tō rātou oranga i Peretānia. Heoi, ko ētehi o ngā wero nui i tau ki ngā manene nei i ahu mai i te noho pūreirei ki tētehi wāhi kāore rawa ngā ratonga i rite ki ngā wāhi i ahu mai ai rātou. I te tau 2016, i hahu kōiwi i te urupā o Hato Hone, i Milton, hei whakamātau i te kaha o te ora me ngā momo mate i pā atu ki ngā tāngata whai i noho i te rohe nei. Nei rā he ripoata mō tētehi kua hahua, kua tapaina ko B21, he tāne ia, ko tōna ingoa kua mōhiotia, ko tōna mate kua āta tuhia. Kua āta whakamātauria ōna kōiwi me ōna toenga kiko mō ngā tohu ora me ngā tohu mate, kia mārama ai mena rānei e hāngai ana ngā tuhinga rongoā mōna, ngā mea i tuhia nōna e takatū ana, tae atu ki te wā i tūroro ia i te mate kohi, ki ngā tohu e puta ana i te mātauranga Rongoā-Koiora ō nāianei. Ka matapakina ngā hīrautanga o ngā kitenga me te māramatanga kua puta i tēnei rangahau e pā ana ki te hapori, ki ngā ratonga hauora, me te kounga o te oranga mō te hunga noho tuawhenua i tērā wā i Aotearoa.",[],Other,1,1
https://openalex.org/W3001287042,W3001287042,,https://doi.org/10.1016/j.atmosres.2020.104868,Spatio-temporal variation of reference evapotranspiration in northwest China based on CORDEX-EA,,,,N/A,N/A
https://openalex.org/W3001664967,W3001664967,,https://doi.org/10.3390/rs12030343,Tree Cover Estimation in Global Drylands from Space Using Deep Learning,"Accurate tree cover mapping is of paramount importance in many fields, from biodiversity conservation to carbon stock estimation, ecohydrology, erosion control, or Earth system modelling. Despite this importance, there is still uncertainty about global forest cover, particularly in drylands. Recently, the Food and Agriculture Organization of the United Nations (FAO) conducted a costly global assessment of dryland forest cover through the visual interpretation of orthoimages using the Collect Earth software, involving hundreds of operators from around the world. Our study proposes a new automatic method for estimating tree cover using artificial intelligence and free orthoimages. Our results show that our tree cover classification model, based on convolutional neural networks (CNN), is 23% more accurate than the manual visual interpretation used by FAO, reaching up to 79% overall accuracy. The smallest differences between the two methods occurred in the driest regions, but disagreement increased with the percentage of tree cover. The application of CNNs could be used to improve and reduce the cost of tree cover maps from the local to the global scale, with broad implications for research and management.",['Convolutional Neural Networks (CNN)'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W3001673168,W3001673168,,https://doi.org/10.5194/gmd-13-4399-2020,RadNet 1.0: exploring deep learning architectures for longwave radiative transfer,"Abstract. Simulating global and regional climate at high resolution is essential to study the effects of climate change and capture extreme events affecting human populations. To achieve this goal, the scalability of climate models and efficiency of individual model components are both important. Radiative transfer is among the most computationally expensive components in a typical climate model. Here we attempt to model this component using a neural network. We aim to study the feasibility of replacing an explicit, physics-based computation of longwave radiative transfer by a neural network emulator and assessing the resultant performance gains. We compare multiple neural-network architectures, including a convolutional neural network, and our results suggest that the performance loss from the use of conventional convolutional networks is not offset by gains in accuracy. We train the networks with and without noise added to the input profiles and find that adding noise improves the ability of the networks to generalise beyond the training set. Prediction of radiative heating rates using our neural network models achieve up to 370× speedup on a GTX 1080 GPU setup and 11× speedup on a Xeon CPU setup compared to the a state-of-the-art radiative transfer library running on the same Xeon CPU. Furthermore, our neural network models yield less than 0.1 K d−1 mean squared error across all pressure levels. Upon introducing this component into a single-column model, we find that the time evolution of the temperature and humidity profiles is physically reasonable, though the model is conservative in its prediction of heating rates in regions where the optical depth changes quickly. Differences exist in the equilibrium climate simulated when using the neural network, which are attributed to small systematic errors that accumulate over time. Thus, we find that the accuracy of the neural network in the “offline” mode does not reflect its performance when coupled with other components.",['Convolutional Neural Networks (CNNs)'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W3001677969,W3001677969,,https://doi.org/10.1080/10095020.2019.1710438,Assessing environmental impacts of urban growth using remote sensing,"This paper provides a study of the changes in land use in urban environments in two cities, Wuhan, China and western Sydney in Australia. Since mixed pixels are a characteristic of medium resolution images such as Landsat, when used for the classification of urban areas, due to changes in urban ground cover within a pixel, Multiple Endmember Spectral Mixture Analysis (MESMA) together with Super-Resolution Mapping (SRM) are employed to derive class fractions to generate classification maps at a higher spatial resolution using an Artificial Neural Network (ANN) predicted Wavelet method. Landsat images over the two cities for a 30-year period, are classified in terms of vegetation, buildings, soil and water. The classifications are then processed using Indifrag software to assess the levels of fragmentation caused by changes in the areas of buildings, vegetation, water and soil over the 30 years. The extents of fragmentation of vegetation, buildings, water and soil for the two cities are compared, while the percentages of vegetation are compared with recommended percentages of green space for urban areas for the benefit of health and well-being of inhabitants. Changes in Ecosystem Service Values (ESVs) resulting from the urbanization have been assessed for Wuhan and Sydney. The UN Sustainable Development Goals (SDG) for urban areas are being assessed by researchers to better understand how to achieve the sustainability of cities.",['Artificial Neural Network'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W3001677969,W3001677969,,https://doi.org/10.1080/10095020.2019.1710438,Assessing environmental impacts of urban growth using remote sensing,"Abstract. Simulating global and regional climate at high resolution is essential to study the effects of climate change and capture extreme events affecting human populations. To achieve this goal, the scalability of climate models and efficiency of individual model components are both important. Radiative transfer is among the most computationally expensive components in a typical climate model. Here we attempt to model this component using a neural network. We aim to study the feasibility of replacing an explicit, physics-based computation of longwave radiative transfer by a neural network emulator and assessing the resultant performance gains. We compare multiple neural-network architectures, including a convolutional neural network, and our results suggest that the performance loss from the use of conventional convolutional networks is not offset by gains in accuracy. We train the networks with and without noise added to the input profiles and find that adding noise improves the ability of the networks to generalise beyond the training set. Prediction of radiative heating rates using our neural network models achieve up to 370× speedup on a GTX 1080 GPU setup and 11× speedup on a Xeon CPU setup compared to the a state-of-the-art radiative transfer library running on the same Xeon CPU. Furthermore, our neural network models yield less than 0.1 K d−1 mean squared error across all pressure levels. Upon introducing this component into a single-column model, we find that the time evolution of the temperature and humidity profiles is physically reasonable, though the model is conservative in its prediction of heating rates in regions where the optical depth changes quickly. Differences exist in the equilibrium climate simulated when using the neural network, which are attributed to small systematic errors that accumulate over time. Thus, we find that the accuracy of the neural network in the “offline” mode does not reflect its performance when coupled with other components.",['Artificial Neural Network'],Classic AI & Neural Network Architectures,0,1
https://openalex.org/W3002086823,W3002086823,,https://doi.org/10.7717/peerj.8407,Speeding up training of automated bird recognizers by data reduction of audio features,"Automated acoustic recognition of birds is considered an important technology in support of biodiversity monitoring and biodiversity conservation activities. These activities require processing large amounts of soundscape recordings. Typically, recordings are transformed to a number of acoustic features, and a machine learning method is used to build models and recognize the sound events of interest. The main problem is the scalability of data processing, either for developing models or for processing recordings made over long time periods. In those cases, the processing time and resources required might become prohibitive for the average user. To address this problem, we evaluated the applicability of three data reduction methods. These methods were applied to a series of acoustic feature vectors as an additional postprocessing step, which aims to reduce the computational demand during training. The experimental results obtained using Mel-frequency cepstral coefficients (MFCCs) and hidden Markov models (HMMs) support the finding that a reduction in training data by a factor of 10 does not significantly affect the recognition performance.","['Mel-frequency cepstral coefficients (MFCCs)', 'hidden Markov models (HMMs)']",Classic AI & Neural Network Architectures,1,0
https://openalex.org/W3002854188,W3002854188,,https://doi.org/10.6224/jn.202002_67(1).05,[The Development of Early Warning Systems for Home/Community Elderly Care].,"With Taiwan now an ""aged society"", home safety for older individuals has become a very important issue. The purpose of establishing early warning systems in homes and/or communities is to generate and disseminate meaningful warning information to medical institutions or rescue units in a timely manner so that they may take timely and appropriate action. The main purpose of this paper is to introduce the current application of information and communication technology (ICT, especially the Internet of Things and artificial intelligence) in early warning systems for home and community care. Two approaches to developing these systems are introduced: instant detection and prevention monitoring. Instant detection facilitates fall detection and personnel tracking, while the focus of prevention monitoring is on preventing falls and physiological status monitoring. The challenges faced by in incorporating ICT into these early monitoring systems are discussed as well.居家社區照護早期警示系統之發展.隨著高齡社會的來臨，長者的居家安全成為非常重要的議題。居家／社區的早期警示系統之目的在及時產生、傳播有意義的警告資訊，提供醫療院所或救助單位能迅速提供適當的照護行動。本文主要的目的在介紹目前資通訊科技在居家和社區早期警示系統上之應用，特別是物聯網及人工智慧。本文中將分成即時偵測及預防監控兩個層次來探討，即時偵測包含跌倒偵測和人員追蹤兩方面，而預防監控特別著重在預防跌倒和生理狀態監控兩方面。同時本文也探討現今發展資通訊科技在居家社區的早期監視系統所面臨的挑戰，期望透過本文的介紹說明能對早期監視系統的發展提供幫助。.","['Fall detection', 'Personnel tracking', 'Prevent falls', 'Physiological status monitoring']",Classic Machine Learning,1,0
https://openalex.org/W3003160242,W3003160242,,,Artificial Intelligence and the Environmental Crisis: Can Technology Really Save the World?,"A radical and challenging book which argues that artificial intelligence needs a completely different set of foundations, based on ecological intelligence rather than human intelligence, if it is to deliver on the promise of a better world. This can usher in the greatest transformation in human history, an age of re-integration. Our very existence is dependent upon our context within the Earth System, and so, surely, artificial intelligence must also be grounded within this context, embracing emergence, interconnectedness and real-time feedback. We discover many positive outcomes across the societal, economic and environmental arenas and discuss how this transformation can be delivered.
 
Key Features:

Identifies a key weakness in current AI thinking, that threatens any hope of a better world.
Highlights the importance of realizing that systems theory is an essential foundation for any technology that hopes to positively transform our world.
Emphasizes the need for a radical new approach to AI, based on ecological systems.
Explains why ecosystem intelligence, not human intelligence, offers the best framework for AI.
Examines how this new approach will impact on the three arenas of society, environment and economics, ushering in a new age of re-integration.",[],New Generation of AI,1,0
https://openalex.org/W3003160242,W3003160242,,,Artificial Intelligence and the Environmental Crisis: Can Technology Really Save the World?,"A radical and challenging book which argues that artificial intelligence needs a completely different set of foundations, based on ecological intelligence rather than human intelligence, if it is to deliver on the promise of a better world. This can usher in the greatest transformation in human history, an age of re-integration. Our very existence is dependent upon our context within the Earth System, and so, surely, artificial intelligence must also be grounded within this context, embracing emergence, interconnectedness and real-time feedback. We discover many positive outcomes across the societal, economic and environmental arenas and discuss how this transformation can be delivered.
 
Key Features:

Identifies a key weakness in current AI thinking, that threatens any hope of a better world.
Highlights the importance of realizing that systems theory is an essential foundation for any technology that hopes to positively transform our world.
Emphasizes the need for a radical new approach to AI, based on ecological systems.
Explains why ecosystem intelligence, not human intelligence, offers the best framework for AI.
Examines how this new approach will impact on the three arenas of society, environment and economics, ushering in a new age of re-integration.",[],New Generation of AI,1,0
https://openalex.org/W3003389821,W3003389821,,https://doi.org/10.37591/joaest.v10i3.3443,IoT and Machine Learning in Green Smart Home Automation and Green Building Management,"Abstract Internet of things (IoT) is a developing concept, which aims to associate billions of devices with each other. The IoT devices sense, assemble, and transfer important information from their environments. This exchange of very large amount of information among billions of devices makes an enormous energy need. The radical growth in urbanization over the last few years needs sustainable, proficient, and smart clarifications for transport, governance, environment, quality of life, and so on. The IoT propose many urbane and universal applications for smart homes. The energy demand of IoT applications is greater than before; while IoT devices carry on to grow in both numbers and necessities. Therefore, IoT-based smart home and its automation must have the capability to competently consume energy and control the allied challenges. Energy management is considered as a key prototype for the comprehension of composite energy systems in smart homes. Further, smart home solutions have to be energy-efficient from both the users’ and environment’s points of view. In other words, smart home solutions have to be energy-efficient, cost-efficient, reliable, secure, and so on. For example, IoT devices should operate in a self-sufficient way without compromising quality of service (QoS) in order to enhance the performance with unremitting network operations. Therefore, the energy efficiency and life span of IoT devices are the key issues to next generation smart home solutions. It has been studied the electrical energy consumption from a prevailing house to make it further efficient presenting as much as possible IoT applications. The smart home applications that are straightforwardly associated with energy efficiency are obviously the light and the temperature monitoring. Hence, they are significant to assure the energy saving. Other smart home arrangements, similar to Fire Detection, Security, are not straightforwardly linked with the energy efficiency. Keywords: IoT, smart home, energy efficiency, Home Appliances, smart grid Cite this Article Partha Ghosh, Suradhuni Ghosh. IoT and Machine Learning in Green Smart Home Automation and Green Building Management. Journal of Alternate Energy Sources & Technologies . 2019; 10(3): 8–36p.",['machine learning'],Classic Machine Learning,1,1
https://openalex.org/W3003402824,W3003402824,,https://doi.org/10.1089/hs.2019.0147,The Road to Achieving Global Health Security: Accelerating Progress and Spurring Urgency to Fill Remaining Gaps,"Health SecurityVol. 18, No. S1 Cynthia H. Cassell and Ronald L. Moolenaar, CDC EditorsOpen AccessThe Road to Achieving Global Health Security: Accelerating Progress and Spurring Urgency to Fill Remaining GapsDiane Meyer, Elizabeth E. Cameron, Jessica Bell, and Jennifer B. NuzzoDiane MeyerAddress correspondence to: Diane Meyer, RN, MPH, Managing Senior Analyst, Johns Hopkins Center for Health Security, 621 East Pratt St., Suite 210, Baltimore, MD 21202 E-mail Address: dmeyer10@jhmi.eduDiane Meyer, RN, MPH, is Managing Senior Analyst and a Research Associate, and Jennifer B. Nuzzo, DrPH, SM, is a Senior Scholar and Associate Professor, both at the Johns Hopkins Center for Health Security and in the Department of Environmental Health and Engineering, Bloomberg School of Public Health, Baltimore, MD. Elizabeth E. Cameron, PhD, is Vice President, and Jessica Bell, MS, is a Senior Program Officer, both in Global Biological Policy and Programs, Nuclear Threat Initiative, Washington, DC.Search for more papers by this author, Elizabeth E. CameronDiane Meyer, RN, MPH, is Managing Senior Analyst and a Research Associate, and Jennifer B. Nuzzo, DrPH, SM, is a Senior Scholar and Associate Professor, both at the Johns Hopkins Center for Health Security and in the Department of Environmental Health and Engineering, Bloomberg School of Public Health, Baltimore, MD. Elizabeth E. Cameron, PhD, is Vice President, and Jessica Bell, MS, is a Senior Program Officer, both in Global Biological Policy and Programs, Nuclear Threat Initiative, Washington, DC.Search for more papers by this author, Jessica BellDiane Meyer, RN, MPH, is Managing Senior Analyst and a Research Associate, and Jennifer B. Nuzzo, DrPH, SM, is a Senior Scholar and Associate Professor, both at the Johns Hopkins Center for Health Security and in the Department of Environmental Health and Engineering, Bloomberg School of Public Health, Baltimore, MD. Elizabeth E. Cameron, PhD, is Vice President, and Jessica Bell, MS, is a Senior Program Officer, both in Global Biological Policy and Programs, Nuclear Threat Initiative, Washington, DC.Search for more papers by this author, and Jennifer B. NuzzoDiane Meyer, RN, MPH, is Managing Senior Analyst and a Research Associate, and Jennifer B. Nuzzo, DrPH, SM, is a Senior Scholar and Associate Professor, both at the Johns Hopkins Center for Health Security and in the Department of Environmental Health and Engineering, Bloomberg School of Public Health, Baltimore, MD. Elizabeth E. Cameron, PhD, is Vice President, and Jessica Bell, MS, is a Senior Program Officer, both in Global Biological Policy and Programs, Nuclear Threat Initiative, Washington, DC.Search for more papers by this authorPublished Online:31 Jan 2020https://doi.org/10.1089/hs.2019.0147AboutSectionsPDF/EPUB Permissions & CitationsPermissionsDownload CitationsTrack CitationsAdd to favorites Back To Publication ShareShare onFacebookTwitterLinked InRedditEmail Five years ago, the world was on a precipice. An outbreak of Ebola that had started in Guinea spilled into neighboring Liberia and Sierra Leone. None of the affected countries had recorded an outbreak of Ebola before, and the response was challenged by lack of public health capacities, community distrust of healthcare workers, poor communication, and difficulties reaching affected populations. International health officials expressed concerns about the potential for further spread of the virus throughout the continent, and, ultimately, more than 11,000 people lost their lives.The United States stepped up as a leader in the global response to the West African Ebola epidemic, which, over a 2-year period, would cost billions of dollars and would lead to the development of a complex web of global partnerships across governments, international organizations, foundations, and private industry. Just before the first Ebola cases in Guinea came to light in 2014, the United States brought together in Washington, DC, partner countries from around the world to launch the Global Health Security Agenda (GHSA). Ironically, the intent of the GHSA was to prevent the very type of uncontrolled epidemic that was spreading silently in West Africa by improving countries' capacities to prevent, detect, and rapidly respond to outbreaks occurring within their borders. During the Ebola epidemic, the United States committed $1 billion to advance the goals of the GHSA. This likely represented the world's largest single investment by a country toward improved implementation of the International Health Regulations (IHR, 2005) and helped catalyze additional contributions from other countries.By the time the outbreak was contained, it was clear that it had resulted in considerable loss of life and significant long-term societal impacts. The economic and social burden of the 2014-2016 West Africa Ebola outbreak is now estimated to be around US$53 billion.1 Importantly, the outbreak resulted in significant indirect impacts on the health systems in affected countries, including decreases in the use of maternal health services and disruptions in HIV/AIDS treatment that will have lasting consequences for health outcomes.2The startling tolls of the 2014 Ebola epidemic and the launch of the GHSA helped create political will to externally assess countries' readiness for significant infectious disease events. The GHSA began this effort through the development of pilot assessments of national public health capacities, which were conducted in 6 countries.3* This effort helped to define metrics for assessing whether countries possess the core public health capacities needed to fulfill their obligations under the IHR to prevent, detect, and respond to public health emergencies with the potential for international spread.Eventually, the GHSA assessment process was transitioned to the World Health Organization (WHO), where it became the foundation for WHO's current Joint External Evaluation (JEE) process. Through the JEE, WHO is now taking a proactive role in assessing whether countries can fulfill their obligations under the IHR. For the first time, it is possible to externally assess countries' core public health capacities, identify gaps in countries' readiness, and coordinate with donors to identify and prioritize financing for specific actions to address these gaps.Since 2014, 108 countries have completed a JEE, and additional countries are in the pipeline. Although a high level of participation in the JEE process is a welcome development following nearly a decade of stalled implementation of the IHR, much more work must be done to improve countries' commitment to advancing global health security. By assessing national core public health capacities, the JEEs represent the first step a country must take to improve its readiness for infectious disease emergencies. Political leadership and actionable follow-through are needed to develop, cost, and finance National Action Plans for Health Security to address gaps in capacities that the JEEs have identified. For example, the first 100 JEEs identified more than 7,000 priority tasks necessary to improve health security, but very few of these gaps have been addressed.4 In fact, despite having undergone a JEE, many countries have yet to draft and cost their action plans, and even fewer have mobilized the resources needed to improve preparedness capacities.4These challenges are evident in data from our recently published Global Health Security (GHS) Index.5 This first-ever benchmarking of health security among the 195 IHR states parties† finds that no country is fully prepared for an epidemic or pandemic. In fact, the average overall GHS Index score is 40.2 out of 100, with all countries showing significant gaps. Most states lack essential public health capacities to prevent, detect, and respond to health emergencies, and there is little evidence that most countries can initiate and exercise these capacities in an actual emergency. Many countries face major political and security risks that could undermine national capability to counter biological threats, and most countries have not allocated funding from national budgets to fill identified preparedness gaps. For example, only 5% of the countries assessed score in the top tier‡ for financing health security.In addition, countries are not prepared for a global catastrophic biological risk (GCBR), including those that could be caused by the international spread of a new or emerging pathogen or by the deliberate or accidental release of a dangerous or engineered agent or organism. Alarmingly, 75% of countries received low scores in GCBR-relevant areas, including oversight of dual-use research and medical countermeasure dispensing. As biotechnologies continue to advance for societal benefit, a dedicated international normative body should be established to promote early identification and reduction of associated risks.Perhaps one of the most concerning thematic findings of the GHS Index is how poorly countries score in the category that measures whether they have a ""sufficient and robust health system to treat the sick and protect healthcare workers."" This category specifically looks at whether countries have the foundational healthcare system capacities necessary to support mobilization of the public health capacities measured elsewhere. The average country score in this category was 26.4 out of 100. This finding suggests a strong need to integrate efforts aimed at strengthening national health systems and promoting adoption of universal health coverage with efforts to boost countries' core public health capacities to tackle infectious disease outbreaks. An important first step will be to reinforce that, as countries are assessing the availability of core public health capacities via the JEE, they are also assessing and improving the strength of their broader health system.These findings highlight an urgent need to increase the financial, technical, and human capacity available to strengthen global health security. Though difficult, it is possible to make progress. The World Bank has determined that ""investing in health security through financing preparedness is a highly cost-effective way to protect lives and safeguard livelihoods and communities.""6 It estimates that in low-income countries, needed investments in preparedness may cost around US$1 per person per year—a reasonable sum compared to the cost of the outbreaks described above.6More leaders are prioritizing the creation of urgent health security financing mechanisms, including expanding the use of World Bank International Development Association allocations for epidemic preparedness. The potential for a global health security matching fund, which we have recommended, is also within reach, but making that fund a reality will require urgent and coordinated leadership from decision makers to leverage investments from national country budgets, international organizations, philanthropists, and donors against specific action plans and measurable targets. This work should start now and could be one focus area for a heads-of-state summit convened by the UN Secretary-General, another key recommendation from our GHS Index report.In our view, long-term global health security cannot be achieved without increased and sustained investments. The GHSA has set an ambitious target of more than 100 countries achieving, by 2024, completion of health security evaluations, resource mobilization, and implementation to fill gaps. To meet this goal, it is essential that the United States play a major leadership role in improving health security capacities across the globe. Continued technical and financial support by the United States for global health security efforts is central to making measurable progress. US support of the GHSA and country-level global health security activities has been a major contributor to the success of health security programs to date, providing both financing and technical experts from the US Centers for Disease Control and Prevention (CDC), the US Agency for International Development, and the US Departments of Health and Human Services, Defense, and State. The United States is also working behind the scenes to support the JEE process, which has helped more than 100 countries assess their public health capacities and begin addressing any shortfalls. Although these efforts are clearly multilateral, US leadership has been instrumental in setting up and enabling their success.This CDC supplement provides compelling evidence of the impact of US leadership and investment toward achieving global health security and highlights the important ongoing international work to prepare for biological threats. The challenges faced and lessons learned by the authors are integral to building and sustaining national health security capacities, particularly at the subnational level. We all know that preparedness begins in the very communities affected by outbreaks, and a country's collective health security is only as strong as its weakest link. Thus, each effort to identify and implement novel, integrative solutions is one small step toward making the world safer and more secure from outbreaks.References1. Huber C, Finelli L, Stevens W. The economic and social burden of the 2014 Ebola outbreak in West Africa. J Infect Dis 2018;218(Suppl 5):S698-S704. Crossref, Medline, Google Scholar2. Brolin Ribacke KJ, Saulnier DD, Eriksson A, von Schreeb J. Effects of the West Africa Ebola virus disease on health-care utilization—a systematic review. Front Public Health 2016;4:222. Crossref, Medline, Google Scholar3. Bell E, Tappero JW, Ijaz K, et al. Joint external evaluation—development and scale-up of global multisectoral health capacity evaluation process. Emerg Infect Dis 2017;23(Suppl). Google Scholar4. Shahpar C, Lee CT, Wilkason C, Buissonnière M, McClelland A, Frieden TR. Protecting the world from infectious disease threats: now or never. BMJ Glob Health 2019;4(4):e001885. Crossref, Medline, Google Scholar5. Global Health Security Index. https://www.ghsindex.org/. Accessed December 10, 2019. Google Scholar6. International Working Group on Financing Preparedness. From Panic and Neglect to Investing in Health Security. Financing Pandemic Preparedness at a National Level. Washington, DC: World Bank; 2017. Google Scholar* Pilot countries were the Republic of Georgia, Peru, Portugal, Uganda, United Kingdom, and Ukraine.† As of April 16, 2013, there are 196 states parties to the World Health Organization (WHO) 2005 International Health Regulations (IHR), including the Holy See. The Holy See is a sovereign juridical entity under international law, but it was not included in the country-specific research for the GHS Index in light of the Holy See's lack of an independent health system.‡ The GHS Index scoring system is on a 100-point scale and includes 3 tiers. Countries that score between 0 and 33.3 are in the bottom tier, countries that score between 33.4 and 66.6 are in the middle tier, and countries that score between 66.7 and 100 are in the upper or ""top"" tier.FiguresReferencesRelatedDetailsCited byValidation analysis of Global Health Security Index (GHSI) scores 201926 October 2020 | BMJ Global Health, Vol. 5, No. 10A Scientometric Analysis of Global Health Research24 April 2020 | International Journal of Environmental Research and Public Health, Vol. 17, No. 8 Volume 18Issue S1Jan 2020 InformationCopyright 2020, Mary Ann Liebert, Inc., publishersTo cite this article:Diane Meyer, Elizabeth E. Cameron, Jessica Bell, and Jennifer B. Nuzzo.The Road to Achieving Global Health Security: Accelerating Progress and Spurring Urgency to Fill Remaining Gaps.Health Security.Jan 2020.S-1-S-3.http://doi.org/10.1089/hs.2019.0147creative commons licensePublished in Volume: 18 Issue S1: January 31, 2020PDF download","['Global Health Security', 'Strategies', 'Gap Filling']",Other,1,1
https://openalex.org/W3003681081,W3003681081,,https://doi.org/10.11646/megataxa.1.1.6,The promise of next-generation taxonomy,"Documenting, naming and classifying the diversity of life on Earth provides baseline information on the biosphere, which is crucially important to understand and mitigate the global changes of the Anthropocene. We should meet three main challenges, using new technological developments without throwing the well-tried and successful foundations of Linnaean nomenclature overboard. 1. Fully embrace cybertaxonomy, machine learning and DNA taxonomy to ease, not burden the workflow of taxonomists. 2. Emphasize diagnosis over description, images over words. 3. Understand promises and pitfalls of omics approaches to avoid taxonomic inflation.",['machine learning'],Classic Machine Learning,1,1
https://openalex.org/W3003706641,W3003706641,,https://doi.org/10.1016/j.cois.2020.01.008,Technological advances in field studies of pollinator ecology and the future of e-ecology,,,,N/A,N/A
https://openalex.org/W3003792992,W3003792992,,https://doi.org/10.12086/oee.2020.190161,An open-pit mine roadway obstacle warning method integrating the object detection and distance threshold model,"In order to solve the problem that the current driving warning method cannot adapt to the unstructured road in open-pit mine, this paper proposes an early warning method that integrates target detection and obstacle distance threshold. Firstly, the original Mask R-CNN detection framework was improved according to the characteristics of open-pit mine obstacles, and dilated convolution was introduced into the framework network to expand the receptive field range without reducing the feature map to ensure the detection accuracy of larger targets. Then, a linear distance factor was constructed based on the target detection results to represent the depth information of obstacles in the input image, and an SVM warning model was established. Finally, in order to ensure the generalization ability of the warning model, transfer learning method was adopted to carry out pre-training of the network in COCO data set, and both the C5 stage and detection layer were trained in the data collected in the field. The experimental results show that the accuracy and recall of the proposed method reach 98.47% and 97.56% in the field data detection, respectively, and the manually designed linear distance factor has a good adaptability to the SVM warning model.","['Mask R-CNN', 'dilated convolution']",Classic AI & Neural Network Architectures,1,1
https://openalex.org/W3003800890,W3003800890,,https://doi.org/10.1029/2019ms001759,Improved ENSO Prediction Skill Resulting From Reduced Climate Drift in IAP‐DecPreS: A Comparison of Full‐Field and Anomaly Initializations,"Abstract When initiated from observational conditions, coupled climate models used in seasonal predictions generally experience climate drifts. How climate drift affects El Niño–Southern Oscillation (ENSO) prediction is important but not clearly understood. Here, we investigate this issue by comparing seasonal hindcasts using two distinct initialization approaches, namely, anomaly and full‐field initializations, based on a climate prediction system named IAP‐DecPreS. The differences between the two approaches are mainly evident in the drift behavior. We find that the hindcasts based on anomaly initialization (Hindcast‐A) have higher ENSO prediction skill compared to those based on full‐field initialization (Hindcast‐F). The climate drifts are largely reduced in the Hindcast‐A as expected. In contrast, the Hindcast‐F features a growing warming of the equatorial central eastern Pacific with increasing lead times. To investigate the impact of drift on the prediction, the 1997/1998 and 2015/2016 El Niño cases are analyzed. At a 7‐month lead, the Hindcast‐A reasonably predicts the two events, while the Hindcast‐F shows large errors in both evolution and amplitude. Budget analyses show that the underestimation of warming tendency in the Hindcast‐F is caused by cooling effects of excessive anomalous surface shortwave radiative flux and anomalous temperature advection by mean horizontal currents, both of which are associated with the climate drift. Our results imply that the use of the AI scheme can improve ENSO predictions through a reduction in climate drift in IAP‐DecPreS. The drifts can dynamically influence ENSO predictions, and their impact cannot be thoroughly removed via the empirical bias correction. Thus, reducing drift impacts is necessary.",[],Other,1,1
https://openalex.org/W3003834097,W3003834097,,https://doi.org/10.1089/bio.2020.29063.bjs,A New Qualification for the New Year: ISBER and American Society of Clinical Pathology Board of Certification Announce New Qualification in Biorepository Science Examination for Biobank Technicians,"Biopreservation and BiobankingVol. 18, No. 1 ISBER CornerFree AccessA New Qualification for the New Year: ISBER and American Society of Clinical Pathology Board of Certification Announce New Qualification in Biorepository Science Examination for Biobank TechniciansBrent Schacter, Nicole Sieffert, Kristina Hill, Pat Tanabe, and Daniel Simeon-DubachBrent SchacterAddress correspondence to: Brent Schacter, MD, FRCPC, Department of Medical Oncology and Hematology, University of Manitoba, CancerCare Manitoba, Room 5008c, 675 McDermot Avenue, Winnipeg, Manitoba R3E 0V9, Canada E-mail Address: bschacter@cancercare.mb.caCancerCare Manitoba/University of Manitoba, Winnipeg, Canada.Search for more papers by this author, Nicole SieffertIndependent Consultant, Galveston, Texas.Search for more papers by this author, Kristina HillIndependent Consultant, Florida.Search for more papers by this author, Pat TanabeASCP Board of Certification, Chicago, Illinois.Search for more papers by this author, and Daniel Simeon-Dubachmedservice, Walchwil, Switzerland.Search for more papers by this authorPublished Online:11 Feb 2020https://doi.org/10.1089/bio.2020.29063.bjsAboutSectionsPDF/EPUB Permissions & CitationsPermissionsDownload CitationsTrack CitationsAdd to favorites Back To Publication ShareShare onFacebookTwitterLinked InRedditEmail Modern biobanking is a complex activity that requires highly trained and skilled repository staff to provide a level of quality that will ensure valid and reliable access to high-quality research specimens. Well-trained repository staff are essential to ensure high-quality biospecimens that will be useful in defining the goals of precision medicine, biomarker development, and biomedical research as a whole. Until recently, no formal repository qualification program existed to define the level of skill required to ensure quality in technical biobanking skills, although some training programs for biobanking had been created, including but not limited to CTRNet, Lund University, Integrated Biobank of Luxembourg (IBBL), Medical University Graz, University Côte D'Azur, Nice.For this reason, International Society for Biological and Environmental Repositories (ISBER) and the American Society for Clinical Pathology Board of Certification (ASCP BOC) have joined forces to create a qualification examination for biobankers. ASCP BOC is an organization that provides excellence in global medical laboratory professional certification. After meeting specific educational and experience requirements for the qualification, candidates will be eligible to complete an online examination and, if successful, gain recognition for their skills and competencies as biobankers. The qualification will be designated as Qualification in Biorepository Science (QBRS) and will be signified by the honorific QBRS.To develop this qualification, an Memorandum of Understanding (MOU) between ISBER and ASCP BOC was signed in the fall of 2017. Subsequently, a QBRS Workgroup, designated the Examination Committee, was established as a standing committee of the ASCP BOC. This committee has a complement of eight members chosen after ISBER's call for volunteers received a very large response. Committee members were selected taking into consideration diversity in work background in biobanking, geography, experience as a practicing biobanker or an individual with expertise in the principles and practice of biobanking as documented by prior contribution to scholarship or leadership in biobanking. The initial committee members, chosen for a 3-year term, were mutually agreed upon by ISBER and ASCP BOC, nominated for formal appointment, and approved by the Board of Governors of the ASCP BOC.* To provide broad oversight of this activity, a steering committee of ISBER members with appropriate backgrounds in standards development was appointed as a subgroup of the ISBER Standards Committee.† It also has representation by ASCP BOC in the person of Pat Tanabe, the executive director of ASCP BOC. The chair of the steering committee is Brent Schacter.The first meeting of the Examination Committee was held in December 2018. In the intervening period, the parameters for the examination were set, supporting documents were developed and a bank of examination questions was created and standardized. The steering committee has provided broad oversight of this process, which has been thorough and comprehensive. The Examination Committee has had the responsibility for developing, reviewing, and updating the biobanking item/exam question bank, performing job task analyses, and creating and updating the examination content guidelines, eligibility requirements, and the candidate experience documentation forms that are needed for the QBRS Program. The Steering Committee has reviewed and provided comment on the supporting elements to clarify and focus content. In essence, ISBER members of the Examination Committee have created the examination content, and ASCP BOC has provided their well-tested and utilized processes for setting the qualification in place.Resource documents for the QBRS examination are now available on the ISBER website at www.isber.org/qualification and the ASCP BOC website at www.ascp.org/boc/qbrs. Details can be found on these sites regarding the routes of and requirements for eligibility to apply for and take the QBRS examination. Other documents and information include a Work Experience Documentation Form, a list of Regional Accrediting Bodies for North American colleges and universities as well as for colleges and universities outside of North America, an examination topic outline, and a list of suggested reading for examination preparation (journals, texts, online).The requirements for examination application may take one of three routes. Route 1 includes a valid ASCP or ASCP technologist/scientist or specialist certification, a baccalaureate degree from a regionally accredited college/university with a major in biology, chemistry, biotechnology, or a related field and 1 year of full-time experience in a biorepository within the past 5 years. Route 2 does not require an ASCP certification, but includes a baccalaureate degree from a regionally accredited college/university with a major in biology, chemistry, biotechnology, or a related field and two full years of full-time work in a biorepository within the past 5 years. An alternative to the major required in both routes is 30 semester hours in biology and chemistry that may be obtained within or in addition to the baccalaureate degree. Route 3 requires a master's degree from a regionally accredited college/university with a major in biology, chemistry, biotechnology, or a related field and 1 year of experience in a biorepository within the past 5 years. A more detailed description of the requirements for application can be found on the ISBER and ASCP BOC websites as noted earlier.The QBRS examination questions encompass the major content areas within Biorepository Science, including specimen handling (collection, processing, and storage), sample/data inventory management and quality control, safety and infection control, and biorepository operations. Each of these topics will comprise 25%–30% of the examination, with the exception of biorepository operations (15%–20%), and will equal a specific percentage as noted of the 50 total examination questions. The questions may be theoretical and/or procedural. The previously referenced websites provide full details regarding the topics that are covered.The QBRS examination will be open for application as of January 2, 2020. The earliest opportunity for qualified applicants to complete the examination will be in April 2020 and the cost is $240 US. The 50 question, multiple choice, timed test is self-administered on your own computer on the date and time of your choice within the 60-day examination period indicated on your admission notification. The examination may be attempted up to three times if initially unsuccessful. QBRS certificate holders will be required to revalidate their qualification every 3 years by documentation of required continuing education or other educational activities as defined by the ASCP BOC.The ISBER/ASCP BOC partnership allows ISBER to fully participate in the development of the global QBRS credential program requirements that are essential for the future of sustainable quality biobanking. The new QBRS is a unique and important enhancement to the global practice of quality biobanking. Biobankers are encouraged to review the QBRS application materials and strongly consider applying for credentialing as a benchmarked quality biorepository scientist. For further questions, please contact standards@isber.org* The members of the Examination (Workgroup) Committee are Anne Braggia, Mary Ann Clements, Carol Elliott, Annemieke De Wilde, Kathy Mangold, Hector Monforte, Piper Mullins, and Alison Parry Jones.† The members of the Steering Committee are Brent Schacter (chair), Monique Albert, Jane Carpenter, Yehudit Cohen, Annemieke De Wilde, Koh Furuta, Carlo Largiader, Nicole Sieffert, Daniel Simeon-Dubach, Tamsin Tarling, Heidi Wagner, Peter Watson, and Pat Tanabe.FiguresReferencesRelatedDetailsCited byBiosafety and biobanking: Current understanding and knowledge gapsBiosafety and Health, Vol. 3, No. 5Biobanking in the COVID-19 Era and Beyond: Part 1. How Early Experiences Can Translate into Actionable Wisdom Clare M. Allocca, Marianna J. Bledsoe, Monique Albert, Sergey V. Anisimov, Elena Bravo, Marta G. Castelhano, Yehudit Cohen, Mieke De Wilde, Koh Furuta, Zisis Kozlakidis, Dunja Martin, Anabela Martins, Shannon McCall, Helen Morrin, Rebecca S. Pugh, Brent Schacter, Daniel Simeon-Dubach, and Emma Snapes15 December 2020 | Biopreservation and Biobanking, Vol. 18, No. 6Biobanking in the COVID-19 Era and Beyond: Part 2. A Set of Tool Implementation Case Studies Clare M. Allocca, Emma Snapes, Monique Albert, Marianna J. Bledsoe, Marta G. Castelhano, Mieke De Wilde, Koh Furuta, Zisis Kozlakidis, Dunja Martin, Anabela Martins, Shannon J. McCall, and Brent Schacter15 December 2020 | Biopreservation and Biobanking, Vol. 18, No. 6The Responses of Biobanks to COVID-19 Marianne K. Henderson, Zisis Kozlakidis, Jajah Fachiroh, Beatrice Wiafe Addai, Xun Xu, Sameera Ezzat, Heidi Wagner, Márcia M.C. Marques, and Birenda K. Yadav15 December 2020 | Biopreservation and Biobanking, Vol. 18, No. 6 Volume 18Issue 1Feb 2020 InformationCopyright 2020, Mary Ann Liebert, Inc., publishersTo cite this article:Brent Schacter, Nicole Sieffert, Kristina Hill, Pat Tanabe, and Daniel Simeon-Dubach.A New Qualification for the New Year: ISBER and American Society of Clinical Pathology Board of Certification Announce New Qualification in Biorepository Science Examination for Biobank Technicians.Biopreservation and Biobanking.Feb 2020.43-44.http://doi.org/10.1089/bio.2020.29063.bjsPublished in Volume: 18 Issue 1: February 11, 2020Online Ahead of Print:January 28, 2020PDF download","['Diffusion models', 'GANs', 'VAEs', 'Foundation Models (LLMs)', 'CLIP']",New Generation of AI,0,0
https://openalex.org/W3003931874,W3003931874,,https://doi.org/10.1016/j.compstruc.2020.106208,"A neural network surrogate model for the performance assessment of a vertical structure subjected to non-stationary, tornadic wind loads","Despite significant advancements in computational technologies and methods, the comprehensive assessment of the performance capacities and risk of structures built in environments prone to severe natural hazards is still a daunting task under standard Monte Carlo-based simulation schemes. This issue is particularly relevant for the consideration of wind actions from loads generated by non-stationary phenomena (e.g. tornadoes) because of extreme complexities in the simulated flow field and the fluid-structure interaction. To mitigate such computational burdens, this study proposes a surrogate modeling approach that utilizes predicted fragilities from artificial neural networks (ANNs) to facilitate the performance-based assessment of a vertical structure subjected to tornadic wind loads. Calibration data for the feedforward ANNs are extracted from numerically generated responses based on a derived wind loading model that capitalizes on the developments of various analytical formulations of a tornado’s wind field. Uncertainties in the structural behavior and in the overall modeling procedure are incorporated in the process, culminating in a life-cycle cost assessment that incorporates a practical, economic value to the simulation framework. The novel application of ANNs in this study, therefore, empowers a more robust performance-based framework for the risk evaluation of structures subjected to tornado wind loads.",['ANNs'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W3004012978,W3004012978,,https://doi.org/10.3390/e22040417,Representational Rényi Heterogeneity,"A discrete system’s heterogeneity is measured by the Rényi heterogeneity family of indices (also known as Hill numbers or Hannah–Kay indices), whose units are the numbers equivalent. Unfortunately, numbers equivalent heterogeneity measures for non-categorical data require a priori (A) categorical partitioning and (B) pairwise distance measurement on the observable data space, thereby precluding application to problems with ill-defined categories or where semantically relevant features must be learned as abstractions from some data. We thus introduce representational Rényi heterogeneity (RRH), which transforms an observable domain onto a latent space upon which the Rényi heterogeneity is both tractable and semantically relevant. This method requires neither a priori binning nor definition of a distance function on the observable space. We show that RRH can generalize existing biodiversity and economic equality indices. Compared with existing indices on a beta-mixture distribution, we show that RRH responds more appropriately to changes in mixture component separation and weighting. Finally, we demonstrate the measurement of RRH in a set of natural images, with respect to abstract representations learned by a deep neural network. The RRH approach will further enable heterogeneity measurement in disciplines whose data do not easily conform to the assumptions of existing indices.",['deep neural network'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W3004015853,W3004015853,,https://doi.org/10.1029/2020gb006788,Quantifying Errors in Observationally Based Estimates of Ocean Carbon Sink Variability,"Abstract Reducing uncertainty in the global carbon budget requires better quantification of ocean CO 2 uptake and its temporal variability. Several methodologies for reconstructing air‐sea CO 2 exchange from pCO 2 observations indicate larger decadal variability than estimated using ocean models. We develop a new application of multiple Large Ensemble Earth system models to assess these reconstructions' ability to estimate spatiotemporal variability. With our Large Ensemble Testbed, pCO 2 fields from 25 ensemble members each of four independent Earth system models are subsampled as the observations and the reconstruction is performed as it would be with real‐world observations. The power of a testbed is that the perfect reconstruction is known for each of the original model fields; thus, reconstruction skill can be comprehensively assessed. We find that a neural‐network approach can skillfully reconstruct air‐sea CO 2 fluxes when it is trained with sufficient data. Flux bias is low for the global mean and Northern Hemisphere, but can be regionally high in the Southern Hemisphere. The phase and amplitude of the seasonal cycle are accurately reconstructed outside of the tropics, but longer‐term variations are reconstructed with only moderate skill. For Southern Ocean decadal variability, insufficient sampling leads to a 31% (15%:58%, interquartile range) overestimation of amplitude, and phasing is only moderately correlated with known truth ( r = 0.54 [0.46:0.63]). Globally, the amplitude of decadal variability is overestimated by 21% (3%:34%). Machine learning, when supplied with sufficient data, can skillfully reconstruct ocean properties. However, data sparsity remains a fundamental limitation to quantification of decadal variability in the ocean carbon sink.",['neural network'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W3004204798,W3004204798,,https://doi.org/10.1128/msphere.00481-19,Biogeographic Patterns in Members of Globally Distributed and Dominant Taxa Found in Port Microbial Communities,"We conducted a global characterization of the microbial communities of shipping ports to serve as a novel system to investigate microbial biogeography. The community structures of port microbes from marine and freshwater habitats house relatively similar phyla, despite spanning large spatial scales. As part of this project, we collected 1,218 surface water samples from 604 locations across eight countries and three continents to catalogue a total of 20 shipping ports distributed across the East and West Coast of the United States, Europe, and Asia to represent the largest study of port-associated microbial communities to date. Here, we demonstrated the utility of machine learning to leverage this robust system to characterize microbial biogeography by identifying trends in biodiversity across broad spatial scales. We found that for geographic locations sharing similar environmental conditions, subpopulations from the dominant phyla of these habitats (Actinobacteria, Bacteroidetes, Cyanobacteria, and Proteobacteria) can be used to differentiate 20 geographic locations distributed globally. These results suggest that despite the overwhelming diversity within microbial communities, members of the most abundant and ubiquitous microbial groups in the system can be used to differentiate a geospatial location across global spatial scales. Our study provides insight into how microbes are dispersed spatially and robust methods whereby we can interrogate microbial biogeography.IMPORTANCE Microbes are ubiquitous throughout the world and are highly diverse. Characterizing the extent of variation in the microbial diversity across large geographic spatial scales is a challenge yet can reveal a lot about what biogeography can tell us about microbial populations and their behavior. Machine learning approaches have been used mostly to examine the human microbiome and, to some extent, microbial communities from the environment. Here, we display how supervised machine learning approaches can be useful to understand microbial biodiversity and biogeography using microbes from globally distributed shipping ports. Our findings indicate that the members of globally dominant phyla are important for differentiating locations, which reduces the reliance on rare taxa to probe geography. Further, this study displays how global biogeographic patterning of aquatic microbial communities (and other systems) can be assessed through populations of the highly abundant and ubiquitous taxa that dominant the system.",['machine learning'],Classic Machine Learning,,
https://openalex.org/W3004208641,W3004208641,,,PulseSatellite: A tool using human-AI feedback loops for satellite image analysis in humanitarian contexts,"Humanitarian response to natural disasters and conflicts can be assisted by satellite image analysis. In a humanitarian context, very specific satellite image analysis tasks must be done accurately and in a timely manner to provide operational support. We present PulseSatellite, a collaborative satellite image analysis tool which leverages neural network models that can be retrained on-the fly and adapted to specific humanitarian contexts and geographies. We present two case studies, in mapping shelters and floods respectively, that illustrate the capabilities of PulseSatellite.",['Neural networks'],Classic AI & Neural Network Architectures,1,1
https://openalex.org/W3004208641,W3004208641,,,PulseSatellite: A tool using human-AI feedback loops for satellite image analysis in humanitarian contexts,"Humanitarian response to natural disasters and conflicts can be assisted by satellite image analysis. In a humanitarian context, very specific satellite image analysis tasks must be done accurately and in a timely manner to provide operational support. We present PulseSatellite, a collaborative satellite image analysis tool which leverages neural network models that can be retrained on-the fly and adapted to specific humanitarian contexts and geographies. We present two case studies, in mapping shelters and floods respectively, that illustrate the capabilities of PulseSatellite.",['Neural networks'],Classic AI & Neural Network Architectures,1,1
